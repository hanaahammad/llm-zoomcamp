{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2346971-07ef-482a-8d98-ff813a7bcc02",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183517bc-f027-43e4-9a4a-86a46f3dcfca",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82f9c39-4d87-4b21-8789-c178649376a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt4o-mini.csv'\n",
    "generated_gpt4_mini = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df = pd.read_csv(generated_gpt4_mini)\n",
    "#df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "#ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca2e555-c2b7-470a-b4a5-a58d081df2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bd9d49-31b0-4d55-a823-ec467a9b0417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90875d1d-fbaf-4f49-a6a4-a36ab6caacd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9aafbe-6e14-4bf5-9977-3f9303c6d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"multi-qa-mpnet-base-dot-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5018d5de-aff7-4700-b809-ab284b94b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "824339da-6641-4fbb-a679-67a84c1b71af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['answer_llm', 'answer_orig', 'document', 'question', 'course'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e332933-fac7-4ef0-9796-69f04897c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dc0a0d-74be-4e2f-9cae-94ea02b7549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be8b937-2868-4378-bd65-afa1eb94c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_llm = embedding_model.encode(answer_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14664a2-8d13-44b9-91a4-b58dcacbc689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.22446787e-01, -2.24855945e-01, -3.24058473e-01, -2.84758747e-01,\n",
       "        7.25685246e-03,  1.01186700e-01,  1.03716828e-01, -1.89983383e-01,\n",
       "       -2.80596819e-02,  2.71588862e-01, -1.15337133e-01,  1.14666067e-01,\n",
       "       -8.49587619e-02,  3.32365334e-01,  5.52725159e-02, -2.22195953e-01,\n",
       "       -1.42540991e-01,  1.02519318e-01, -1.52333513e-01, -2.02912480e-01,\n",
       "        1.98424123e-02,  8.38148072e-02, -5.68632185e-01,  2.32843738e-02,\n",
       "       -1.67292967e-01, -2.39256978e-01, -8.05461779e-02,  2.57081706e-02,\n",
       "       -8.15464854e-02, -7.39289895e-02, -2.61550128e-01,  1.92576721e-02,\n",
       "        3.22909206e-01,  1.90357178e-01, -9.34726413e-05, -2.13165879e-01,\n",
       "        2.88942400e-02, -1.79529544e-02, -5.92760742e-02,  1.99918360e-01,\n",
       "       -4.75170761e-02,  1.71634018e-01, -2.45914217e-02, -9.38058272e-02,\n",
       "       -3.57002944e-01,  1.33263648e-01,  1.94046125e-01, -1.18530720e-01,\n",
       "        4.56915259e-01,  1.47728026e-01,  3.35945129e-01, -1.86959922e-01,\n",
       "        2.45954573e-01, -1.07774340e-01, -1.80860028e-01,  1.18171811e-01,\n",
       "        7.27293491e-02,  2.78034240e-01,  4.16389078e-01, -1.66038379e-01,\n",
       "       -1.28587544e-01,  3.40979755e-01, -5.31822741e-02,  2.86051054e-02,\n",
       "        2.70212889e-01,  1.59812327e-02,  5.30229270e-01, -4.24391508e-01,\n",
       "        4.41499911e-02,  1.12921625e-01,  5.93987703e-01,  1.31700784e-01,\n",
       "        7.96379242e-03, -9.32307169e-03,  2.07376942e-01,  9.57206115e-02,\n",
       "       -1.83128089e-01,  1.22415833e-01, -2.01750502e-01,  3.12428623e-01,\n",
       "       -5.54993525e-02, -2.87764519e-01, -1.73390672e-01,  1.55470833e-01,\n",
       "        1.19513851e-02,  3.49036843e-01, -8.38189647e-02, -1.50645673e-01,\n",
       "        5.33231497e-02, -1.06787771e-01,  1.13244697e-01,  3.14916521e-01,\n",
       "       -2.95591471e-03,  4.66762662e-01, -1.56012818e-01, -3.61533940e-01,\n",
       "        3.31575684e-02,  2.06269294e-01, -1.06713705e-01, -5.01035377e-02,\n",
       "        1.83970094e-01, -1.39952311e-02,  2.16501430e-01,  1.41000226e-01,\n",
       "        1.90431923e-01, -3.77752930e-01,  8.65839720e-02, -9.80310962e-02,\n",
       "        2.32716188e-01,  2.01485455e-02, -9.70340669e-02,  1.01333454e-01,\n",
       "       -1.72074765e-01, -1.49902523e-01, -2.79156834e-01,  4.38269109e-01,\n",
       "       -1.79244265e-01, -5.75874746e-02, -7.84665346e-02, -3.23518276e-01,\n",
       "       -2.88021326e-01,  1.18698701e-01,  8.74241889e-02,  2.05323339e-01,\n",
       "       -4.80113328e-02, -5.71198687e-02, -2.83935368e-02, -3.82448174e-02,\n",
       "       -2.26608112e-01, -6.20818585e-02, -8.28165710e-02,  3.57217342e-01,\n",
       "       -1.73984215e-01, -2.00290859e-01,  2.40433529e-01,  2.16891631e-01,\n",
       "       -6.78277835e-02,  1.77686363e-01, -7.99813494e-03,  2.68137783e-01,\n",
       "        1.61456153e-01,  3.94612193e-01,  8.85783583e-02,  2.40580857e-01,\n",
       "       -2.59242184e-03, -3.16258460e-01, -2.44215056e-01,  3.14837635e-01,\n",
       "       -1.19753405e-01,  2.73649432e-02, -1.63026467e-01, -1.62029341e-02,\n",
       "       -3.58390175e-02,  3.33115458e-01,  5.83249509e-01, -2.79058278e-01,\n",
       "        4.58128482e-01,  4.30684894e-01, -9.04698372e-02, -9.46645811e-02,\n",
       "       -4.69529629e-02,  1.82061538e-01,  1.93517879e-01, -5.74657433e-02,\n",
       "        5.64569905e-02,  6.01405799e-02, -2.71578550e-01,  3.31836641e-02,\n",
       "       -2.93490320e-01,  8.48192647e-02,  1.16654970e-01, -3.32128964e-02,\n",
       "       -9.28956419e-02,  8.89663324e-02,  4.50681895e-03, -1.12345457e-01,\n",
       "        2.86367029e-01, -4.58183020e-01,  2.24826097e-01, -1.59531206e-01,\n",
       "       -3.91896069e-02, -4.82417732e-01,  2.00283840e-01,  5.05793765e-02,\n",
       "       -7.37685412e-02, -2.89325342e-02,  5.19142114e-02,  2.53143936e-01,\n",
       "       -1.18403316e-01, -3.78581790e-05, -1.42470875e-03,  8.79565403e-02,\n",
       "       -1.54602751e-01,  1.39947578e-01, -1.63175523e-01, -2.27565065e-01,\n",
       "        2.43593212e-02,  1.83513477e-01,  2.09395960e-01,  6.44850498e-03,\n",
       "       -1.67488828e-01,  2.13646874e-01, -9.41734239e-02, -1.58160273e-02,\n",
       "       -8.20813030e-02, -1.83308542e-01,  2.60268122e-01, -5.81487060e-01,\n",
       "       -1.88392997e-01,  4.93148804e-01,  1.71536863e-01, -1.94943994e-01,\n",
       "       -2.98341885e-02, -1.10752098e-01,  1.75626159e-01, -2.15448767e-01,\n",
       "        3.90823662e-01, -4.05653584e-04,  1.63337633e-01, -1.30663574e-01,\n",
       "       -1.60531923e-01, -1.78250387e-01,  1.44646183e-01, -5.53424470e-02,\n",
       "       -2.84335196e-01, -2.52671540e-01, -2.86735028e-01,  7.28117898e-02,\n",
       "        1.01622291e-01,  2.40730360e-01,  2.70242900e-01, -2.02046037e-01,\n",
       "        3.18083584e-01,  2.44049832e-01, -1.42584518e-01,  8.29213336e-02,\n",
       "        4.85366620e-02,  2.96781361e-01,  4.12520528e-01, -3.14378828e-01,\n",
       "       -1.16970047e-01,  6.29203022e-02,  7.08070546e-02,  2.58253574e-01,\n",
       "       -1.14308326e-02,  4.45277423e-01,  1.21435836e-01, -1.32654235e-01,\n",
       "       -7.34771490e-02,  1.45819008e-01,  8.71957168e-02,  3.29194218e-02,\n",
       "       -1.06550090e-01,  1.32414714e-01,  5.37193939e-02,  1.55813500e-01,\n",
       "       -3.02492045e-02, -1.43763840e-01, -2.87022501e-01,  2.91071653e-01,\n",
       "        1.64530054e-01, -1.11769669e-01,  2.36827210e-01, -3.21419209e-01,\n",
       "       -1.66114420e-01, -1.28119681e-02,  3.42823088e-01, -1.29733726e-01,\n",
       "       -8.64384547e-02,  8.01282004e-02,  2.09743306e-01, -1.31370753e-01,\n",
       "       -4.56719965e-01, -2.07562461e-01,  2.11608663e-01, -1.06123202e-01,\n",
       "       -7.91288912e-02, -1.07585587e-01, -3.71915519e-01, -7.27089718e-02,\n",
       "       -1.18880950e-01, -8.83411691e-02, -1.14617441e-02, -1.38135478e-01,\n",
       "       -2.01837182e-01, -4.67054769e-02, -9.99320671e-02, -2.49767497e-01,\n",
       "        2.34003976e-01, -3.08610618e-01,  5.94544411e-02, -1.53505117e-01,\n",
       "        2.65017509e-01,  3.01973661e-03, -1.05429024e-01,  1.93159610e-01,\n",
       "        3.11239898e-01,  3.94330204e-01, -1.93251409e-02,  4.99086767e-01,\n",
       "        1.55236805e-02, -1.99357539e-01,  5.28639473e-04,  4.31942075e-01,\n",
       "        7.14836037e-03, -1.23075821e-01,  8.09212588e-03, -1.80045828e-01,\n",
       "        6.30232133e-03, -3.00479792e-02, -3.72296929e-01,  1.83589846e-01,\n",
       "        2.57175654e-01, -1.55412167e-01,  1.24235503e-01,  1.37525395e-01,\n",
       "       -1.35490865e-01,  3.29676084e-02, -9.26109552e-02, -5.65365136e-01,\n",
       "        2.80105211e-02, -2.07514241e-02, -1.69507459e-01, -2.20879570e-01,\n",
       "       -2.19279274e-01, -2.83492416e-01, -4.83235836e-01, -3.42599422e-01,\n",
       "       -9.17720199e-02,  2.96830446e-01, -5.98628353e-03,  6.14563860e-02,\n",
       "       -1.05392344e-01,  1.58028498e-01,  4.33736555e-02,  2.40767330e-01,\n",
       "       -3.02058876e-01, -2.03180507e-01,  3.31530154e-01, -3.77642214e-01,\n",
       "       -2.81263500e-01,  1.91836253e-01, -1.27187893e-01,  1.78842068e-01,\n",
       "       -2.64506459e-01,  1.23102181e-02, -1.61026716e-01,  1.34970218e-01,\n",
       "       -8.89988691e-02, -4.67516296e-02,  4.90023911e-01,  7.38458410e-02,\n",
       "       -1.30986854e-01, -3.05826992e-01, -1.67545572e-01,  1.94467992e-01,\n",
       "        1.63925245e-01,  1.95639223e-01,  2.50460088e-01, -4.28530991e-01,\n",
       "        3.45157646e-03, -2.58735716e-01,  5.29080987e-01, -3.74270082e-01,\n",
       "        1.52395874e-01, -1.04267634e-01,  5.28327897e-02,  6.97042271e-02,\n",
       "        3.10416430e-01,  1.34908870e-01, -1.46409914e-01,  8.79694968e-02,\n",
       "       -2.16057554e-01, -5.98206883e-03,  1.46351457e-01,  1.00754961e-01,\n",
       "       -3.56721640e-01,  2.37128824e-01, -2.08308369e-01, -1.37767941e-01,\n",
       "        1.87475309e-01, -1.37022287e-01,  1.79654717e-01,  9.50281098e-02,\n",
       "        3.05513024e-01, -2.35129194e-03, -5.99395745e-02,  3.43031436e-01,\n",
       "        2.22358525e-01,  3.86910826e-01, -4.61394712e-02, -5.23233116e-01,\n",
       "       -1.88939229e-01, -3.29891369e-02,  1.58315763e-01, -6.72142655e-02,\n",
       "        1.70431465e-01, -1.60779700e-01, -1.32888451e-01,  1.94981813e-01,\n",
       "       -7.49423355e-02,  1.33112490e-01, -3.46184261e-02, -3.98086198e-02,\n",
       "        1.55842796e-01,  7.61212111e-02,  6.12084121e-02,  1.30054295e-01,\n",
       "       -4.20598775e-01, -8.50358531e-02,  7.93767571e-02,  1.17576607e-01,\n",
       "        1.19344229e-02, -8.69084708e-03,  1.18011601e-01, -3.85569453e-01,\n",
       "       -1.99203864e-01,  3.17576230e-01,  6.12187423e-02, -1.49612010e-01,\n",
       "       -8.59778225e-02, -3.21717486e-02,  1.85915425e-01, -1.35080591e-01,\n",
       "        3.26779962e-01,  1.11499630e-01,  2.00124979e-01, -1.81169987e-01,\n",
       "        9.46175028e-03,  2.59241760e-01, -8.62892270e-02,  1.24217950e-01,\n",
       "       -2.26192176e-01,  1.87308654e-01, -6.76105320e-02,  1.09886616e-01,\n",
       "        7.81963542e-02,  1.59898788e-01,  4.34805155e-02,  3.77582192e-01,\n",
       "        2.00295318e-02,  3.12313259e-01,  3.17892283e-01,  3.18764038e-02,\n",
       "        1.84716970e-01,  1.02976814e-01, -1.29831247e-02, -5.33965945e-01,\n",
       "       -4.15449170e-03, -9.74933580e-02,  2.92788357e-01, -1.68568827e-02,\n",
       "       -3.65061492e-01,  2.62162954e-01, -1.99976221e-01, -1.79652423e-01,\n",
       "       -6.74350783e-02, -7.36466050e-02,  7.99735077e-03, -8.52292180e-02,\n",
       "        3.02016109e-01,  7.65381873e-01,  1.86538070e-01,  9.91610214e-02,\n",
       "       -3.15703489e-02, -2.39601493e-01,  3.49765569e-01, -3.79434586e-01,\n",
       "        4.37371463e-01, -3.03044915e-01,  3.50981392e-02, -1.36658363e-02,\n",
       "       -3.92119922e-02,  1.74251080e-01,  2.19215870e-01,  3.65047865e-02,\n",
       "        1.70673192e-01,  1.96939513e-01, -1.31071225e-01, -4.28889804e-02,\n",
       "        1.75453350e-01, -4.72445823e-02,  6.98638707e-02,  3.11694294e-02,\n",
       "        3.22514057e-01,  4.49009240e-01,  1.86776459e-01, -1.16198212e-02,\n",
       "       -1.47021309e-01, -2.00406462e-01,  7.67491460e-02, -1.27667755e-01,\n",
       "       -6.29129484e-02, -4.80404019e-01,  1.54105470e-01, -9.61345807e-02,\n",
       "       -2.31545091e-01,  3.21784727e-02, -2.23328829e-01, -9.49444342e-03,\n",
       "        1.23602450e-01, -1.67446628e-01,  2.84746259e-01,  1.42774368e-02,\n",
       "       -2.71190912e-01, -3.30283642e-01,  3.32763910e-01,  1.96248457e-01,\n",
       "       -2.55561262e-01,  1.17187388e-01,  4.77881014e-01, -4.56433184e-02,\n",
       "       -1.86917484e-01, -2.67586440e-01,  1.55057460e-01,  4.42823023e-01,\n",
       "        3.23591769e-01,  2.25058839e-01,  4.15324569e-02, -2.00824827e-01,\n",
       "        1.77915275e-01,  3.05669248e-01,  2.31600389e-01, -3.19246769e-01,\n",
       "       -1.18139260e-01,  1.34351581e-01,  2.80499488e-01, -2.21151471e-01,\n",
       "        5.30993640e-02,  1.29903704e-01,  6.53694794e-02, -1.18017374e-02,\n",
       "        6.73177615e-02,  8.00406039e-02, -5.13182759e-01, -5.82337454e-02,\n",
       "        6.54618070e-02,  2.76209205e-01, -1.83693431e-02,  2.94542134e-01,\n",
       "       -3.07798862e-01,  1.83834136e-01,  1.59030899e-01,  4.07142013e-01,\n",
       "       -1.66562796e-01, -4.79783326e-01, -2.10012287e-01, -4.13606048e-01,\n",
       "        5.92363775e-02,  1.54404178e-01,  6.58277946e-04,  2.10360914e-01,\n",
       "        2.83089727e-01,  3.63211900e-01,  1.09330736e-01, -5.22614777e-01,\n",
       "       -1.22007132e-01,  1.48911718e-02,  8.16331431e-02,  9.79121178e-02,\n",
       "       -1.71466529e-01, -1.19786099e-01,  3.07113945e-01,  2.41553888e-01,\n",
       "        1.07853383e-01, -1.99582413e-01, -3.44078958e-01, -6.04019500e-02,\n",
       "        5.21589555e-02,  3.28598432e-02, -3.27344029e-03,  1.36293814e-01,\n",
       "       -3.81061547e-02, -2.55616337e-01,  1.35476336e-01, -2.36675933e-01,\n",
       "       -4.05685216e-01,  2.38533825e-01,  4.29498106e-02,  1.72241256e-02,\n",
       "       -2.48770982e-01, -5.33274673e-02, -3.07872538e-02,  5.81806749e-02,\n",
       "       -1.23233400e-01,  2.18564849e-02,  2.29185998e-01,  9.34011936e-02,\n",
       "       -2.54486740e-01, -1.76821023e-01,  1.78003624e-01, -1.88909963e-01,\n",
       "       -2.32188895e-01,  1.38992369e-01,  8.63837004e-02,  1.66123450e-01,\n",
       "       -1.26168042e-01,  4.47001457e-02, -2.57241167e-03,  9.59316716e-02,\n",
       "        1.70473695e-01,  4.11358997e-02,  3.73511076e-01, -2.45751202e-01,\n",
       "        8.69029164e-02, -3.60793531e-01, -1.35020092e-01,  2.28721783e-01,\n",
       "        5.50211556e-02,  2.56113350e-01, -2.00423226e-02,  1.00339249e-01,\n",
       "        2.35081837e-02, -5.19269891e-02,  1.96859062e-01, -3.61584331e-04,\n",
       "        3.07785809e-01, -1.46380305e-01,  9.31805372e-02,  1.40383616e-01,\n",
       "        1.81082040e-02, -1.38114646e-01,  4.64576036e-02,  5.93978502e-02,\n",
       "        4.88917083e-02,  2.51312286e-01, -8.47730488e-02,  7.51707852e-02,\n",
       "        1.41398963e-02,  3.21199179e-01,  1.87376663e-01,  3.38847637e-01,\n",
       "        1.51104882e-01,  3.21048468e-01,  1.62717327e-01, -4.25226182e-01,\n",
       "       -3.60833198e-01,  4.96278405e-02,  1.51703060e-01, -2.27194399e-01,\n",
       "       -1.19753852e-01, -2.01471411e-02, -2.40546048e-01,  5.62720783e-02,\n",
       "        3.93153280e-02,  1.62902594e-01,  4.60218899e-02,  1.69598982e-01,\n",
       "       -1.60548344e-01, -2.60229339e-03, -9.23943892e-02, -4.32310075e-01,\n",
       "        9.29703489e-02,  3.15057337e-01,  1.51553424e-02,  4.36365977e-02,\n",
       "       -2.50602573e-01, -8.28461647e-02,  1.22858964e-01,  3.40400226e-02,\n",
       "        1.75263077e-01, -1.60563752e-01, -3.39264154e-01,  8.57212469e-02,\n",
       "        7.73875937e-02, -1.93213969e-01,  1.34666383e-01,  3.19171953e-03,\n",
       "        2.99942225e-01, -2.12176647e-02,  1.68446288e-01,  3.32506180e-01,\n",
       "       -2.90306926e-01, -2.65653003e-02,  1.57835707e-01, -1.45968214e-01,\n",
       "        1.02217034e-01, -3.66670936e-01, -1.05406441e-01,  8.61350894e-02,\n",
       "       -2.02301562e-01,  3.80774029e-02, -1.82997420e-01, -1.71337619e-01,\n",
       "       -1.67107940e-01, -4.81708080e-01, -3.76031473e-02, -2.37805232e-01,\n",
       "        1.88101411e-01, -5.88411167e-02,  5.97653806e-01,  2.54528642e-01,\n",
       "        3.43908668e-02,  3.61726992e-02, -3.01713318e-01, -3.13887030e-01,\n",
       "       -2.44418848e-02,  3.54958177e-02, -1.56710401e-01, -3.16900879e-01,\n",
       "        2.10860781e-02,  2.57124811e-01,  4.08265144e-01,  1.50323123e-01,\n",
       "       -6.00392697e-03, -1.62305713e-01,  3.02282065e-01, -2.29149401e-01,\n",
       "        1.85533553e-01,  9.38914269e-02,  4.12929766e-02, -1.50900915e-01,\n",
       "       -1.33867145e-01,  2.03005984e-01, -2.04596579e-01,  3.01504314e-01,\n",
       "        2.38587230e-01,  6.47759959e-02,  1.75633088e-01,  2.81314284e-01,\n",
       "        1.58511728e-01,  2.10842025e-03,  3.89198929e-01, -2.64083624e-01,\n",
       "       -2.38809317e-01,  2.06713200e-01,  1.16575725e-01, -1.77012801e-01,\n",
       "       -2.77638156e-02,  1.83659017e-01,  2.25405917e-01, -8.78798813e-02,\n",
       "       -1.43584803e-01,  2.10636675e-01,  1.69541121e-01, -5.85013244e-04,\n",
       "       -3.66569944e-02, -3.57495815e-01,  2.06115067e-01, -1.50764853e-01,\n",
       "       -8.18620622e-02,  3.86621356e-02,  1.66414917e-01,  1.40702883e-02,\n",
       "       -2.76515484e-01, -1.28965557e-01, -6.98803812e-02,  2.13923350e-01,\n",
       "       -2.81380713e-01, -3.66245098e-02, -1.43628970e-01,  6.90277517e-02,\n",
       "       -7.71772638e-02,  1.96926981e-01, -2.78328627e-01, -4.52038832e-02,\n",
       "       -1.19244650e-01, -3.84129494e-01,  8.88783112e-02,  4.29855824e-01,\n",
       "        2.08253011e-01, -3.37734938e-01, -2.85533667e-01,  9.70599577e-02,\n",
       "        2.04244569e-01, -6.10274412e-02, -1.66054487e-01, -2.67020494e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61759b3-1a59-48c5-8860-4bc9e98f2f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.515997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v_orig = embedding_model.encode(df.iloc[0].answer_orig)\n",
    "\n",
    "v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a656daf-e432-4b3c-b54a-a9c82cfd89b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q2. Computing the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ddc5a0e-9ba0-4753-8bbb-f7eadee974e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_llm': 'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Where can I sign up for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can sign up using the link provided in the course GitHub repository: [https://airtable.com/shryxwLd0COOEaqXo](https://airtable.com/shryxwLd0COOEaqXo).',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Can you provide a link to sign up?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is an FAQ for the Machine Learning course. It addresses frequently asked technical questions and is available in the course GitHub repository. You can find the link to the FAQ [here](https://airtable.com/shryxwLd0COOEaqXo).',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Is there an FAQ for this Machine Learning course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The context does not provide any specific information about a GitHub repository for the sign-up link for the course. Therefore, I cannot confirm whether or not such a repository exists.',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Does this course have a GitHub repository for the sign-up link?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To structure your questions and answers for the course effectively, consider the following steps:\\n\\n1. **Identify Your Topic**: Start by clearly defining the topic your question addresses. This helps in organizing related questions together.\\n\\n2. **Be Specific**: Formulate your question to be specific and concise. This makes it easier for others to understand what information you're seeking.\\n\\n3. **Provide Context**: If your question arises from a particular scenario or issue, briefly explain that context so that it can be better understood.\\n\\n4. **Refer to Course Materials**: When formulating answers, reference course materials, such as course pages or specific modules, to provide a clear and credible response.\\n\\n5. **Consider Audience**: Keep in mind who will be reading your questions and answers. Make sure the language and complexity match their understanding level.\\n\\n6. **Format for Clarity**: Use bullet points or numbered lists for answers to enhance clarity and readability.\\n\\n7. **Incorporate Feedback Loop**: Encourage readers to ask follow-up questions or provide feedback on the answers if clarity is lacking.\\n\\nBy structuring your questions and answers this way, you can ensure they are clear, relevant, and beneficial to others in the course.\",\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'How can I structure my questions and answers for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The course videos are pre-recorded, and you can start watching them right now.',\n",
       "  'answer_orig': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'document': '39fda9f0',\n",
       "  'question': 'Are the course videos live or pre-recorded?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can start watching the course videos right now, as they are pre-recorded. If you haven’t taken part in the previous iteration, you are encouraged to begin watching them.',\n",
       "  'answer_orig': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'document': '39fda9f0',\n",
       "  'question': 'When can I start watching the course videos?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the live office hours sessions are recorded.',\n",
       "  'answer_orig': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'document': '39fda9f0',\n",
       "  'question': 'Are the live office hours sessions recorded?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find the office hours sessions in the course playlist on YouTube, where both the live office hours and the pre-recorded course videos are available.',\n",
       "  'answer_orig': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'document': '39fda9f0',\n",
       "  'question': 'Where can I find the office hours sessions?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can access the pre-recorded course videos on the course page at http://mlzoomcamp.com/. You can also find them in the course playlist on YouTube by visiting the DTC YouTube channel and searching for the relevant course playlist.',\n",
       "  'answer_orig': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'document': '39fda9f0',\n",
       "  'question': 'Where can I access the pre-recorded course videos?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, all sessions are recorded, so if you miss one, you won't miss anything. You can catch up on the content later. Additionally, you can submit your questions in advance for office hours, and those sessions are also recorded.\",\n",
       "  'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'document': '5170565b',\n",
       "  'question': 'Are sessions recorded if I miss one?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you can ask your questions in advance if you can't attend a live stream. You can submit your questions for office hours ahead of time, and they will be covered during the live session. Additionally, you can always ask questions in Slack.\",\n",
       "  'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'document': '5170565b',\n",
       "  'question': \"Can I ask questions in advance if I can't attend a live stream?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you miss a session, don't worry! Everything is recorded, so you won’t miss anything. You can also ask your questions for office hours in advance, and they will be covered during the live stream. Additionally, you can always ask questions in Slack.\",\n",
       "  'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'document': '5170565b',\n",
       "  'question': 'How will my questions be addressed if I miss a session?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is a way to catch up on a missed session. Everything is recorded, so you won’t miss anything. You can also ask your questions for office hours in advance, and they will be covered during the live stream. Additionally, you can always ask questions in Slack.',\n",
       "  'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'document': '5170565b',\n",
       "  'question': 'Is there a way to catch up on a missed session?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can still interact with instructors after missing a session. Everything is recorded, so you won’t miss any content. You can ask your questions in advance for office hours, and those questions will be covered during the live stream. Additionally, you can always ask questions in Slack.',\n",
       "  'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'document': '5170565b',\n",
       "  'question': 'Can I still interact with instructors after missing a session?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The course will cover the bare minimum of theory, focusing more on practical application. The theory will be addressed on an intuitive level, meaning specific derivations, such as the gradient update rule for logistic regression, will not be covered in depth. Instead, the course will teach how to use logistic regression and interpret the results.',\n",
       "  'answer_orig': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\",\n",
       "  'document': 'ecca790c',\n",
       "  'question': 'How much theoretical content is there in the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, the course will not cover theoretical derivations like the gradient update rule for logistic regression. The focus is more on practical applications, and the theory will only be covered at an intuitive level.',\n",
       "  'answer_orig': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\",\n",
       "  'document': 'ecca790c',\n",
       "  'question': 'Will the course cover theoretical derivations like the gradient update rule for logistic regression?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The focus of the course is more on practice rather than theory. The course will cover only the bare minimum of theory, primarily on an intuitive level, while emphasizing practical applications and skills.',\n",
       "  'answer_orig': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\",\n",
       "  'document': 'ecca790c',\n",
       "  'question': 'Is the focus of the course more on practice or theory?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To find more about the theoretical topics not covered in this course, consider looking for other great courses that delve deeper into those areas. The course itself focuses primarily on practical applications and covers theoretical concepts only at an intuitive level.',\n",
       "  'answer_orig': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\",\n",
       "  'document': 'ecca790c',\n",
       "  'question': 'Where can I find more about the theoretical topics not covered in this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the course will help you understand how to use logistic regression and interpret its results, although it will cover the theory only at an intuitive level. The course focuses more on practical applications rather than in-depth theoretical derivations.',\n",
       "  'answer_orig': \"The bare minimum. The focus is more on practice, and we'll cover the theory only on the intuitive level.: https://mlbookcamp.com/article/python\\nFor example, we won't derive the gradient update rule for logistic regression (there are other great courses for that), but we'll cover how to use logistic regression and make sense of the results.\",\n",
       "  'document': 'ecca790c',\n",
       "  'question': 'Will the course help me understand how to use logistic regression and interpret its results?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No prior knowledge in math is necessary for this course. While some linear algebra will be covered, the course will primarily focus on code with very few formulas.',\n",
       "  'answer_orig': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'c25b3de4',\n",
       "  'question': 'Is prior knowledge in math necessary for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The course will cover some linear algebra, but there will be very few formulas involved, focusing mostly on code instead.',\n",
       "  'answer_orig': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'c25b3de4',\n",
       "  'question': 'What type of mathematical content will be covered?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there are resources available to help with linear algebra. You can watch the \"ML Zoomcamp 1.8 - Linear Algebra Refresher\" from Alexey Grigorev and the \"Essence of Linear Algebra\" playlist from 3Blue1Brown. Additionally, you can ask the community for help if you have any questions.',\n",
       "  'answer_orig': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'c25b3de4',\n",
       "  'question': 'Are there resources available to help with linear algebra?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can seek help from the community for math-related questions.',\n",
       "  'answer_orig': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'c25b3de4',\n",
       "  'question': 'Can I seek help from the community for math-related questions?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there are recommended videos for learning linear algebra. You can watch \"ML Zoomcamp 1.8 - Linear Algebra Refresher\" by Alexey Grigorev, or you can check out the excellent playlist from 3Blue1Brown titled \"Vectors | Chapter 1, Essence of Linear Algebra.\"',\n",
       "  'answer_orig': \"Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\\nHere are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'c25b3de4',\n",
       "  'question': 'Are there any recommended videos for learning linear algebra?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you haven't received a confirmation email after filling out the form, it is normal to experience a delay as the process is automated. You should eventually receive the email. In the meantime, check your promotions tab in Gmail as well as your spam folder. If you unsubscribed from the newsletter, you won't receive course-related updates. To ensure you don’t miss any important information, consider joining the #course-ml-zoomcamp channel in Slack and the telegram channel with announcements.\",\n",
       "  'answer_orig': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'document': '6ba259b1',\n",
       "  'question': \"What should I do if I haven't received a confirmation email after filling out the form?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, it is possible that your confirmation email went to your spam folder. If you haven't received it, it's recommended to check your promotions tab in Gmail as well as your spam folder.\",\n",
       "  'answer_orig': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'document': '6ba259b1',\n",
       "  'question': 'Is it possible my confirmation email went to my spam folder?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, unsubscribing from the newsletter will affect your receipt of course-related updates. If you unsubscribe, you won't receive those updates. However, you can join the #course-ml-zoomcamp channel in Slack and the telegram channel with announcements to stay informed about the course.\",\n",
       "  'answer_orig': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'document': '6ba259b1',\n",
       "  'question': 'Can unsubscribing from the newsletter affect receiving course updates?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you don't receive the confirmation email, check your promotions tab in Gmail as well as your spam folder. If you unsubscribed from the newsletter, you won't receive course-related updates. To ensure you don’t miss any updates, join the #course-ml-zoomcamp channel in Slack and the telegram channel with announcements. This will keep you informed about the course.\",\n",
       "  'answer_orig': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'document': '6ba259b1',\n",
       "  'question': 'Where can I get course updates if I don’t receive the confirmation email?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you're having email issues, you can stay informed about the course by joining the #course-ml-zoomcamp channel in Slack and the Telegram channel with announcements. This will ensure you don’t miss any important updates regarding the course.\",\n",
       "  'answer_orig': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'document': '6ba259b1',\n",
       "  'question': \"How can I stay informed about the course if I'm having email issues?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The duration of the course is approximately 4 months, but it may take longer if you choose to engage in extra activities such as an additional project or article.',\n",
       "  'answer_orig': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)',\n",
       "  'document': '67e2fd13',\n",
       "  'question': 'What is the duration of the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The course takes approximately 4 months, but it may take more time if you choose to participate in extra activities such as an extra project or an article.',\n",
       "  'answer_orig': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)',\n",
       "  'document': '67e2fd13',\n",
       "  'question': 'How many months does the course take?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the course can take more than 4 months if you choose to engage in extra activities such as an additional project or article.',\n",
       "  'answer_orig': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)',\n",
       "  'document': '67e2fd13',\n",
       "  'question': 'Can the course take more than 4 months?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Based on the context, the course duration is approximately 4 months, but it may take longer if you choose to engage in extra activities, such as additional projects or articles. There is no specific mention of a formal process for extending the course duration itself, but the self-paced mode allows you to go through the materials at your own speed.',\n",
       "  'answer_orig': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)',\n",
       "  'document': '67e2fd13',\n",
       "  'question': 'Is it possible to extend the course duration?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Extra activities that might extend the course time include undertaking an extra project or writing an article.',\n",
       "  'answer_orig': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)',\n",
       "  'document': '67e2fd13',\n",
       "  'question': 'What extra activities might extend the course time?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You should allocate around ~10 hours per week for this course.',\n",
       "  'answer_orig': 'Around ~10 hours per week. Timur Kamaliev did a detailed analysis of how much time students of the previous cohort needed to spend on different modules and projects. Full article',\n",
       "  'document': 'a6897e8c',\n",
       "  'question': 'How many hours per week should I allocate for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The time needed for different modules was analyzed by Timur Kamaliev.',\n",
       "  'answer_orig': 'Around ~10 hours per week. Timur Kamaliev did a detailed analysis of how much time students of the previous cohort needed to spend on different modules and projects. Full article',\n",
       "  'document': 'a6897e8c',\n",
       "  'question': 'Who analyzed the time needed for different modules?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Students of the previous cohort spent around ~10 hours per week on the course.',\n",
       "  'answer_orig': 'Around ~10 hours per week. Timur Kamaliev did a detailed analysis of how much time students of the previous cohort needed to spend on different modules and projects. Full article',\n",
       "  'document': 'a6897e8c',\n",
       "  'question': 'How much time did students of the previous cohort spend weekly?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The estimated weekly time commitment for the course is around 10 hours per week.',\n",
       "  'answer_orig': 'Around ~10 hours per week. Timur Kamaliev did a detailed analysis of how much time students of the previous cohort needed to spend on different modules and projects. Full article',\n",
       "  'document': 'a6897e8c',\n",
       "  'question': 'Can you give an estimated weekly time commitment for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find the detailed analysis of study time requirements conducted by Timur Kamaliev in a full article that outlines how much time students of the previous cohort needed to spend on different modules and projects.',\n",
       "  'answer_orig': 'Around ~10 hours per week. Timur Kamaliev did a detailed analysis of how much time students of the previous cohort needed to spend on different modules and projects. Full article',\n",
       "  'document': 'a6897e8c',\n",
       "  'question': 'Where can I find the detailed analysis of study time requirements?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To earn a certificate in this course, you need to submit at least 2 out of 3 course projects and review 3 peers’ projects by the deadline. If you successfully meet these requirements, you will receive a certificate.',\n",
       "  'answer_orig': 'Yes, if you finish at least 2 out of 3 projects and review 3 peers’ Projects by the deadline, you will get a certificate. This is what it looks like: link. There’s also a version without a robot: link.',\n",
       "  'document': '2eba08e3',\n",
       "  'question': 'How can I earn a certificate in this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To receive a certificate, you need to submit at least 2 out of the 3 course projects and peer-review at least 3 projects from your course-mates for each submission by the deadline.',\n",
       "  'answer_orig': 'Yes, if you finish at least 2 out of 3 projects and review 3 peers’ Projects by the deadline, you will get a certificate. This is what it looks like: link. There’s also a version without a robot: link.',\n",
       "  'document': '2eba08e3',\n",
       "  'question': 'What are the requirements to receive a certificate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, you do not need to complete all projects to get a certificate. You only need to submit at least 2 out of 3 projects and review 3 peers’ projects by the deadline.',\n",
       "  'answer_orig': 'Yes, if you finish at least 2 out of 3 projects and review 3 peers’ Projects by the deadline, you will get a certificate. This is what it looks like: link. There’s also a version without a robot: link.',\n",
       "  'document': '2eba08e3',\n",
       "  'question': 'Do I need to complete all projects to get a certificate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The deadline to qualify for the certificate is based on when you need to submit 2 out of 3 course projects and review 3 peers’ projects. Specific deadline dates can be found on the 2023 cohort page.',\n",
       "  'answer_orig': 'Yes, if you finish at least 2 out of 3 projects and review 3 peers’ Projects by the deadline, you will get a certificate. This is what it looks like: link. There’s also a version without a robot: link.',\n",
       "  'document': '2eba08e3',\n",
       "  'question': 'What is the deadline to qualify for the certificate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is an option for a certificate without a robot image.',\n",
       "  'answer_orig': 'Yes, if you finish at least 2 out of 3 projects and review 3 peers’ Projects by the deadline, you will get a certificate. This is what it looks like: link. There’s also a version without a robot: link.',\n",
       "  'document': '2eba08e3',\n",
       "  'question': 'Is there an option for a certificate without a robot image?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you could still receive a certificate even if you don't complete the midterm project, as long as you finish at least 2 out of 3 projects and review 3 peers' projects by the deadline.\",\n",
       "  'answer_orig': \"Yes, it's possible. See the previous answer.\",\n",
       "  'document': '1d644223',\n",
       "  'question': \"Will I receive a certificate if I don't complete the midterm project?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, it is possible to graduate without submitting the midterm project, as you can still receive a certificate by completing at least 2 out of 3 projects and reviewing 3 peers’ projects by the deadline.',\n",
       "  'answer_orig': \"Yes, it's possible. See the previous answer.\",\n",
       "  'document': '1d644223',\n",
       "  'question': 'Can I still graduate without submitting the midterm project?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you may still be eligible for certification if you missed the midterm project. As long as you complete at least 2 out of the 3 projects and review 3 peers’ projects by the deadline, you will receive a certificate.',\n",
       "  'answer_orig': \"Yes, it's possible. See the previous answer.\",\n",
       "  'document': '1d644223',\n",
       "  'question': 'Am I eligible for certification if I missed the midterm project?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, it is not mandatory to complete the midterm project for the certificate. You can receive a certificate by submitting at least 2 out of the 3 course projects and reviewing 3 peers’ projects by the deadline.',\n",
       "  'answer_orig': \"Yes, it's possible. See the previous answer.\",\n",
       "  'document': '1d644223',\n",
       "  'question': 'Is it mandatory to complete the midterm project for the certificate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, missing the midterm project does not affect your certification eligibility as long as you submit at least two out of three projects and complete the peer reviews required. According to the course coordinator, only two projects are needed to obtain the course certificate.',\n",
       "  'answer_orig': \"Yes, it's possible. See the previous answer.\",\n",
       "  'document': '1d644223',\n",
       "  'question': 'Does missing the midterm project affect my certification eligibility?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To participate in this course, you should have a basic understanding of Python, specifically the following skills:\\n\\n1. How to run a Jupyter notebook.\\n2. How to import libraries and an understanding of what libraries are.\\n3. How to declare a variable and what variables are.\\n4. Important operations related to data analysis.\\n\\nIf you are familiar with these topics, you know enough Python for the course. If not, it is recommended that you review these basics before enrolling. You can also take the free course \"Learn Python Basics for Data Analysis\" on the OpenClassrooms e-learning platform to help you prepare.',\n",
       "  'answer_orig': 'Check this article. If you know everything in this article, you know enough. If you don’t, read the article and join the coursIntroduction to Pythone too :)\\nIntroduction to Python – Machine Learning Bookcamp\\nYou can follow this English course from the OpenClassrooms e-learning platform, which is free and covers the python basics for data analysis: Learn Python Basics for Data Analysis - OpenClassrooms . It is important to know some basics such as: how to run a Jupyter notebook, how to import libraries (and what libraries are), how to declare a variable (and what variables are) and some important operations regarding data analysis.\\n(Mélanie Fouesnard)',\n",
       "  'document': '14890cd2',\n",
       "  'question': 'What Python basics are required for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can learn the necessary Python knowledge for this course by reading an article that outlines the required Python skills. If you know everything in that article, you are prepared for the course. If not, it\\'s recommended that you read the article and also consider joining the \"Introduction to Python\" course. Additionally, you can follow a free English course on the OpenClassrooms e-learning platform titled \"Learn Python Basics for Data Analysis,\" which covers the Python basics essential for data analysis, such as running a Jupyter notebook, importing libraries, declaring variables, and performing important data analysis operations.',\n",
       "  'answer_orig': 'Check this article. If you know everything in this article, you know enough. If you don’t, read the article and join the coursIntroduction to Pythone too :)\\nIntroduction to Python – Machine Learning Bookcamp\\nYou can follow this English course from the OpenClassrooms e-learning platform, which is free and covers the python basics for data analysis: Learn Python Basics for Data Analysis - OpenClassrooms . It is important to know some basics such as: how to run a Jupyter notebook, how to import libraries (and what libraries are), how to declare a variable (and what variables are) and some important operations regarding data analysis.\\n(Mélanie Fouesnard)',\n",
       "  'document': '14890cd2',\n",
       "  'question': 'Where can I learn the necessary Python knowledge for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'It is important to know how to run a Jupyter notebook for this course because notebooks provide a user-friendly interface for developing and testing machine learning models. They allow for interactive coding, visualization of data, and step-by-step execution of code, which can simplify the training process compared to running scripts. Additionally, understanding how to navigate and execute commands in Jupyter notebooks is essential when working on projects that may require peer review, as seen with the need for a train.py file that complements the notebook for seamless collaboration.',\n",
       "  'answer_orig': 'Check this article. If you know everything in this article, you know enough. If you don’t, read the article and join the coursIntroduction to Pythone too :)\\nIntroduction to Python – Machine Learning Bookcamp\\nYou can follow this English course from the OpenClassrooms e-learning platform, which is free and covers the python basics for data analysis: Learn Python Basics for Data Analysis - OpenClassrooms . It is important to know some basics such as: how to run a Jupyter notebook, how to import libraries (and what libraries are), how to declare a variable (and what variables are) and some important operations regarding data analysis.\\n(Mélanie Fouesnard)',\n",
       "  'document': '14890cd2',\n",
       "  'question': 'Why is it important to know how to run a Jupyter notebook for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'For this course, you should know some basic operations regarding data analysis, including how to run a Jupyter notebook, how to import libraries and understand what libraries are, how to declare a variable and understand what variables are, and engage in important operations related to data analysis.',\n",
       "  'answer_orig': 'Check this article. If you know everything in this article, you know enough. If you don’t, read the article and join the coursIntroduction to Pythone too :)\\nIntroduction to Python – Machine Learning Bookcamp\\nYou can follow this English course from the OpenClassrooms e-learning platform, which is free and covers the python basics for data analysis: Learn Python Basics for Data Analysis - OpenClassrooms . It is important to know some basics such as: how to run a Jupyter notebook, how to import libraries (and what libraries are), how to declare a variable (and what variables are) and some important operations regarding data analysis.\\n(Mélanie Fouesnard)',\n",
       "  'document': '14890cd2',\n",
       "  'question': 'What basic operations regarding data analysis should I know for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To learn how to declare variables in Python for this course, it\\'s recommended that you read the article mentioned in the FAQs. This article will provide the necessary information about basic Python knowledge, including how to declare a variable and what variables are. Additionally, you can follow the free English course, \"Learn Python Basics for Data Analysis,\" offered by OpenClassrooms, which covers Python basics that are essential for data analysis, including variable declaration.',\n",
       "  'answer_orig': 'Check this article. If you know everything in this article, you know enough. If you don’t, read the article and join the coursIntroduction to Pythone too :)\\nIntroduction to Python – Machine Learning Bookcamp\\nYou can follow this English course from the OpenClassrooms e-learning platform, which is free and covers the python basics for data analysis: Learn Python Basics for Data Analysis - OpenClassrooms . It is important to know some basics such as: how to run a Jupyter notebook, how to import libraries (and what libraries are), how to declare a variable (and what variables are) and some important operations regarding data analysis.\\n(Mélanie Fouesnard)',\n",
       "  'document': '14890cd2',\n",
       "  'question': 'How can I learn to declare variables in Python for this course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'For the course, all you need is a working laptop with an internet connection for the Machine Learning part. The Deep Learning part is more resource-intensive, but you can use a cloud service (Saturn Cloud is recommended, but others can be used as well).',\n",
       "  'answer_orig': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)',\n",
       "  'document': 'a4fad482',\n",
       "  'question': 'Are there any specific hardware requirements for the course, or is everything mainly based on cloud services?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, for the Machine Learning section, you just need a working laptop with an internet connection.',\n",
       "  'answer_orig': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)',\n",
       "  'document': 'a4fad482',\n",
       "  'question': 'Do I just need a laptop and internet for the Machine Learning section?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the Deep Learning part of the course is more resource-intensive than the Machine Learning part. While a working laptop with an internet connection is sufficient for the Machine Learning part, the Deep Learning part requires more resources, for which you can use cloud services (the course uses Saturn cloud but other options are available).',\n",
       "  'answer_orig': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)',\n",
       "  'document': 'a4fad482',\n",
       "  'question': 'Is the Deep Learning part of the course more resource-intensive than the Machine Learning part?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, Saturn Cloud can be used for the Deep Learning part of the course. While the Deep Learning section is more resource-intensive, you can utilize Saturn Cloud or any other cloud service for these tasks.',\n",
       "  'answer_orig': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)',\n",
       "  'document': 'a4fad482',\n",
       "  'question': 'Can Saturn Cloud be used for the Deep Learning part of the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, it is possible to use a cloud service other than Saturn Cloud for the Deep Learning section. While Saturn Cloud is used in the course, any other cloud service can be utilized as well.',\n",
       "  'answer_orig': 'For the Machine Learning part, all you need is a working laptop with an internet connection. The Deep Learning part is more resource intensive, but for that you can use a cloud (we use Saturn cloud but can be anything else).\\n(Rileen Sinha; based on response by Alexey on Slack)',\n",
       "  'document': 'a4fad482',\n",
       "  'question': 'Is it possible to use a cloud service other than Saturn Cloud for the Deep Learning section?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find instructions to install TensorFlow GPU on Ubuntu by referring to this article: [https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/](https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/). Additionally, make sure to follow steps to install CUDA and cuDNN as they are necessary for GPU support.',\n",
       "  'answer_orig': 'Here is an article that worked for me: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/',\n",
       "  'document': '34b7fd35',\n",
       "  'question': 'Where can I find instructions to install TensorFlow GPU on Ubuntu?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is a guide to set up TensorFlow with GPU support on Ubuntu. You can find an article that worked for someone here: [Setting up TensorFlow with GPU on Ubuntu](https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/). Additionally, you will need to install CUDA and cuDNN, and the context provides a simplified guide for that setup. Make sure to follow the installation instructions carefully to ensure proper functionality.',\n",
       "  'answer_orig': 'Here is an article that worked for me: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/',\n",
       "  'document': '34b7fd35',\n",
       "  'question': 'Is there a guide to set up TensorFlow with GPU on Ubuntu?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To configure GPU support for TensorFlow on your Ubuntu machine, you'll need to install CUDA and cuDNN. A simplified guide for installation can be helpful. Additionally, you may find an article that outlines the process useful: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/. Make sure to follow the steps for installing the appropriate NVIDIA drivers and setting up the TensorFlow environment tailored for GPU usage.\",\n",
       "  'answer_orig': 'Here is an article that worked for me: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/',\n",
       "  'document': '34b7fd35',\n",
       "  'question': 'How do I configure GPU support for TensorFlow on my Ubuntu machine?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can refer to the article linked here for guidance on setting up TensorFlow with GPU support on Ubuntu: [Setup TensorFlow with GPU support](https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/). This resource includes helpful steps for the installation process.',\n",
       "  'answer_orig': 'Here is an article that worked for me: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/',\n",
       "  'document': '34b7fd35',\n",
       "  'question': 'Can you direct me to a resource for installing TensorFlow with GPU on Ubuntu?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To set up TensorFlow with GPU support on Ubuntu, follow these general steps:\\n\\n1. **Install Nvidia Drivers**: You can download the necessary Nvidia drivers from the official Nvidia website: [Nvidia Drivers](https://www.nvidia.com/download/index.aspx).\\n\\n2. **Install CUDA Toolkit**: Download and install the CUDA toolkit (version 11.x.x) from the CUDA Toolkit Archive: [CUDA Toolkit Archive](https://developer.nvidia.com/cuda-toolkit-archive).\\n\\n3. **Install cuDNN**: Download and install cuDNN from the following link: [cuDNN Download](https://developer.nvidia.com/rdp/cudnn-download).\\n\\n4. **Install TensorFlow**: You have two options:\\n   - Install TensorFlow with GPU support through Anaconda by running: `conda install tensorflow-gpu`.\\n   - Alternatively, install TensorFlow using pip by following the instructions at the TensorFlow installation guide for Linux: [TensorFlow Installation](https://www.tensorflow.org/install/pip#linux_1).\\n\\n5. **Set Environment Variables**: Make sure to follow any specific instructions for setting environment variables as necessary.\\n\\nFor a detailed guide tailored to your needs, you can refer to this article: [Setting up TensorFlow GPU on Ubuntu](https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/).',\n",
       "  'answer_orig': 'Here is an article that worked for me: https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/',\n",
       "  'document': '34b7fd35',\n",
       "  'question': 'What is the procedure to set up TensorFlow GPU on Ubuntu?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To join a channel in Slack, follow these steps:\\n\\n1. Click “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\n2. Browse the list of public channels in your workspace or use the search bar to search by channel name or description.\\n3. Select a channel from the list to view it.\\n4. Click Join Channel.\\n\\nFor further details, you can visit the Slack help page: [Join a channel](https://slack.com/help/articles/205239967-Join-a-channel).\",\n",
       "  'answer_orig': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\",\n",
       "  'document': '4930aa19',\n",
       "  'question': 'How can I join a channel in Slack?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To find course channels on Slack, follow these steps:\\n\\n1. Go to the Slack workspace.\\n2. Click “All channels” at the top of your left sidebar. If you don’t see this option, click “More” to find it.\\n3. Browse the list of public channels or use the search bar to search by channel name or description.\\n4. Select the channel you want from the list to view it.\\n5. Click “Join Channel” to become a member. \\n\\nFor more detailed guidance, you can visit this link: https://slack.com/help/articles/205239967-Join-a-channel.',\n",
       "  'answer_orig': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\",\n",
       "  'document': '4930aa19',\n",
       "  'question': 'What steps should I follow to find course channels on Slack?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you need to provide the URL to your GitHub repository. The repository must be public so that whoever corrects the homework can access it.',\n",
       "  'answer_orig': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\",\n",
       "  'document': '4930aa19',\n",
       "  'question': 'Is there a need to give the URL to our GitHub repo?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You need to provide the GitHub URL for your homework by including the URL to your repository. This URL is required in order to receive a grade for your homework.',\n",
       "  'answer_orig': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\",\n",
       "  'document': '4930aa19',\n",
       "  'question': 'Where do I provide the GitHub URL for our homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To join a Slack channel, follow these steps:\\n\\n1. Click \"All channels\" at the top of your left sidebar. If you don\\'t see this option, click “More” to find it.\\n2. Browse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\n3. Select a channel from the list to view it.\\n4. Click \"Join Channel.\"\\n\\nFor more detailed instructions, you can visit this link: https://slack.com/help/articles/205239967-Join-a-channel.',\n",
       "  'answer_orig': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\",\n",
       "  'document': '4930aa19',\n",
       "  'question': 'Can you show me how to join a Slack channel?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you can still participate in the course if you join late. However, you won’t be able to submit some of the homeworks. To receive a certificate, you need to submit 2 out of 3 course projects and review 3 peers' projects by the deadline.\",\n",
       "  'answer_orig': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'document': 'ee58a693',\n",
       "  'question': 'If I join the course late, can I still participate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can still obtain a certificate if you join the course after it has started. As long as you submit 2 out of 3 course projects and review 3 peers’ projects by the deadline, you will be eligible for a certificate.',\n",
       "  'answer_orig': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'document': 'ee58a693',\n",
       "  'question': 'Will I be able to obtain a certificate if I join the course after it has started?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To be eligible for a certificate, you must submit 2 out of 3 course projects and review 3 peers’ projects by the deadline.',\n",
       "  'answer_orig': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'document': 'ee58a693',\n",
       "  'question': 'How many course projects must I submit to be eligible for a certificate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To receive a certificate, you are required to finish at least 2 out of 3 projects and review 3 peers' projects by the deadline.\",\n",
       "  'answer_orig': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'document': 'ee58a693',\n",
       "  'question': 'What is the requirement for peer reviews to get a certificate?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can join the course after it has started. However, you won’t be able to submit some of the homeworks. Homework is not mandatory for finishing the course, but to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline.',\n",
       "  'answer_orig': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'document': 'ee58a693',\n",
       "  'question': 'Can I submit homework if I join the course after it has started?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the course is available in a self-paced mode, allowing you to go through the materials at any time.',\n",
       "  'answer_orig': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       "  'document': '636f55d5',\n",
       "  'question': 'Is the course available in a self-paced mode?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can start the course anytime. The course is available in self-paced mode, allowing you to go through the materials at any time. If you prefer to do it with other students, the next cohort iterations will begin in September 2023 and September 2024.',\n",
       "  'answer_orig': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       "  'document': '636f55d5',\n",
       "  'question': 'Can I start the course anytime?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The next cohort will start in September 2023. Subsequent iterations are also expected to occur in September 2024 and potentially other Septembers as well.',\n",
       "  'answer_orig': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       "  'document': '636f55d5',\n",
       "  'question': 'When is the next cohort starting?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The course materials are available in self-paced mode, so you can go through them at any time. There are no set times for the course materials if you choose this option. If you prefer to progress with a cohort, the next iterations will occur in September 2023 and September 2024.',\n",
       "  'answer_orig': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       "  'document': '636f55d5',\n",
       "  'question': 'Are there set times for the course materials?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there will be iterations in future Septembers, specifically in September 2024 and potentially in other Septembers as well.',\n",
       "  'answer_orig': 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       "  'document': '636f55d5',\n",
       "  'question': 'Will there be iterations in future Septembers?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, you cannot submit your homework after the due date. The form closes after the due date, and late submissions will not be evaluated. However, homework is not mandatory for finishing the course.',\n",
       "  'answer_orig': 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       "  'document': 'c839b764',\n",
       "  'question': 'Can I send in my homework late?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, it is not feasible to submit homework after the deadline. The form is closed after the due date, and homework is not mandatory for finishing the course.',\n",
       "  'answer_orig': 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       "  'document': 'c839b764',\n",
       "  'question': 'Is it feasible to submit homework post deadline?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you miss the homework submission deadline, you will not be able to submit the homework as the form is closed after the due date. However, it's important to note that homework is not mandatory for finishing the course.\",\n",
       "  'answer_orig': 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       "  'document': 'c839b764',\n",
       "  'question': 'What happens if I miss the homework submission deadline?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, it’s not possible to submit homework after the due date. The form is closed after the due date. However, homework is not mandatory for finishing the course.',\n",
       "  'answer_orig': 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       "  'document': 'c839b764',\n",
       "  'question': 'After the due date, can homework still be submitted?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"No, late homework submissions are not accepted. Once the due date has passed, the submission form is closed, and you cannot submit your homework. However, it's worth noting that homework is not mandatory for completing the course.\",\n",
       "  'answer_orig': 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       "  'document': 'c839b764',\n",
       "  'question': 'Are late homework submissions accepted?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The initial step after joining the course is to go to the course page (http://mlzoomcamp.com/), scroll down, and start going through the course materials. Then, read everything in the cohort folder for your cohort’s year, and begin watching the videos and office hours from previous cohorts.',\n",
       "  'answer_orig': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'document': '0a278fb2',\n",
       "  'question': 'What is the initial step after joining the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To view the content of the course, go to the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/), scroll down, and start going through the course materials. Be sure to read everything in the cohort folder for your cohort’s year, click on the links, and start watching the videos. You can also access office hours from previous cohorts and check the DTC YouTube channel for playlists related to the course. Alternatively, you can use this link: [http://mlzoomcamp.com/#syllabus](http://mlzoomcamp.com/#syllabus).',\n",
       "  'answer_orig': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'document': '0a278fb2',\n",
       "  'question': 'How can I view the content of the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"You can find the materials related to your cohort by going to the course page at http://mlzoomcamp.com/, scrolling down, and accessing the cohort folder for your specific cohort's year. Make sure to read everything in that folder and click on the links to start watching the videos. Additionally, you can watch office hours from previous cohorts on the DTC YouTube channel by searching for your course year in the Playlists. You can also use this direct link to access the syllabus: http://mlzoomcamp.com/#syllabus.\",\n",
       "  'answer_orig': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'document': '0a278fb2',\n",
       "  'question': 'Where can I find the materials related to my cohort?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To access the videos from previous office hours, go to the DTC YouTube channel, click on Playlists, and search for the relevant course year.',\n",
       "  'answer_orig': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'document': '0a278fb2',\n",
       "  'question': 'How do I access the videos from previous office hours?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'ML Zoomcamp was first launched in 2021.',\n",
       "  'answer_orig': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'document': '0a278fb2',\n",
       "  'question': 'When was ML Zoomcamp first introduced?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find the deadlines for the 2023 cohort by visiting the 2023 cohort page, where the deadlines are listed.',\n",
       "  'answer_orig': 'For the 2023 cohort, you can see the deadlines here (it’s taken from the 2023 cohort page)',\n",
       "  'document': '8de4fefd',\n",
       "  'question': 'Where can I find the deadlines for the 2023 cohort?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The deadline information for the 2023 cohort is available by visiting the designated page (it’s taken from the 2023 cohort page).',\n",
       "  'answer_orig': 'For the 2023 cohort, you can see the deadlines here (it’s taken from the 2023 cohort page)',\n",
       "  'document': '8de4fefd',\n",
       "  'question': 'Where is the deadline information available for the 2023 cohort?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To check the deadlines for the 2023 course, you can see them on the 2023 cohort page.',\n",
       "  'answer_orig': 'For the 2023 cohort, you can see the deadlines here (it’s taken from the 2023 cohort page)',\n",
       "  'document': '8de4fefd',\n",
       "  'question': 'How do I check the deadlines for the 2023 course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can see the deadlines for the 2023 cohort by referring to the 2023 cohort page.',\n",
       "  'answer_orig': 'For the 2023 cohort, you can see the deadlines here (it’s taken from the 2023 cohort page)',\n",
       "  'document': '8de4fefd',\n",
       "  'question': 'Can you show me where to see the 2023 cohort deadlines?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The deadlines for the 2023 cohort are listed on the 2023 cohort page. You can see them [here](it’s taken from the 2023 cohort page).',\n",
       "  'answer_orig': 'For the 2023 cohort, you can see the deadlines here (it’s taken from the 2023 cohort page)',\n",
       "  'document': '8de4fefd',\n",
       "  'question': 'Where are the 2023 cohort deadlines listed?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The main changes between the 2022 and 2023 versions of the course are that there was one special module (BentoML) included in the previous iteration, while the rest of the modules remain the same. Additionally, the homework for the 2023 version is different from that of 2022.',\n",
       "  'answer_orig': 'There’s not much difference. There was one special module (BentoML) in the previous iteration of the course, but the rest of the modules are the same as in 2022. The homework this year is different.',\n",
       "  'document': '94e86808',\n",
       "  'question': 'What has changed between the 2022 and 2023 versions of the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is a module missing in the 2023 course compared to 2022. The special module (BentoML) that was part of the previous iteration of the course in 2022 is not included in the 2023 course. However, the rest of the modules are the same as in 2022.',\n",
       "  'answer_orig': 'There’s not much difference. There was one special module (BentoML) in the previous iteration of the course, but the rest of the modules are the same as in 2022. The homework this year is different.',\n",
       "  'document': '94e86808',\n",
       "  'question': 'Is there any module missing in the 2023 course compared to 2022?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, the homework assignments in the 2023 course are different from those in 2022.',\n",
       "  'answer_orig': 'There’s not much difference. There was one special module (BentoML) in the previous iteration of the course, but the rest of the modules are the same as in 2022. The homework this year is different.',\n",
       "  'document': '94e86808',\n",
       "  'question': 'Are the homework assignments in the 2023 course the same as in 2022?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, BentoML was included in the 2022 course but was a special module that is not part of the 2023 course iteration.',\n",
       "  'answer_orig': 'There’s not much difference. There was one special module (BentoML) in the previous iteration of the course, but the rest of the modules are the same as in 2022. The homework this year is different.',\n",
       "  'document': '94e86808',\n",
       "  'question': 'Was BentoML included in the 2022 course but not in the 2023 course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the majority of modules are unchanged from the 2022 course. There was one special module (BentoML) in the previous iteration, but the rest of the modules remain the same as in 2022.',\n",
       "  'answer_orig': 'There’s not much difference. There was one special module (BentoML) in the previous iteration of the course, but the rest of the modules are the same as in 2022. The homework this year is different.',\n",
       "  'document': '94e86808',\n",
       "  'question': 'Are the majority of modules unchanged from the 2022 course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"We won’t be releasing new course videos; we will be using the videos from 2021. The focus of the course and the skills we want to teach have remained the same, and the videos are still up-to-date. If you haven't taken part in the previous iteration, you can start watching the videos, and it will still be useful for your learning. However, it's recommended to use Python 3.10 instead of Python 3.8.\",\n",
       "  'answer_orig': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'document': 'e7ba6b8a',\n",
       "  'question': 'Will you be releasing new course videos or using the ones from 2021?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, the course videos are not being re-recorded for this iteration. The videos from the previous iteration are still up-to-date and will be used.',\n",
       "  'answer_orig': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'document': 'e7ba6b8a',\n",
       "  'question': 'Are the course videos being re-recorded for this iteration?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'There is no difference in the skills taught in this iteration compared to 2021. The focus of the course and the skills intended to be taught have remained the same.',\n",
       "  'answer_orig': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'document': 'e7ba6b8a',\n",
       "  'question': 'Is there any difference in the skills taught in this iteration compared to 2021?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you should watch the videos even if you didn't take the course in 2021. The videos are still up-to-date, and you will find them useful for learning new things. However, it's recommended to use Python 3.10 instead of Python 3.8.\",\n",
       "  'answer_orig': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'document': 'e7ba6b8a',\n",
       "  'question': \"Should I watch the videos if I didn't take the course in 2021?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The recommended Python version for this course iteration is Python 3.10.',\n",
       "  'answer_orig': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'document': 'e7ba6b8a',\n",
       "  'question': 'Which Python version is recommended for this course iteration?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'When posting about what you learned from the course on your social media pages, use the tag **#mlzoomcamp**.',\n",
       "  'answer_orig': 'When you post about what you learned from the course on your social media pages, use the tag #mlzoomcamp. When you submit your homework, there’s a section in the form for putting the links there. Separate multiple links by any whitespace character (linebreak, space, tab, etc).\\nFor posting the learning in public links, you get extra scores. But the number of scores is limited to 7 points: if you put more than 7 links in your homework form, you’ll get only 7 points.\\nThe same content can be posted to 7 different social sites and still earn you 7 points if you add 7 URLs per week, see Alexey’s reply. (~ ellacharmed)\\nFor midterms/capstones, the awarded points are doubled as the duration is longer. So for projects the points are capped at 14 for 14 URLs.',\n",
       "  'document': 'f7bc2f65',\n",
       "  'question': 'What tag should I use when posting about my course learning on social media?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To submit your learning in public links when turning in homework, you should include the URLs of your social media posts in the designated section of the homework submission form. You should use the tag #mlzoomcamp when posting about what you learned. If you have multiple links, separate them using any whitespace character such as line breaks, spaces, or tabs. Keep in mind that you can earn a maximum of 7 points for this section, regardless of the number of links you submit; submitting more than 7 links will still cap your score at 7 points.',\n",
       "  'answer_orig': 'When you post about what you learned from the course on your social media pages, use the tag #mlzoomcamp. When you submit your homework, there’s a section in the form for putting the links there. Separate multiple links by any whitespace character (linebreak, space, tab, etc).\\nFor posting the learning in public links, you get extra scores. But the number of scores is limited to 7 points: if you put more than 7 links in your homework form, you’ll get only 7 points.\\nThe same content can be posted to 7 different social sites and still earn you 7 points if you add 7 URLs per week, see Alexey’s reply. (~ ellacharmed)\\nFor midterms/capstones, the awarded points are doubled as the duration is longer. So for projects the points are capped at 14 for 14 URLs.',\n",
       "  'document': 'f7bc2f65',\n",
       "  'question': 'How should I submit my learning in public links when turning in homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, it is not possible to earn more than 7 points for posting learning links in weekly homework. Regardless of the number of links posted, you can only receive a maximum of 7 points.',\n",
       "  'answer_orig': 'When you post about what you learned from the course on your social media pages, use the tag #mlzoomcamp. When you submit your homework, there’s a section in the form for putting the links there. Separate multiple links by any whitespace character (linebreak, space, tab, etc).\\nFor posting the learning in public links, you get extra scores. But the number of scores is limited to 7 points: if you put more than 7 links in your homework form, you’ll get only 7 points.\\nThe same content can be posted to 7 different social sites and still earn you 7 points if you add 7 URLs per week, see Alexey’s reply. (~ ellacharmed)\\nFor midterms/capstones, the awarded points are doubled as the duration is longer. So for projects the points are capped at 14 for 14 URLs.',\n",
       "  'document': 'f7bc2f65',\n",
       "  'question': 'Is it possible to earn more than 7 points for posting learning links in weekly homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can post the same content on multiple social sites to earn points for your homework. You can earn up to 7 points if you add 7 different URLs for your posts, even if the content is the same.',\n",
       "  'answer_orig': 'When you post about what you learned from the course on your social media pages, use the tag #mlzoomcamp. When you submit your homework, there’s a section in the form for putting the links there. Separate multiple links by any whitespace character (linebreak, space, tab, etc).\\nFor posting the learning in public links, you get extra scores. But the number of scores is limited to 7 points: if you put more than 7 links in your homework form, you’ll get only 7 points.\\nThe same content can be posted to 7 different social sites and still earn you 7 points if you add 7 URLs per week, see Alexey’s reply. (~ ellacharmed)\\nFor midterms/capstones, the awarded points are doubled as the duration is longer. So for projects the points are capped at 14 for 14 URLs.',\n",
       "  'document': 'f7bc2f65',\n",
       "  'question': 'Can I post the same content on multiple social sites to earn points for my homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can earn up to 14 points for posting public learning links during midterms and capstones. This is because the points awarded for learning in public links are doubled during this period, allowing you to submit 14 URLs for the projects.',\n",
       "  'answer_orig': 'When you post about what you learned from the course on your social media pages, use the tag #mlzoomcamp. When you submit your homework, there’s a section in the form for putting the links there. Separate multiple links by any whitespace character (linebreak, space, tab, etc).\\nFor posting the learning in public links, you get extra scores. But the number of scores is limited to 7 points: if you put more than 7 links in your homework form, you’ll get only 7 points.\\nThe same content can be posted to 7 different social sites and still earn you 7 points if you add 7 URLs per week, see Alexey’s reply. (~ ellacharmed)\\nFor midterms/capstones, the awarded points are doubled as the duration is longer. So for projects the points are capped at 14 for 14 URLs.',\n",
       "  'document': 'f7bc2f65',\n",
       "  'question': 'How many points can I earn for posting public learning links during midterms and capstones?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Based on the provided context, it does not explicitly mention whether you can share your course projects on a public platform. However, it does state that you can create your own GitHub repository for the course, where you can include your notes, homework, and projects. This implies that sharing your projects in your own repository is permitted, but the context does not provide clear guidance on sharing them publicly beyond that.',\n",
       "  'answer_orig': \"You can create your own github repository for the course with your notes, homework, projects, etc.\\nThen fork the original course repo and add a link under the 'Community Notes' section to the notes that are in your own repo.\\nAfter that's done, create a pull request to sync your fork with the original course repo.\\n(By Wesley Barreto)\",\n",
       "  'document': 'ae52a907',\n",
       "  'question': 'Can I share my course projects on a public platform?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To add your notes to the Community Notes section, you can create your own GitHub repository for the course that includes your notes, homework, and projects. Then, fork the original course repository and add a link to your own repository under the 'Community Notes' section. After that, create a pull request to sync your fork with the original course repository.\",\n",
       "  'answer_orig': \"You can create your own github repository for the course with your notes, homework, projects, etc.\\nThen fork the original course repo and add a link under the 'Community Notes' section to the notes that are in your own repo.\\nAfter that's done, create a pull request to sync your fork with the original course repo.\\n(By Wesley Barreto)\",\n",
       "  'document': 'ae52a907',\n",
       "  'question': 'How do I add my notes to the Community Notes section?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To sync your changes with the original course repo, first, create your own GitHub repository for the course with your notes, homework, projects, etc. Then, fork the original course repo and add a link under the 'Community Notes' section to the notes in your own repo. Once that is completed, create a pull request to sync your fork with the original course repo.\",\n",
       "  'answer_orig': \"You can create your own github repository for the course with your notes, homework, projects, etc.\\nThen fork the original course repo and add a link under the 'Community Notes' section to the notes that are in your own repo.\\nAfter that's done, create a pull request to sync your fork with the original course repo.\\n(By Wesley Barreto)\",\n",
       "  'document': 'ae52a907',\n",
       "  'question': 'What is the process to sync my changes with the original course repo?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"You should host your course-related notes and projects by creating your own GitHub repository for the course. Include your notes, homework, and projects in that repository. Then, fork the original course repository and add a link under the 'Community Notes' section to your own repository. After doing that, create a pull request to sync your fork with the original course repository.\",\n",
       "  'answer_orig': \"You can create your own github repository for the course with your notes, homework, projects, etc.\\nThen fork the original course repo and add a link under the 'Community Notes' section to the notes that are in your own repo.\\nAfter that's done, create a pull request to sync your fork with the original course repo.\\n(By Wesley Barreto)\",\n",
       "  'document': 'ae52a907',\n",
       "  'question': 'Where should I host my course-related notes and projects?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you can add a link to your own repo in the course repository under the 'Community Notes' section. First, create your own GitHub repository for the course and fork the original course repo. After that, you can add the link to your notes in your own repo and then create a pull request to sync your fork with the original course repo.\",\n",
       "  'answer_orig': \"You can create your own github repository for the course with your notes, homework, projects, etc.\\nThen fork the original course repo and add a link under the 'Community Notes' section to the notes that are in your own repo.\\nAfter that's done, create a pull request to sync your fork with the original course repo.\\n(By Wesley Barreto)\",\n",
       "  'document': 'ae52a907',\n",
       "  'question': 'Is there a specific location to add a link to my own repo in the course repository?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find the leaderboard links for 2023 and 2022 at the following URLs:\\n\\n- 2023: [Leaderboard Link](https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml)\\n- 2022: [Leaderboard Link](https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml)',\n",
       "  'answer_orig': \"Leaderboard Links:\\n2023 - https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml\\n2022 - https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml\\nPython Code:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode('utf-8')).hexdigest()\\nYou need to call the function as follows:\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\nThe quotes are required to denote that your email is a string.\\n(By Wesley Barreto)\\nYou can also use this website directly by entering your email: http://www.sha1-online.com. Then, you just have to copy and paste your hashed email in the “research” bar of the leaderboard to get your scores.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'dab5a24a',\n",
       "  'question': 'Where can I find the leaderboard links for 2023 and 2022?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To compute the hash for your email using Python, you can use the following code:\\n\\n```python\\nfrom hashlib import sha1\\n\\ndef compute_hash(email):\\n    return sha1(email.lower().encode('utf-8')).hexdigest()\\n\\n# Example usage - replace 'YOUR_EMAIL_HERE' with your actual email address\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\n```\\n\\nMake sure to replace 'YOUR_EMAIL_HERE' with your actual email address, and remember that the quotes are required to denote that your email is a string.\",\n",
       "  'answer_orig': \"Leaderboard Links:\\n2023 - https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml\\n2022 - https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml\\nPython Code:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode('utf-8')).hexdigest()\\nYou need to call the function as follows:\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\nThe quotes are required to denote that your email is a string.\\n(By Wesley Barreto)\\nYou can also use this website directly by entering your email: http://www.sha1-online.com. Then, you just have to copy and paste your hashed email in the “research” bar of the leaderboard to get your scores.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'dab5a24a',\n",
       "  'question': 'How do I compute the hash for my email using Python?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, you do not need to format your email in any special way before computing the hash, other than ensuring it is in lowercase. The Python code provided will convert the email to lowercase automatically before computing the hash.',\n",
       "  'answer_orig': \"Leaderboard Links:\\n2023 - https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml\\n2022 - https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml\\nPython Code:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode('utf-8')).hexdigest()\\nYou need to call the function as follows:\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\nThe quotes are required to denote that your email is a string.\\n(By Wesley Barreto)\\nYou can also use this website directly by entering your email: http://www.sha1-online.com. Then, you just have to copy and paste your hashed email in the “research” bar of the leaderboard to get your scores.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'dab5a24a',\n",
       "  'question': 'Do I need to format my email in any special way before computing the hash?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you can use an online tool to compute your email's hash. You can enter your email on the website http://www.sha1-online.com to get the hashed value. After obtaining the hash, you can copy and paste it as needed.\",\n",
       "  'answer_orig': \"Leaderboard Links:\\n2023 - https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml\\n2022 - https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml\\nPython Code:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode('utf-8')).hexdigest()\\nYou need to call the function as follows:\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\nThe quotes are required to denote that your email is a string.\\n(By Wesley Barreto)\\nYou can also use this website directly by entering your email: http://www.sha1-online.com. Then, you just have to copy and paste your hashed email in the “research” bar of the leaderboard to get your scores.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'dab5a24a',\n",
       "  'question': \"Is there an online tool I can use to compute my email's hash?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To use the hashed email to check your scores on the leaderboard, you need to follow these steps:\\n\\n1. Compute the hash of your email using the provided Python code:\\n   ```python\\n   from hashlib import sha1\\n   def compute_hash(email):\\n       return sha1(email.lower().encode(\\'utf-8\\')).hexdigest()\\n   \\n   # Example usage\\n   email = \"YOUR_EMAIL_HERE\"\\n   hashed_email = compute_hash(email)\\n   print(\"Hashed Email (SHA-1):\", hashed_email)\\n   ```\\n   Make sure to replace `\"YOUR_EMAIL_HERE\"` with your actual email address.\\n\\n2. Alternatively, you can use the website http://www.sha1-online.com to compute your hashed email.\\n\\n3. After obtaining your hashed email, go to the leaderboard link provided for the corresponding year (for example, 2023:\\n   [Leaderboard 2023](https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml)).\\n\\n4. Finally, copy and paste your hashed email into the “research” bar of the leaderboard to find your scores.',\n",
       "  'answer_orig': \"Leaderboard Links:\\n2023 - https://docs.google.com/spreadsheets/d/e/2PACX-1vSNK_yGtELX1RJK1SSRl4xiUbD0XZMYS6uwHnybc7Mql-WMnMgO7hHSu59w-1cE7FeFZjkopbh684UE/pubhtml\\n2022 - https://docs.google.com/spreadsheets/d/e/2PACX-1vQzLGpva63gb2rIilFnpZMRSb-buyr5oGh8jmDtIb8DANo4n6hDalra_WRCl4EZwO1JvaC4UIS62n5h/pubhtml\\nPython Code:\\nfrom hashlib import sha1\\ndef compute_hash(email):\\nreturn sha1(email.lower().encode('utf-8')).hexdigest()\\nYou need to call the function as follows:\\nprint(compute_hash('YOUR_EMAIL_HERE'))\\nThe quotes are required to denote that your email is a string.\\n(By Wesley Barreto)\\nYou can also use this website directly by entering your email: http://www.sha1-online.com. Then, you just have to copy and paste your hashed email in the “research” bar of the leaderboard to get your scores.\\n(Mélanie Fouesnard)\",\n",
       "  'document': 'dab5a24a',\n",
       "  'question': 'How do I use the hashed email to check my scores on the leaderboard?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To resolve the error 'wget is not recognized as an internal or external command' on a Windows system, you need to install wget. The easiest way to do this is by using Chocolatey; you can run the command `choco install wget`. Alternatively, you can download a binary from a source and place it in any location that is part of your PATH, such as `C:/tools/`.\",\n",
       "  'answer_orig': 'If you get “wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run\\nsudo apt-get install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\nchoco install wget\\nOr you can download a binary from here and put it to any location in your PATH (e.g. C:/tools/)\\nOn Mac, the easiest way to install wget is to use brew.\\nBrew install wget\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need eeeto use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAnd then in your python code, for example in your jupyter notebook, use:\\nimport wget\\nwget.download(\"URL\")\\nThis should download whatever is at the URL in the same directory as your code.\\n(Memoona Tahira)\\nAlternatively, you can read a CSV file from a URL directly with pandas:\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\nValid URL schemes include http, ftp, s3, gs, and file.\\nIn some cases you might need to bypass https checks:\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\nOr you can use the built-in Python functionality for downloading the files:\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\nUrllib.request.urlretrieve() is a standard Python library function available on all devices and platforms. URL requests and URL data retrieval are done with the urllib.request module.\\nThe urlretrieve() function allows you to download files from URLs and save them locally. Python programs use it to download files from the internet.\\nOn any Python-enabled device or platform, you can use the urllib.request.urlretrieve() function to download the file.\\n(Mohammad Emad Sharifi)',\n",
       "  'document': '49f9bda9',\n",
       "  'question': \"How can I resolve 'wget is not recognized as an internal or external command' on a Windows system?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To install wget on a Mac, follow these steps:\\n\\n1. Open your terminal.\\n2. Use Homebrew to install wget by running the command:\\n   ```\\n   brew install wget\\n   ```\\n\\nAlternatively, you can use a Python wget library by first installing it with pip:\\n1. Install the library by running:\\n   ```\\n   pip install wget\\n   ```\\n2. In your Python code, use it by writing:\\n   ```python\\n   import wget\\n   wget.download(\"URL\")\\n   ```\\n\\nThis will download the file from the specified URL.',\n",
       "  'answer_orig': 'If you get “wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run\\nsudo apt-get install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\nchoco install wget\\nOr you can download a binary from here and put it to any location in your PATH (e.g. C:/tools/)\\nOn Mac, the easiest way to install wget is to use brew.\\nBrew install wget\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need eeeto use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAnd then in your python code, for example in your jupyter notebook, use:\\nimport wget\\nwget.download(\"URL\")\\nThis should download whatever is at the URL in the same directory as your code.\\n(Memoona Tahira)\\nAlternatively, you can read a CSV file from a URL directly with pandas:\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\nValid URL schemes include http, ftp, s3, gs, and file.\\nIn some cases you might need to bypass https checks:\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\nOr you can use the built-in Python functionality for downloading the files:\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\nUrllib.request.urlretrieve() is a standard Python library function available on all devices and platforms. URL requests and URL data retrieval are done with the urllib.request module.\\nThe urlretrieve() function allows you to download files from URLs and save them locally. Python programs use it to download files from the internet.\\nOn any Python-enabled device or platform, you can use the urllib.request.urlretrieve() function to download the file.\\n(Mohammad Emad Sharifi)',\n",
       "  'document': '49f9bda9',\n",
       "  'question': 'What are the steps to install wget on a Mac?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can use Python to perform the same task as wget. You can utilize the `wget` library in Python by first installing it with pip:\\n\\n```bash\\npip install wget\\n```\\n\\nThen, in your Python code, you can download a file using:\\n\\n```python\\nimport wget\\nwget.download(\"URL\")\\n```\\n\\nThis will download the file located at the specified URL to the same directory as your code.\\n\\nAlternatively, you can use the built-in `urllib` library as follows:\\n\\n```python\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\n```\\n\\nBoth methods will allow you to download files from the internet in a way similar to wget.',\n",
       "  'answer_orig': 'If you get “wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run\\nsudo apt-get install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\nchoco install wget\\nOr you can download a binary from here and put it to any location in your PATH (e.g. C:/tools/)\\nOn Mac, the easiest way to install wget is to use brew.\\nBrew install wget\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need eeeto use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAnd then in your python code, for example in your jupyter notebook, use:\\nimport wget\\nwget.download(\"URL\")\\nThis should download whatever is at the URL in the same directory as your code.\\n(Memoona Tahira)\\nAlternatively, you can read a CSV file from a URL directly with pandas:\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\nValid URL schemes include http, ftp, s3, gs, and file.\\nIn some cases you might need to bypass https checks:\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\nOr you can use the built-in Python functionality for downloading the files:\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\nUrllib.request.urlretrieve() is a standard Python library function available on all devices and platforms. URL requests and URL data retrieval are done with the urllib.request module.\\nThe urlretrieve() function allows you to download files from URLs and save them locally. Python programs use it to download files from the internet.\\nOn any Python-enabled device or platform, you can use the urllib.request.urlretrieve() function to download the file.\\n(Mohammad Emad Sharifi)',\n",
       "  'document': '49f9bda9',\n",
       "  'question': 'Can I use Python to perform the same task as wget? If so, how?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can use the function `urllib.request.urlretrieve()` to download files from URLs in Python. This function allows you to retrieve files from the internet and save them locally. Here\\'s an example of how to use it:\\n\\n```python\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\n``` \\n\\nThis will download the file from the specified URL and save it as \"housing.csv\" in your local directory.',\n",
       "  'answer_orig': 'If you get “wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run\\nsudo apt-get install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\nchoco install wget\\nOr you can download a binary from here and put it to any location in your PATH (e.g. C:/tools/)\\nOn Mac, the easiest way to install wget is to use brew.\\nBrew install wget\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need eeeto use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAnd then in your python code, for example in your jupyter notebook, use:\\nimport wget\\nwget.download(\"URL\")\\nThis should download whatever is at the URL in the same directory as your code.\\n(Memoona Tahira)\\nAlternatively, you can read a CSV file from a URL directly with pandas:\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\nValid URL schemes include http, ftp, s3, gs, and file.\\nIn some cases you might need to bypass https checks:\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\nOr you can use the built-in Python functionality for downloading the files:\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\nUrllib.request.urlretrieve() is a standard Python library function available on all devices and platforms. URL requests and URL data retrieval are done with the urllib.request module.\\nThe urlretrieve() function allows you to download files from URLs and save them locally. Python programs use it to download files from the internet.\\nOn any Python-enabled device or platform, you can use the urllib.request.urlretrieve() function to download the file.\\n(Mohammad Emad Sharifi)',\n",
       "  'document': '49f9bda9',\n",
       "  'question': \"What function in Python's urllib.request can I use to download files from URLs?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can read a CSV file directly from a URL using pandas with the following code:\\n\\n```python\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\n```\\n\\nMake sure that the URL is valid; supported URL schemes include http, ftp, s3, gs, and file. If needed, you might have to bypass https checks using:\\n\\n```python\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\n```\\n\\nAlternatively, you can use the built-in Python functionality with `urllib.request`:\\n\\n```python\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\n```\\n\\nThis will allow you to download files from URLs and save them locally.',\n",
       "  'answer_orig': 'If you get “wget is not recognized as an internal or external command”, you need to install it.\\nOn Ubuntu, run\\nsudo apt-get install wget\\nOn Windows, the easiest way to install wget is to use Chocolatey:\\nchoco install wget\\nOr you can download a binary from here and put it to any location in your PATH (e.g. C:/tools/)\\nOn Mac, the easiest way to install wget is to use brew.\\nBrew install wget\\nAlternatively, you can use a Python wget library, but instead of simply using “wget” you’ll need eeeto use\\npython -m wget\\nYou need to install it with pip first:\\npip install wget\\nAnd then in your python code, for example in your jupyter notebook, use:\\nimport wget\\nwget.download(\"URL\")\\nThis should download whatever is at the URL in the same directory as your code.\\n(Memoona Tahira)\\nAlternatively, you can read a CSV file from a URL directly with pandas:\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\ndf = pd.read_csv(url)\\nValid URL schemes include http, ftp, s3, gs, and file.\\nIn some cases you might need to bypass https checks:\\nimport ssl\\nssl._create_default_https_context = ssl._create_unverified_context\\nOr you can use the built-in Python functionality for downloading the files:\\nimport urllib.request\\nurl = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\nurllib.request.urlretrieve(url, \"housing.csv\")\\nUrllib.request.urlretrieve() is a standard Python library function available on all devices and platforms. URL requests and URL data retrieval are done with the urllib.request module.\\nThe urlretrieve() function allows you to download files from URLs and save them locally. Python programs use it to download files from the internet.\\nOn any Python-enabled device or platform, you can use the urllib.request.urlretrieve() function to download the file.\\n(Mohammad Emad Sharifi)',\n",
       "  'document': '49f9bda9',\n",
       "  'question': 'How can I read a CSV file directly from a URL using pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To download a CSV file inside a Jupyter notebook, you can use the following methods:\\n\\n1. **Using wget**:\\n   ```python\\n   !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n   ```\\n   (The exclamation mark `!` allows you to run shell commands in your notebook.)\\n\\n2. **Using the pandas library**:\\n   You can read a CSV file directly from a URL with pandas:\\n   ```python\\n   import pandas as pd\\n   url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\n   df = pd.read_csv(url)\\n   ```\\n\\n3. **Using urllib**:\\n   You can also download the file using the built-in Python `urllib` module:\\n   ```python\\n   import urllib.request\\n   url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\\n   urllib.request.urlretrieve(url, \"housing.csv\")\\n   ```\\n\\nAll these methods will allow you to download and access the CSV file within your Jupyter notebook environment.',\n",
       "  'answer_orig': 'You can use\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nTo download the data too. The exclamation mark !, lets you execute shell commands inside your notebooks. This works generally for shell commands such as ls, cp, mkdir, mv etc . . .\\nFor instance, if you then want to move your data into a data directory alongside your notebook-containing directory, you could execute the following:\\n!mkdir -p ../data/\\n!mv housing.csv ../data/',\n",
       "  'document': 'd44de7d1',\n",
       "  'question': 'How can I download a CSV file inside a Jupyter notebook?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'In a Jupyter notebook, the exclamation mark (!) is used to run shell commands directly from the notebook. For example, if you use `!ls -lh`, it will execute the `ls -lh` command in the shell and display the output in the notebook. However, if you are using Windows and encounter an error with the `ls` command, you can use `!dir` to achieve similar functionality.',\n",
       "  'answer_orig': 'You can use\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nTo download the data too. The exclamation mark !, lets you execute shell commands inside your notebooks. This works generally for shell commands such as ls, cp, mkdir, mv etc . . .\\nFor instance, if you then want to move your data into a data directory alongside your notebook-containing directory, you could execute the following:\\n!mkdir -p ../data/\\n!mv housing.csv ../data/',\n",
       "  'document': 'd44de7d1',\n",
       "  'question': 'What does the exclamation mark (!) do in a Jupyter notebook?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To execute shell commands like `ls`, `cp`, and `mkdir` in a Jupyter notebook, you can use the `!` operator followed by the command you want to run. \\n\\nFor example:\\n- To list files in a directory, use: `!ls` (on Unix systems) or `!dir` (on Windows systems).\\n- To copy files, use: `!cp <source> <destination>` (on Unix systems) or the equivalent command for Windows.\\n- To create a directory, use: `!mkdir <directory_name>`.\\n\\nRemember that the availability of specific commands may vary based on your operating system. If you're using Windows and encounter errors like `'ls' is not recognized as an internal or external command`, switch to using `!dir` instead.\",\n",
       "  'answer_orig': 'You can use\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nTo download the data too. The exclamation mark !, lets you execute shell commands inside your notebooks. This works generally for shell commands such as ls, cp, mkdir, mv etc . . .\\nFor instance, if you then want to move your data into a data directory alongside your notebook-containing directory, you could execute the following:\\n!mkdir -p ../data/\\n!mv housing.csv ../data/',\n",
       "  'document': 'd44de7d1',\n",
       "  'question': 'How can I execute shell commands like ls, cp, and mkdir in a Jupyter notebook?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To create a directory named 'data', use the command:\\n\\n```\\n!mkdir -p ../data/\\n```\",\n",
       "  'answer_orig': 'You can use\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nTo download the data too. The exclamation mark !, lets you execute shell commands inside your notebooks. This works generally for shell commands such as ls, cp, mkdir, mv etc . . .\\nFor instance, if you then want to move your data into a data directory alongside your notebook-containing directory, you could execute the following:\\n!mkdir -p ../data/\\n!mv housing.csv ../data/',\n",
       "  'document': 'd44de7d1',\n",
       "  'question': \"What command do I use to create a directory named 'data'?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To move a file into a different directory within a Jupyter notebook, you can use the `!mv` command. For example, if you want to move a file named `housing.csv` into a directory called `data`, you can execute the following commands in your notebook:\\n\\n1. First, create the directory if it doesn't exist:\\n   ```\\n   !mkdir -p ../data/\\n   ```\\n\\n2. Then, move the file to that directory:\\n   ```\\n   !mv housing.csv ../data/\\n   ```\\n\\nThis will relocate `housing.csv` into the `data` directory.\",\n",
       "  'answer_orig': 'You can use\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nTo download the data too. The exclamation mark !, lets you execute shell commands inside your notebooks. This works generally for shell commands such as ls, cp, mkdir, mv etc . . .\\nFor instance, if you then want to move your data into a data directory alongside your notebook-containing directory, you could execute the following:\\n!mkdir -p ../data/\\n!mv housing.csv ../data/',\n",
       "  'document': 'd44de7d1',\n",
       "  'question': 'How do I move a file into a different directory within a Jupyter notebook?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To set up a WSL development environment on a Windows 11 device, follow these steps:\\n\\n1. Use the Microsoft Learn link to set up a WSL development environment: [Set up a WSL development environment | Microsoft Learn](https://learn.microsoft.com/en-us/windows/wsl/install).\\n2. Ensure you have the “Virtual Machine Platform” feature activated in your Windows features. You can check this by searching for \"features\" in the research bar.\\n3. Install a Linux distribution such as ‘Ubuntu’ or ‘Debian’ from the Microsoft Store.\\n4. After installation, open the app and create a username and a secure password.\\n5. Once inside the Linux system, you can execute commands like `pwd` to verify you are in Linux.\\n6. To connect to VS Code, download the Microsoft verified VS Code extension ‘WSL’ which allows remote connections to your WSL Ubuntu instance similar to a virtual machine.\\n\\nMake sure your system supports virtualization in the BIOS settings as well.',\n",
       "  'answer_orig': '(Tyler Simpson)',\n",
       "  'document': '314ebe32',\n",
       "  'question': 'How can I set up a WSL development environment on a Windows 11 device?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To connect your WSL Ubuntu instance to VS Code on Windows 11, follow these steps:\\n\\n1. Make sure you have WSL set up on your Windows 11 device. You can refer to the Microsoft Learn link for guidance: Set up a WSL development environment | Microsoft Learn.\\n\\n2. Download and install the Microsoft verified VS Code extension called 'WSL'. This extension allows you to remotely connect to your WSL Ubuntu instance as if it were a virtual machine. \\n\\nFollowing these steps will enable you to use VS Code seamlessly with your WSL Ubuntu environment.\",\n",
       "  'answer_orig': '(Tyler Simpson)',\n",
       "  'document': '314ebe32',\n",
       "  'question': 'How do I connect my WSL Ubuntu instance to VS Code on Windows 11?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To connect VS Code to WSL, you should download the Microsoft verified VS Code extension ‘WSL’. This will allow you to remotely connect to your WSL Ubuntu instance.',\n",
       "  'answer_orig': '(Tyler Simpson)',\n",
       "  'document': '314ebe32',\n",
       "  'question': 'Which extension should I download to connect VS Code to WSL?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can use VS Code to remotely connect to your WSL Ubuntu instance. To do this, you need to download the Microsoft verified VS Code extension ‘WSL’. This will allow you to connect to your WSL Ubuntu instance just as if it were a virtual machine. For more details, you can refer to the Microsoft Learn link on setting up a WSL development environment.',\n",
       "  'answer_orig': '(Tyler Simpson)',\n",
       "  'document': '314ebe32',\n",
       "  'question': 'Can I use VS Code to remotely connect to my WSL Ubuntu instance?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is a guide on Microsoft Learn for setting up WSL on Windows 11. You can find it at the link: Set up a WSL development environment | Microsoft Learn.',\n",
       "  'answer_orig': '(Tyler Simpson)',\n",
       "  'document': '314ebe32',\n",
       "  'question': 'Is there a guide on Microsoft Learn for setting up WSL on Windows 11?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To fix the error message \\'src refspec master does not match any\\' when using git push, you can run the following commands:\\n\\n1. First, create an initial commit with the command:\\n   ```\\n   git commit -m \"initial commit\"\\n   ```\\n2. Then, push your changes to the main branch using:\\n   ```\\n   git push origin main\\n   ```\\n\\nIf this is your first time using GitHub, you might also find a helpful tutorial at this link: https://dennisivy.com/github-quickstart.',\n",
       "  'answer_orig': 'This is my first time using Github to upload a code. I was getting the below error message when I type\\ngit push -u origin master:\\nerror: src refspec master does not match any\\nerror: failed to push some refs to \\'https://github.com/XXXXXX/1st-Homework.git\\'\\nSolution:\\nThe error message got fixed by running below commands:\\ngit commit -m \"initial commit\"\\ngit push origin main\\nIf this is your first time to use Github, you will find a great & straightforward tutorial in this link https://dennisivy.com/github-quickstart\\n(Asia Saeed)\\nYou can also use the “upload file” functionality from GitHub for that\\nIf you write your code on Google colab you can also directly share it on your Github.\\n(By Pranab Sarma)',\n",
       "  'document': '98cff602',\n",
       "  'question': \"How can I fix the error message 'src refspec master does not match any' when using git push?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find a great and straightforward tutorial on using GitHub for the first time at this link: [https://dennisivy.com/github-quickstart](https://dennisivy.com/github-quickstart).',\n",
       "  'answer_orig': 'This is my first time using Github to upload a code. I was getting the below error message when I type\\ngit push -u origin master:\\nerror: src refspec master does not match any\\nerror: failed to push some refs to \\'https://github.com/XXXXXX/1st-Homework.git\\'\\nSolution:\\nThe error message got fixed by running below commands:\\ngit commit -m \"initial commit\"\\ngit push origin main\\nIf this is your first time to use Github, you will find a great & straightforward tutorial in this link https://dennisivy.com/github-quickstart\\n(Asia Saeed)\\nYou can also use the “upload file” functionality from GitHub for that\\nIf you write your code on Google colab you can also directly share it on your Github.\\n(By Pranab Sarma)',\n",
       "  'document': '98cff602',\n",
       "  'question': \"Where can I find a tutorial on using GitHub if it's my first time?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To push an initial commit to GitHub, follow these steps:\\n\\n1. Make sure you have made your changes and are ready to commit them.\\n2. Run the command to commit your changes:\\n   ```\\n   git commit -m \"initial commit\"\\n   ```\\n3. Push your changes to GitHub using:\\n   ```\\n   git push origin main\\n   ```\\n\\nIf you encounter the error message \"src refspec master does not match any,\" ensure you\\'re pushing to the correct branch name, which is typically \"main\" for new repositories. You can also refer to this [GitHub quickstart tutorial](https://dennisivy.com/github-quickstart) for further guidance.',\n",
       "  'answer_orig': 'This is my first time using Github to upload a code. I was getting the below error message when I type\\ngit push -u origin master:\\nerror: src refspec master does not match any\\nerror: failed to push some refs to \\'https://github.com/XXXXXX/1st-Homework.git\\'\\nSolution:\\nThe error message got fixed by running below commands:\\ngit commit -m \"initial commit\"\\ngit push origin main\\nIf this is your first time to use Github, you will find a great & straightforward tutorial in this link https://dennisivy.com/github-quickstart\\n(Asia Saeed)\\nYou can also use the “upload file” functionality from GitHub for that\\nIf you write your code on Google colab you can also directly share it on your Github.\\n(By Pranab Sarma)',\n",
       "  'document': '98cff602',\n",
       "  'question': 'What are the steps to push an initial commit to GitHub?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can use the “upload file” functionality from GitHub to submit your homework.',\n",
       "  'answer_orig': 'This is my first time using Github to upload a code. I was getting the below error message when I type\\ngit push -u origin master:\\nerror: src refspec master does not match any\\nerror: failed to push some refs to \\'https://github.com/XXXXXX/1st-Homework.git\\'\\nSolution:\\nThe error message got fixed by running below commands:\\ngit commit -m \"initial commit\"\\ngit push origin main\\nIf this is your first time to use Github, you will find a great & straightforward tutorial in this link https://dennisivy.com/github-quickstart\\n(Asia Saeed)\\nYou can also use the “upload file” functionality from GitHub for that\\nIf you write your code on Google colab you can also directly share it on your Github.\\n(By Pranab Sarma)',\n",
       "  'document': '98cff602',\n",
       "  'question': \"Can I use the 'upload file' functionality on GitHub to submit my homework?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, it is possible to directly share code from Google Colab to GitHub. You can do this by using the built-in functionality within Google Colab to save your notebooks directly to your GitHub repository.',\n",
       "  'answer_orig': 'This is my first time using Github to upload a code. I was getting the below error message when I type\\ngit push -u origin master:\\nerror: src refspec master does not match any\\nerror: failed to push some refs to \\'https://github.com/XXXXXX/1st-Homework.git\\'\\nSolution:\\nThe error message got fixed by running below commands:\\ngit commit -m \"initial commit\"\\ngit push origin main\\nIf this is your first time to use Github, you will find a great & straightforward tutorial in this link https://dennisivy.com/github-quickstart\\n(Asia Saeed)\\nYou can also use the “upload file” functionality from GitHub for that\\nIf you write your code on Google colab you can also directly share it on your Github.\\n(By Pranab Sarma)',\n",
       "  'document': '98cff602',\n",
       "  'question': 'Is it possible to directly share code from Google Colab to GitHub?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'A singular matrix error occurs during matrix inversion because not every matrix is invertible. In the homework, this error often arises when there is an issue with the order of matrix multiplication. Since multiplication is not commutative, the order of the matrices involved in the operation (using the method .dot) must be respected; otherwise, it can lead to incorrect results and a singular matrix error.',\n",
       "  'answer_orig': \"I'm trying to invert the matrix but I got error that the matrix is singular matrix\\nThe singular matrix error is caused by the fact that not every matrix can be inverted. In particular, in the homework it happens because you have to pay close attention when dealing with multiplication (the method .dot) since multiplication is not commutative! X.dot(Y) is not necessarily equal to Y.dot(X), so respect the order otherwise you get the wrong matrix.\",\n",
       "  'document': '54ec0de4',\n",
       "  'question': 'Why does a singular matrix error occur during matrix inversion in the homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To avoid getting a singular matrix error while using the .dot method in your homework, be sure to pay close attention to the order of your matrix multiplication. Remember that multiplication is not commutative, meaning that \\\\( X.dot(Y) \\\\) is not necessarily equal to \\\\( Y.dot(X) \\\\). Therefore, you need to respect the order in which you perform the multiplication to avoid errors. Additionally, ensure that the matrices you're multiplying are suitable for inversion, as not every matrix can be inverted.\",\n",
       "  'answer_orig': \"I'm trying to invert the matrix but I got error that the matrix is singular matrix\\nThe singular matrix error is caused by the fact that not every matrix can be inverted. In particular, in the homework it happens because you have to pay close attention when dealing with multiplication (the method .dot) since multiplication is not commutative! X.dot(Y) is not necessarily equal to Y.dot(X), so respect the order otherwise you get the wrong matrix.\",\n",
       "  'document': '54ec0de4',\n",
       "  'question': 'How can I avoid getting a singular matrix error while using .dot method in the homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The primary cause of a singular matrix error in matrix multiplication tasks is that not every matrix can be inverted. This error often arises because the order of multiplication matters; specifically, \\\\( X.dot(Y) \\\\) is not necessarily equal to \\\\( Y.dot(X) \\\\). Failing to respect this order can lead to incorrect results and result in a singular matrix error.',\n",
       "  'answer_orig': \"I'm trying to invert the matrix but I got error that the matrix is singular matrix\\nThe singular matrix error is caused by the fact that not every matrix can be inverted. In particular, in the homework it happens because you have to pay close attention when dealing with multiplication (the method .dot) since multiplication is not commutative! X.dot(Y) is not necessarily equal to Y.dot(X), so respect the order otherwise you get the wrong matrix.\",\n",
       "  'document': '54ec0de4',\n",
       "  'question': 'What is the primary cause of a singular matrix error in matrix multiplication tasks?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'In the homework, X.dot(Y) is not necessarily equal to Y.dot(X) because matrix multiplication is not commutative. The order of multiplying matrices matters; for a valid multiplication, the number of columns in the first matrix must match the number of rows in the second matrix. If this condition is not satisfied, or if the matrices are not conformable for multiplication, you may encounter a ValueError due to dimension mismatch.',\n",
       "  'answer_orig': \"I'm trying to invert the matrix but I got error that the matrix is singular matrix\\nThe singular matrix error is caused by the fact that not every matrix can be inverted. In particular, in the homework it happens because you have to pay close attention when dealing with multiplication (the method .dot) since multiplication is not commutative! X.dot(Y) is not necessarily equal to Y.dot(X), so respect the order otherwise you get the wrong matrix.\",\n",
       "  'document': '54ec0de4',\n",
       "  'question': 'In the homework, why is X.dot(Y) not necessarily equal to Y.dot(X)?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To prevent singular matrix errors in the machine learning course, pay close attention to the following:\\n\\n1. **Matrix Multiplication Order**: Use the method `.dot()` for matrix multiplication and remember that multiplication is not commutative. This means that \\\\( X.dot(Y) \\\\) is not necessarily equal to \\\\( Y.dot(X) \\\\). Always respect the order of multiplication to avoid incorrect matrices.\\n\\n2. **Matrix Inversion**: Be cautious about inverting matrices in your code. If you calculate the inverse of a matrix \\\\( X \\\\) once, avoid doing it a second time without ensuring that the matrix has not changed in a way that makes it singular.\\n\\nBy focusing on these aspects, you can minimize the likelihood of encountering singular matrix errors.',\n",
       "  'answer_orig': \"I'm trying to invert the matrix but I got error that the matrix is singular matrix\\nThe singular matrix error is caused by the fact that not every matrix can be inverted. In particular, in the homework it happens because you have to pay close attention when dealing with multiplication (the method .dot) since multiplication is not commutative! X.dot(Y) is not necessarily equal to Y.dot(X), so respect the order otherwise you get the wrong matrix.\",\n",
       "  'document': '54ec0de4',\n",
       "  'question': 'What should I pay close attention to in order to prevent singular matrix errors in the machine learning course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If conda is not recognized as an internal command, you should check if you have Anaconda or Miniconda installed on your system. If not, you need to install one of them first. If you are on Windows and have just installed Anaconda, try using Anaconda’s own terminal called “Anaconda Prompt”.',\n",
       "  'answer_orig': 'I have a problem with my terminal. Command\\nconda create -n ml-zoomcamp python=3.9\\ndoesn’t work. Any of 3.8/ 3.9 / 3.10 should be all fine\\nIf you’re on Windows and just installed Anaconda, you can use Anaconda’s own terminal called “Anaconda Prompt”.\\nIf you don’t have Anaconda or Miniconda, you should install it first\\n(Tatyana Mardvilko)',\n",
       "  'document': 'f81f4ecb',\n",
       "  'question': 'What should I do if conda is not recognized as an internal command?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, the command 'conda create -n ml-zoomcamp python=3.9' will work with Python 3.8. The context states that any of Python versions 3.8, 3.9, or 3.10 should be fine.\",\n",
       "  'answer_orig': 'I have a problem with my terminal. Command\\nconda create -n ml-zoomcamp python=3.9\\ndoesn’t work. Any of 3.8/ 3.9 / 3.10 should be all fine\\nIf you’re on Windows and just installed Anaconda, you can use Anaconda’s own terminal called “Anaconda Prompt”.\\nIf you don’t have Anaconda or Miniconda, you should install it first\\n(Tatyana Mardvilko)',\n",
       "  'document': 'f81f4ecb',\n",
       "  'question': \"Will the command 'conda create -n ml-zoomcamp python=3.9' work with Python 3.8?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"It is not strictly necessary to use Anaconda's own terminal on Windows, but it is recommended. You can use Anaconda Prompt, which is provided as part of the Anaconda installation, to run commands like `conda create` and `conda activate`.\",\n",
       "  'answer_orig': 'I have a problem with my terminal. Command\\nconda create -n ml-zoomcamp python=3.9\\ndoesn’t work. Any of 3.8/ 3.9 / 3.10 should be all fine\\nIf you’re on Windows and just installed Anaconda, you can use Anaconda’s own terminal called “Anaconda Prompt”.\\nIf you don’t have Anaconda or Miniconda, you should install it first\\n(Tatyana Mardvilko)',\n",
       "  'document': 'f81f4ecb',\n",
       "  'question': \"Is it necessary to use Anaconda's own terminal on Windows?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, you need to install Anaconda or Miniconda if you don't already have them.\",\n",
       "  'answer_orig': 'I have a problem with my terminal. Command\\nconda create -n ml-zoomcamp python=3.9\\ndoesn’t work. Any of 3.8/ 3.9 / 3.10 should be all fine\\nIf you’re on Windows and just installed Anaconda, you can use Anaconda’s own terminal called “Anaconda Prompt”.\\nIf you don’t have Anaconda or Miniconda, you should install it first\\n(Tatyana Mardvilko)',\n",
       "  'document': 'f81f4ecb',\n",
       "  'question': \"Do I need to install Anaconda or Miniconda if I don't already have them?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, the specified Python version for the course does not need to be exactly 3.9. While the recommended version for the 2023 cohort is Python 3.10, using Python 3.8 is also mentioned, and the course materials are still relevant regardless of the slight version differences.',\n",
       "  'answer_orig': 'I have a problem with my terminal. Command\\nconda create -n ml-zoomcamp python=3.9\\ndoesn’t work. Any of 3.8/ 3.9 / 3.10 should be all fine\\nIf you’re on Windows and just installed Anaconda, you can use Anaconda’s own terminal called “Anaconda Prompt”.\\nIf you don’t have Anaconda or Miniconda, you should install it first\\n(Tatyana Mardvilko)',\n",
       "  'document': 'f81f4ecb',\n",
       "  'question': 'Does the specified Python version for the course need to be exactly 3.9?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To read a dataset with Pandas in Windows, you may encounter issues if you use backslashes in the file path. In Python, the backslash (`\\\\`) is treated as an escape character, which can cause conflicts. To avoid this, you should add an \"r\" before the file path so that Python treats it as a literal string instead. \\n\\nHere’s how you should load the file:\\n\\n```python\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n```\\n\\nBy using `r` in front of the path, you can successfully read the dataset without running into errors related to escape sequences.',\n",
       "  'answer_orig': 'How do I read the dataset with Pandas in Windows?\\nI used the code below but not working\\ndf = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\nUnlike Linux/Mac OS, Windows uses the backslash (\\\\) to navigate the files that cause the conflict with Python. The problem with using the backslash is that in Python, the \\'\\\\\\' has a purpose known as an escape sequence. Escape sequences allow us to include special characters in strings, for example, \"\\\\n\" to add a new line or \"\\\\t\" to add spaces, etc. To avoid the issue we just need to add \"r\" before the file path and Python will treat it as a literal string (not an escape sequence).\\nHere’s how we should be loading the file instead:\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n(Muhammad Awon)',\n",
       "  'document': 'be760b92',\n",
       "  'question': \"How do I read a dataset with Pandas in Windows when my code doesn't work?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The code `df = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')` does not work in Windows because the backslash (`\\\\`) used in the file path is interpreted by Python as an escape character, which can lead to conflicts. To avoid this issue, you should prepend the file path with an \"r\" to treat it as a raw string, like this: `df = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')`. This way, Python will correctly interpret the backslashes in the file path.',\n",
       "  'answer_orig': 'How do I read the dataset with Pandas in Windows?\\nI used the code below but not working\\ndf = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\nUnlike Linux/Mac OS, Windows uses the backslash (\\\\) to navigate the files that cause the conflict with Python. The problem with using the backslash is that in Python, the \\'\\\\\\' has a purpose known as an escape sequence. Escape sequences allow us to include special characters in strings, for example, \"\\\\n\" to add a new line or \"\\\\t\" to add spaces, etc. To avoid the issue we just need to add \"r\" before the file path and Python will treat it as a literal string (not an escape sequence).\\nHere’s how we should be loading the file instead:\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n(Muhammad Awon)',\n",
       "  'document': 'be760b92',\n",
       "  'question': \"Why does my code df = pd.read_csv('C:\\\\Users\\\\username\\\\Downloads\\\\data.csv') not work in Windows?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The reason behind the backslash causing an issue when reading files in Windows using Pandas is that Windows uses the backslash (\\\\) to navigate files, which conflicts with Python\\'s use of the backslash as an escape sequence. Escape sequences allow for the inclusion of special characters in strings, such as \"\\\\n\" for new lines or \"\\\\t\" for tabs. To avoid this issue, it is recommended to prefix the file path with \"r\" to treat it as a literal string, preventing Python from interpreting the backslashes as escape sequences.',\n",
       "  'answer_orig': 'How do I read the dataset with Pandas in Windows?\\nI used the code below but not working\\ndf = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\nUnlike Linux/Mac OS, Windows uses the backslash (\\\\) to navigate the files that cause the conflict with Python. The problem with using the backslash is that in Python, the \\'\\\\\\' has a purpose known as an escape sequence. Escape sequences allow us to include special characters in strings, for example, \"\\\\n\" to add a new line or \"\\\\t\" to add spaces, etc. To avoid the issue we just need to add \"r\" before the file path and Python will treat it as a literal string (not an escape sequence).\\nHere’s how we should be loading the file instead:\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n(Muhammad Awon)',\n",
       "  'document': 'be760b92',\n",
       "  'question': 'What is the reason behind backslash causing an issue when reading files in Windows using Pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Adding 'r' before the file path in Windows with Pandas indicates that the string is a raw string literal. This means that Python will treat the backslashes in the file path as literal characters rather than escape sequences. This is necessary because in Python, the backslash has a special meaning as an escape character, which can cause conflicts when specifying file paths. By using the raw string format, you can correctly read the file without encountering issues related to escape sequences.\",\n",
       "  'answer_orig': 'How do I read the dataset with Pandas in Windows?\\nI used the code below but not working\\ndf = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\nUnlike Linux/Mac OS, Windows uses the backslash (\\\\) to navigate the files that cause the conflict with Python. The problem with using the backslash is that in Python, the \\'\\\\\\' has a purpose known as an escape sequence. Escape sequences allow us to include special characters in strings, for example, \"\\\\n\" to add a new line or \"\\\\t\" to add spaces, etc. To avoid the issue we just need to add \"r\" before the file path and Python will treat it as a literal string (not an escape sequence).\\nHere’s how we should be loading the file instead:\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n(Muhammad Awon)',\n",
       "  'document': 'be760b92',\n",
       "  'question': \"What does adding 'r' before the file path do when reading a file in Windows with Pandas?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To read a file with Pandas in Windows, you should use the raw string format to avoid issues with the backslash in file paths. Here\\'s an example:\\n\\n```python\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n```\\n\\nBy adding \"r\" before the file path, Python treats it as a literal string, preventing any conflicts with escape sequences.',\n",
       "  'answer_orig': 'How do I read the dataset with Pandas in Windows?\\nI used the code below but not working\\ndf = pd.read_csv(\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\nUnlike Linux/Mac OS, Windows uses the backslash (\\\\) to navigate the files that cause the conflict with Python. The problem with using the backslash is that in Python, the \\'\\\\\\' has a purpose known as an escape sequence. Escape sequences allow us to include special characters in strings, for example, \"\\\\n\" to add a new line or \"\\\\t\" to add spaces, etc. To avoid the issue we just need to add \"r\" before the file path and Python will treat it as a literal string (not an escape sequence).\\nHere’s how we should be loading the file instead:\\ndf = pd.read_csv(r\\'C:\\\\Users\\\\username\\\\Downloads\\\\data.csv\\')\\n(Muhammad Awon)',\n",
       "  'document': 'be760b92',\n",
       "  'question': 'Can you show an example of reading a file with Pandas in Windows?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To fix a \\'403 Forbidden\\' error when pushing to GitHub, you should run the following command:\\n\\n```bash\\ngit config -l | grep url\\n```\\n\\nEnsure that the output looks like this:\\n\\n```\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\n```\\n\\nIf it doesn\\'t, change it to the following format:\\n\\n```bash\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n```',\n",
       "  'answer_orig': 'Type the following command:\\ngit config -l | grep url\\nThe output should look like this:\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\nChange this to the following format and make sure the change is reflected using command in step 1:\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n(Added by Dheeraj Karra)',\n",
       "  'document': 'a2cfa1c9',\n",
       "  'question': \"What command should I run to fix a '403 Forbidden' error when pushing to GitHub?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To check the current URL configuration for your Git repository, you can use the following command:\\n\\n```bash\\ngit config -l | grep url\\n```\\n\\nThe output will show you the URL, formatted like this:\\n\\n```\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\n```',\n",
       "  'answer_orig': 'Type the following command:\\ngit config -l | grep url\\nThe output should look like this:\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\nChange this to the following format and make sure the change is reflected using command in step 1:\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n(Added by Dheeraj Karra)',\n",
       "  'document': 'a2cfa1c9',\n",
       "  'question': 'How can I check the current URL configuration for my Git repository?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Before making changes to fix a GitHub push error, the `remote.origin.url` should look like this:\\n\\n```\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\n```\\n\\nYou should then change it to reflect the following format:\\n\\n```\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n```',\n",
       "  'answer_orig': 'Type the following command:\\ngit config -l | grep url\\nThe output should look like this:\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\nChange this to the following format and make sure the change is reflected using command in step 1:\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n(Added by Dheeraj Karra)',\n",
       "  'document': 'a2cfa1c9',\n",
       "  'question': 'What should the remote.origin.url look like before making changes to fix a GitHub push error?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To change the remote URL and fix a \\'403 Forbidden\\' error when pushing to GitHub, you can follow these steps:\\n\\n1. First, check the current remote URL by typing the following command in your terminal:\\n   ```\\n   git config -l | grep url\\n   ```\\n   The output should look like this:\\n   ```\\n   remote.origin.url=https://github.com/github-username/github-repository-name.git\\n   ```\\n\\n2. Change the remote URL to the following format using the command below:\\n   ```\\n   git remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n   ```\\n\\nEnsure that the changes are reflected by running the command in step 1 again.',\n",
       "  'answer_orig': 'Type the following command:\\ngit config -l | grep url\\nThe output should look like this:\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\nChange this to the following format and make sure the change is reflected using command in step 1:\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n(Added by Dheeraj Karra)',\n",
       "  'document': 'a2cfa1c9',\n",
       "  'question': \"How do I change the remote URL to fix a '403 Forbidden' error when pushing to GitHub?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To ensure the changes to the Git URL are correctly applied after updating, you should verify the configuration by using the following command:\\n\\n```\\ngit config -l | grep url\\n```\\n\\nThe output should show the updated URL in the format:\\n\\n```\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\n```\\n\\nMake sure that this reflects the changes you made with the command:\\n\\n```\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n```',\n",
       "  'answer_orig': 'Type the following command:\\ngit config -l | grep url\\nThe output should look like this:\\nremote.origin.url=https://github.com/github-username/github-repository-name.git\\nChange this to the following format and make sure the change is reflected using command in step 1:\\ngit remote set-url origin \"https://github-username@github.com/github-username/github-repository-name.git\"\\n(Added by Dheeraj Karra)',\n",
       "  'document': 'a2cfa1c9',\n",
       "  'question': 'After updating the Git URL, how can I ensure the changes are correctly applied?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"You are encountering the 'fatal: Authentication failed for https://github.com/username' error because support for password authentication was removed on August 13, 2021. To resolve this issue, you need to create a personal access token from your GitHub account and use it when making a push of your changes. For more information on currently recommended modes of authentication, you can refer to the GitHub documentation at: https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls.\",\n",
       "  'answer_orig': \"I had a problem when I tried to push my code from Git Bash:\\nremote: Support for password authentication was removed on August 13, 2021.\\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\\nfatal: Authentication failed for 'https://github.com/username\\nSolution:\\nCreate a personal access token from your github account and use it when you make a push of your last changes.\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\\nBruno Bedón\",\n",
       "  'document': '7b907071',\n",
       "  'question': \"Why am I encountering 'fatal: Authentication failed for https://github.com/username' error when pushing code?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If password authentication for GitHub is no longer supported, you should create a personal access token from your GitHub account and use it when you push your code. For detailed information about currently recommended modes of authentication, you can visit this link: [GitHub Docs](https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls).',\n",
       "  'answer_orig': \"I had a problem when I tried to push my code from Git Bash:\\nremote: Support for password authentication was removed on August 13, 2021.\\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\\nfatal: Authentication failed for 'https://github.com/username\\nSolution:\\nCreate a personal access token from your github account and use it when you make a push of your last changes.\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\\nBruno Bedón\",\n",
       "  'document': '7b907071',\n",
       "  'question': 'What should I do if password authentication for GitHub is no longer supported?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find information on currently recommended modes of authentication for GitHub after password support was removed by visiting the following link: [GitHub Authentication Documentation](https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls).',\n",
       "  'answer_orig': \"I had a problem when I tried to push my code from Git Bash:\\nremote: Support for password authentication was removed on August 13, 2021.\\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\\nfatal: Authentication failed for 'https://github.com/username\\nSolution:\\nCreate a personal access token from your github account and use it when you make a push of your last changes.\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\\nBruno Bedón\",\n",
       "  'document': '7b907071',\n",
       "  'question': 'Where can I find information on recommended authentications for GitHub after password support was removed?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To configure your GitHub authentication if you can't use a password, you need to create a personal access token from your GitHub account and use that token when pushing changes. Additionally, you can set up SSH keys for authentication by following the instructions provided in the GitHub documentation on generating a new SSH key and adding it to the SSH agent. This way, you can authenticate with GitHub without needing to use a password.\",\n",
       "  'answer_orig': \"I had a problem when I tried to push my code from Git Bash:\\nremote: Support for password authentication was removed on August 13, 2021.\\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\\nfatal: Authentication failed for 'https://github.com/username\\nSolution:\\nCreate a personal access token from your github account and use it when you make a push of your last changes.\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\\nBruno Bedón\",\n",
       "  'document': '7b907071',\n",
       "  'question': \"How can I configure my GitHub authentication if I can't use a password?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To create a personal access token for GitHub authentication, you can follow the guide provided by GitHub. Specifically, you'll need to create a personal access token from your GitHub account and use it when pushing your changes. For detailed instructions, refer to the GitHub documentation at [this link](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent).\",\n",
       "  'answer_orig': \"I had a problem when I tried to push my code from Git Bash:\\nremote: Support for password authentication was removed on August 13, 2021.\\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\\nfatal: Authentication failed for 'https://github.com/username\\nSolution:\\nCreate a personal access token from your github account and use it when you make a push of your last changes.\\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\\nBruno Bedón\",\n",
       "  'document': '7b907071',\n",
       "  'question': 'Where do I create a personal access token for GitHub authentication?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To resolve the \"wget: unable to resolve host address\" error in Kaggle, you should turn on the Internet for your session in the Kaggle notebook settings. You can find this option on the settings panel, located on the right-hand side of the Kaggle screen. Additionally, you may need to verify your phone number to confirm that you are not a bot.',\n",
       "  'answer_orig': \"In Kaggle, when you are trying to !wget a dataset from github (or any other public repository/location), you get the following error:\\nGetting  this error while trying to import data- !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n--2022-09-17 16:55:24--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\\nwget: unable to resolve host address 'raw.githubusercontent.com'\\nSolution:\\nIn your Kaggle notebook settings, turn on the Internet for your session. It's on the settings panel, on the right hand side of the Kaggle screen. You'll be asked to verify your phone number so Kaggle knows you are not a bot.\",\n",
       "  'document': 'fc2e0a61',\n",
       "  'question': 'How can I resolve the wget: unable to resolve host address error in Kaggle?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'When wget fails to resolve a host address in Kaggle, you should turn on the Internet for your session in your Kaggle notebook settings. This option is found on the settings panel on the right-hand side of the Kaggle screen. You may be required to verify your phone number to confirm that you are not a bot.',\n",
       "  'answer_orig': \"In Kaggle, when you are trying to !wget a dataset from github (or any other public repository/location), you get the following error:\\nGetting  this error while trying to import data- !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n--2022-09-17 16:55:24--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\\nwget: unable to resolve host address 'raw.githubusercontent.com'\\nSolution:\\nIn your Kaggle notebook settings, turn on the Internet for your session. It's on the settings panel, on the right hand side of the Kaggle screen. You'll be asked to verify your phone number so Kaggle knows you are not a bot.\",\n",
       "  'document': 'fc2e0a61',\n",
       "  'question': 'What should I do when wget fails to resolve a host address in Kaggle?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To import data with `wget` in Kaggle without encountering errors, make sure to enable the Internet for your session. You can do this by accessing the settings panel on the right-hand side of the Kaggle screen. After enabling the Internet, you can use the command:\\n\\n```bash\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\nIf you still face issues with resolving the host address, double-check that the Internet is indeed enabled for your session.',\n",
       "  'answer_orig': \"In Kaggle, when you are trying to !wget a dataset from github (or any other public repository/location), you get the following error:\\nGetting  this error while trying to import data- !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n--2022-09-17 16:55:24--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\\nwget: unable to resolve host address 'raw.githubusercontent.com'\\nSolution:\\nIn your Kaggle notebook settings, turn on the Internet for your session. It's on the settings panel, on the right hand side of the Kaggle screen. You'll be asked to verify your phone number so Kaggle knows you are not a bot.\",\n",
       "  'document': 'fc2e0a61',\n",
       "  'question': 'How to import data with wget in Kaggle without encountering errors?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To fix wget errors in Kaggle, you need to adjust the settings in your Kaggle notebook by turning on the Internet for your session. This option is available on the settings panel on the right-hand side of the Kaggle screen. Please note that you will be asked to verify your phone number to confirm you are not a bot.',\n",
       "  'answer_orig': \"In Kaggle, when you are trying to !wget a dataset from github (or any other public repository/location), you get the following error:\\nGetting  this error while trying to import data- !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n--2022-09-17 16:55:24--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\\nwget: unable to resolve host address 'raw.githubusercontent.com'\\nSolution:\\nIn your Kaggle notebook settings, turn on the Internet for your session. It's on the settings panel, on the right hand side of the Kaggle screen. You'll be asked to verify your phone number so Kaggle knows you are not a bot.\",\n",
       "  'document': 'fc2e0a61',\n",
       "  'question': 'What settings need to be adjusted in Kaggle to fix wget errors?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You need to verify your phone number to use wget in Kaggle because turning on the Internet for your session requires this step. Verifying your phone number helps Kaggle ensure that you are not a bot.',\n",
       "  'answer_orig': \"In Kaggle, when you are trying to !wget a dataset from github (or any other public repository/location), you get the following error:\\nGetting  this error while trying to import data- !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n--2022-09-17 16:55:24--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\\nwget: unable to resolve host address 'raw.githubusercontent.com'\\nSolution:\\nIn your Kaggle notebook settings, turn on the Internet for your session. It's on the settings panel, on the right hand side of the Kaggle screen. You'll be asked to verify your phone number so Kaggle knows you are not a bot.\",\n",
       "  'document': 'fc2e0a61',\n",
       "  'question': 'Why do I need to verify my phone number to use wget in Kaggle?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You should watch the video titled \"Creating Virtual Environment for Python from VS Code\" to set up a virtual environment for Python in VS Code.',\n",
       "  'answer_orig': 'I found this video quite helpful: Creating Virtual Environment for Python from VS Code\\n[Native Jupiter Notebooks support in VS Code] In VS Code you can also have a native Jupiter Notebooks support, i.e. you do not need to open a web browser to code in a Notebook. If you have port forwarding enabled + run a ‘jupyter notebook ‘ command from a remote machine + have a remote connection configured in .ssh/config (as Alexey’s video suggests) - VS Code can execute remote Jupyter Notebooks files on a remote server from your local machine: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\\n[Git support from VS Code] You can work with Github from VSCode - staging and commits are easy from the VS Code’s UI:  https://code.visualstudio.com/docs/sourcecontrol/overview\\n(Added by Ivan Brigida)',\n",
       "  'document': 'd43e5742',\n",
       "  'question': 'What video should I watch to set up a virtual environment for Python in VS Code?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, it is possible to use Jupyter Notebooks in VS Code without a web browser. VS Code has native support for Jupyter Notebooks, allowing you to code in a Notebook directly within the VS Code environment.',\n",
       "  'answer_orig': 'I found this video quite helpful: Creating Virtual Environment for Python from VS Code\\n[Native Jupiter Notebooks support in VS Code] In VS Code you can also have a native Jupiter Notebooks support, i.e. you do not need to open a web browser to code in a Notebook. If you have port forwarding enabled + run a ‘jupyter notebook ‘ command from a remote machine + have a remote connection configured in .ssh/config (as Alexey’s video suggests) - VS Code can execute remote Jupyter Notebooks files on a remote server from your local machine: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\\n[Git support from VS Code] You can work with Github from VSCode - staging and commits are easy from the VS Code’s UI:  https://code.visualstudio.com/docs/sourcecontrol/overview\\n(Added by Ivan Brigida)',\n",
       "  'document': 'd43e5742',\n",
       "  'question': 'Is it possible to use Jupyter Notebooks in VS Code without a web browser?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To execute remote Jupyter Notebook files from your local machine using VS Code, you need to ensure that you have port forwarding enabled and run the `jupyter notebook` command from the remote machine. Additionally, you must have a remote connection configured in your `.ssh/config` file. Once set up, you can use VS Code's native Jupyter Notebooks support to code in the Notebook without needing to open a web browser. More details can be found in the VS Code Jupyter documentation: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\",\n",
       "  'answer_orig': 'I found this video quite helpful: Creating Virtual Environment for Python from VS Code\\n[Native Jupiter Notebooks support in VS Code] In VS Code you can also have a native Jupiter Notebooks support, i.e. you do not need to open a web browser to code in a Notebook. If you have port forwarding enabled + run a ‘jupyter notebook ‘ command from a remote machine + have a remote connection configured in .ssh/config (as Alexey’s video suggests) - VS Code can execute remote Jupyter Notebooks files on a remote server from your local machine: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\\n[Git support from VS Code] You can work with Github from VSCode - staging and commits are easy from the VS Code’s UI:  https://code.visualstudio.com/docs/sourcecontrol/overview\\n(Added by Ivan Brigida)',\n",
       "  'document': 'd43e5742',\n",
       "  'question': 'How can I execute remote Jupyter Notebooks files from my local machine using VS Code?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find more information about working with GitHub from VS Code at the following link: https://code.visualstudio.com/docs/sourcecontrol/overview.',\n",
       "  'answer_orig': 'I found this video quite helpful: Creating Virtual Environment for Python from VS Code\\n[Native Jupiter Notebooks support in VS Code] In VS Code you can also have a native Jupiter Notebooks support, i.e. you do not need to open a web browser to code in a Notebook. If you have port forwarding enabled + run a ‘jupyter notebook ‘ command from a remote machine + have a remote connection configured in .ssh/config (as Alexey’s video suggests) - VS Code can execute remote Jupyter Notebooks files on a remote server from your local machine: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\\n[Git support from VS Code] You can work with Github from VSCode - staging and commits are easy from the VS Code’s UI:  https://code.visualstudio.com/docs/sourcecontrol/overview\\n(Added by Ivan Brigida)',\n",
       "  'document': 'd43e5742',\n",
       "  'question': 'Where can I find more information about working with GitHub from VS Code?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To run Jupyter Notebooks remotely using VS Code, you need to ensure the following setup:\\n\\n1. **Port Forwarding**: Make sure that port forwarding is enabled.\\n2. **Jupyter Notebook Command**: Run the command `jupyter notebook` from a remote machine.\\n3. **Remote Connection Configuration**: Configure a remote connection in your `.ssh/config` file.\\n\\nFollowing these steps will allow VS Code to execute remote Jupyter Notebook files from your local machine. For further assistance, you can refer to the official VS Code documentation on Jupyter Notebooks: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.',\n",
       "  'answer_orig': 'I found this video quite helpful: Creating Virtual Environment for Python from VS Code\\n[Native Jupiter Notebooks support in VS Code] In VS Code you can also have a native Jupiter Notebooks support, i.e. you do not need to open a web browser to code in a Notebook. If you have port forwarding enabled + run a ‘jupyter notebook ‘ command from a remote machine + have a remote connection configured in .ssh/config (as Alexey’s video suggests) - VS Code can execute remote Jupyter Notebooks files on a remote server from your local machine: https://code.visualstudio.com/docs/datascience/jupyter-notebooks.\\n[Git support from VS Code] You can work with Github from VSCode - staging and commits are easy from the VS Code’s UI:  https://code.visualstudio.com/docs/sourcecontrol/overview\\n(Added by Ivan Brigida)',\n",
       "  'document': 'd43e5742',\n",
       "  'question': 'What setup is necessary to run Jupyter Notebooks remotely using VS Code?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'No, you do not need to run \"conda create -n ....\" every time you start VS Code to work on the project. This command is only necessary the first time to create the environment. After that, you only need to run \"conda activate ml-zoomcamp\" to activate the environment whenever you want to use it.',\n",
       "  'answer_orig': 'With regards to creating an environment for the project, do we need to run the command \"conda create -n .......\" and \"conda activate ml-zoomcamp\" everytime we open vs code to work on the project?\\nAnswer:\\n\"conda create -n ....\" is just run the first time to create the environment. Once created, you just need to run \"conda activate ml-zoomcamp\" whenever you want to use it.\\n(Added by Wesley Barreto)\\nconda env export > environment.yml will also allow you to reproduce your existing environment in a YAML file.  You can then recreate it with conda env create -f environment.yml',\n",
       "  'document': '32bc0538',\n",
       "  'question': \"Is it necessary to run 'conda create -n ...' every time I start VS Code to work on the project?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'After creating the environment, you should use the command \"conda activate ml-zoomcamp\" to activate it in VS Code.',\n",
       "  'answer_orig': 'With regards to creating an environment for the project, do we need to run the command \"conda create -n .......\" and \"conda activate ml-zoomcamp\" everytime we open vs code to work on the project?\\nAnswer:\\n\"conda create -n ....\" is just run the first time to create the environment. Once created, you just need to run \"conda activate ml-zoomcamp\" whenever you want to use it.\\n(Added by Wesley Barreto)\\nconda env export > environment.yml will also allow you to reproduce your existing environment in a YAML file.  You can then recreate it with conda env create -f environment.yml',\n",
       "  'document': '32bc0538',\n",
       "  'question': 'What command should I use to activate the environment in VS Code after creating it?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To save your current Conda environment to a file, you can use the command:\\n\\n```\\nconda env export > environment.yml\\n```\\n\\nThis will create a YAML file named `environment.yml` that contains all the dependencies of your existing environment. You can then recreate the environment using the following command:\\n\\n```\\nconda env create -f environment.yml\\n```',\n",
       "  'answer_orig': 'With regards to creating an environment for the project, do we need to run the command \"conda create -n .......\" and \"conda activate ml-zoomcamp\" everytime we open vs code to work on the project?\\nAnswer:\\n\"conda create -n ....\" is just run the first time to create the environment. Once created, you just need to run \"conda activate ml-zoomcamp\" whenever you want to use it.\\n(Added by Wesley Barreto)\\nconda env export > environment.yml will also allow you to reproduce your existing environment in a YAML file.  You can then recreate it with conda env create -f environment.yml',\n",
       "  'document': '32bc0538',\n",
       "  'question': 'How can I save my current Conda environment to a file?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The command that allows you to recreate an environment from a saved YAML file is `conda env create -f environment.yml`.',\n",
       "  'answer_orig': 'With regards to creating an environment for the project, do we need to run the command \"conda create -n .......\" and \"conda activate ml-zoomcamp\" everytime we open vs code to work on the project?\\nAnswer:\\n\"conda create -n ....\" is just run the first time to create the environment. Once created, you just need to run \"conda activate ml-zoomcamp\" whenever you want to use it.\\n(Added by Wesley Barreto)\\nconda env export > environment.yml will also allow you to reproduce your existing environment in a YAML file.  You can then recreate it with conda env create -f environment.yml',\n",
       "  'document': '32bc0538',\n",
       "  'question': 'What command allows me to recreate an environment from a saved YAML file?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'After the Conda environment is created, you need to execute the command `conda activate ml-zoomcamp` to use it.',\n",
       "  'answer_orig': 'With regards to creating an environment for the project, do we need to run the command \"conda create -n .......\" and \"conda activate ml-zoomcamp\" everytime we open vs code to work on the project?\\nAnswer:\\n\"conda create -n ....\" is just run the first time to create the environment. Once created, you just need to run \"conda activate ml-zoomcamp\" whenever you want to use it.\\n(Added by Wesley Barreto)\\nconda env export > environment.yml will also allow you to reproduce your existing environment in a YAML file.  You can then recreate it with conda env create -f environment.yml',\n",
       "  'document': '32bc0538',\n",
       "  'question': 'After the Conda environment is created, which command is executed to use it?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'When you invert a matrix and multiply it by the original matrix, you would typically expect to obtain an identity matrix. However, due to floating point precision issues in computer arithmetic, you may not get an exact identity matrix. Instead, you might see results like small numerical errors, for instance:\\n\\n```\\n[[ 1.00000000e+00 -1.38777878e-16]\\n [ 3.16968674e-13  1.00000000e+00]]\\n```\\n\\nThis discrepancy occurs because floating point math can introduce small errors when performing calculations, leading to results that are very close to but not exactly equal to the expected identity matrix.',\n",
       "  'answer_orig': \"I was doing Question 7 from Week1 Homework and with step6: Invert XTX, I created the inverse. Now, an inverse when multiplied by the original matrix should return in an Identity matrix. But when I multiplied the inverse with the original matrix, it gave a matrix like this:\\nInverse * Original:\\n[[ 1.00000000e+00 -1.38777878e-16]\\n[ 3.16968674e-13  1.00000000e+00]]\\nSolution:\\nIt's because floating point math doesn't work well on computers as shown here: https://stackoverflow.com/questions/588004/is-floating-point-math-broken\\n(Added by Wesley Barreto)\",\n",
       "  'document': 'b6730228',\n",
       "  'question': \"If I invert a matrix and multiply by the original, why don't I get an exact identity matrix?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The matrices do not return an exact identity after multiplication due to floating point precision issues in computer calculations. Floating point math can lead to small errors, which means that when the inverse of a matrix is multiplied by the original matrix, the result may be very close to the identity matrix but not exactly equal to it. This can result in values like -1.38777878e-16 or 3.16968674e-13 appearing instead of perfect zeros.',\n",
       "  'answer_orig': \"I was doing Question 7 from Week1 Homework and with step6: Invert XTX, I created the inverse. Now, an inverse when multiplied by the original matrix should return in an Identity matrix. But when I multiplied the inverse with the original matrix, it gave a matrix like this:\\nInverse * Original:\\n[[ 1.00000000e+00 -1.38777878e-16]\\n[ 3.16968674e-13  1.00000000e+00]]\\nSolution:\\nIt's because floating point math doesn't work well on computers as shown here: https://stackoverflow.com/questions/588004/is-floating-point-math-broken\\n(Added by Wesley Barreto)\",\n",
       "  'document': 'b6730228',\n",
       "  'question': 'Why do the matrices not return an exact identity after multiplication?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The imprecise results after matrix inversion can be attributed to the limitations of floating point arithmetic in computers. When you invert a matrix and multiply it by the original matrix, ideally, the result should be an identity matrix. However, due to floating point precision issues, you may encounter very small values close to zero that affect the outcome, resulting in a matrix that resembles an identity matrix but includes tiny discrepancies, such as:\\n\\n```\\n[[ 1.00000000e+00 -1.38777878e-16]\\n [ 3.16968674e-13  1.00000000e+00]]\\n```\\n\\nThese discrepancies arise because floating point math may not produce exact results as expected, which is a known issue in computational mathematics.',\n",
       "  'answer_orig': \"I was doing Question 7 from Week1 Homework and with step6: Invert XTX, I created the inverse. Now, an inverse when multiplied by the original matrix should return in an Identity matrix. But when I multiplied the inverse with the original matrix, it gave a matrix like this:\\nInverse * Original:\\n[[ 1.00000000e+00 -1.38777878e-16]\\n[ 3.16968674e-13  1.00000000e+00]]\\nSolution:\\nIt's because floating point math doesn't work well on computers as shown here: https://stackoverflow.com/questions/588004/is-floating-point-math-broken\\n(Added by Wesley Barreto)\",\n",
       "  'document': 'b6730228',\n",
       "  'question': 'Can you explain the imprecise results after matrix inversion?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The slight errors observed when multiplying an inverted matrix by the original matrix are primarily due to floating point precision issues in computer arithmetic. When performing calculations with floating point numbers, the results may not be exact, leading to very small discrepancies, as illustrated in the example given in the FAQ. This is a common occurrence when dealing with matrix operations in programming and can be attributed to the inherent limitations of floating point representation.',\n",
       "  'answer_orig': \"I was doing Question 7 from Week1 Homework and with step6: Invert XTX, I created the inverse. Now, an inverse when multiplied by the original matrix should return in an Identity matrix. But when I multiplied the inverse with the original matrix, it gave a matrix like this:\\nInverse * Original:\\n[[ 1.00000000e+00 -1.38777878e-16]\\n[ 3.16968674e-13  1.00000000e+00]]\\nSolution:\\nIt's because floating point math doesn't work well on computers as shown here: https://stackoverflow.com/questions/588004/is-floating-point-math-broken\\n(Added by Wesley Barreto)\",\n",
       "  'document': 'b6730228',\n",
       "  'question': 'What causes the slight errors when multiplying an inverted matrix by the original?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Floating-point math affects the accuracy of matrix operations because it doesn't work well on computers, leading to small numerical errors. For example, when calculating the inverse of a matrix and multiplying it by the original matrix, the expected result should ideally be an identity matrix. However, due to the limitations of floating-point arithmetic, the result may deviate slightly, as shown in the example where the product yielded values very close to 1 but not exactly, indicating precision issues inherent in floating-point computations.\",\n",
       "  'answer_orig': \"I was doing Question 7 from Week1 Homework and with step6: Invert XTX, I created the inverse. Now, an inverse when multiplied by the original matrix should return in an Identity matrix. But when I multiplied the inverse with the original matrix, it gave a matrix like this:\\nInverse * Original:\\n[[ 1.00000000e+00 -1.38777878e-16]\\n[ 3.16968674e-13  1.00000000e+00]]\\nSolution:\\nIt's because floating point math doesn't work well on computers as shown here: https://stackoverflow.com/questions/588004/is-floating-point-math-broken\\n(Added by Wesley Barreto)\",\n",
       "  'document': 'b6730228',\n",
       "  'question': 'Why does floating-point math affect the accuracy of matrix operations?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The command that helps print dataset information in pandas is `df.info()`. This function prints information about the dataset, such as the index datatype, number of entries, column information with not-null count and datatype, and memory usage by the dataset.',\n",
       "  'answer_orig': 'Answer:\\nIt prints the information about the dataset like:\\nIndex datatype\\nNo. of entries\\nColumn information with not-null count and datatype\\nMemory usage by dataset\\nWe use it as:\\ndf.info()\\n(Added by Aadarsha Shrestha & Emoghena Itakpe)',\n",
       "  'document': '3ce9bbb8',\n",
       "  'question': 'What command helps print dataset information in pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To check the column info and memory usage of a pandas DataFrame, you can use the `info()` method. It prints details about the dataset, including the index datatype, number of entries, column information with not-null count and datatype, and memory usage by the dataset. You can use it as follows:\\n\\n```python\\ndf.info()\\n```',\n",
       "  'answer_orig': 'Answer:\\nIt prints the information about the dataset like:\\nIndex datatype\\nNo. of entries\\nColumn information with not-null count and datatype\\nMemory usage by dataset\\nWe use it as:\\ndf.info()\\n(Added by Aadarsha Shrestha & Emoghena Itakpe)',\n",
       "  'document': '3ce9bbb8',\n",
       "  'question': 'How to check column info and memory usage of a pandas DataFrame?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To view the index datatype and the number of entries in a dataset, you should use the method `pandas.DataFrame.info()`. You can do this by calling it as follows:\\n\\n```python\\ndf.info()\\n``` \\n\\nThis will print the information about the dataset, including the index datatype and the number of entries.',\n",
       "  'answer_orig': 'Answer:\\nIt prints the information about the dataset like:\\nIndex datatype\\nNo. of entries\\nColumn information with not-null count and datatype\\nMemory usage by dataset\\nWe use it as:\\ndf.info()\\n(Added by Aadarsha Shrestha & Emoghena Itakpe)',\n",
       "  'document': '3ce9bbb8',\n",
       "  'question': 'What method should I use to view index datatype and the number of entries?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The pandas function that prints column data type and not-null count is `pandas.DataFrame.info()`.',\n",
       "  'answer_orig': 'Answer:\\nIt prints the information about the dataset like:\\nIndex datatype\\nNo. of entries\\nColumn information with not-null count and datatype\\nMemory usage by dataset\\nWe use it as:\\ndf.info()\\n(Added by Aadarsha Shrestha & Emoghena Itakpe)',\n",
       "  'document': '3ce9bbb8',\n",
       "  'question': 'Which pandas function prints column data type and not-null count?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To obtain general dataset info in pandas, you can use the `pandas.DataFrame.info()` method. This method prints information about the dataset, including the index datatype, number of entries, column information with not-null count and datatype, and memory usage by the dataset. You can call this method on your dataframe like this:\\n\\n```python\\ndf.info()\\n```',\n",
       "  'answer_orig': 'Answer:\\nIt prints the information about the dataset like:\\nIndex datatype\\nNo. of entries\\nColumn information with not-null count and datatype\\nMemory usage by dataset\\nWe use it as:\\ndf.info()\\n(Added by Aadarsha Shrestha & Emoghena Itakpe)',\n",
       "  'document': '3ce9bbb8',\n",
       "  'question': 'How can I obtain general dataset info in pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you get a NameError for 'np' in your code, it likely means that the numpy library has not been imported. To resolve this, you should ensure that you include the following import statement at the beginning of your code:\\n\\n```python\\nimport numpy as np\\n```\\n\\nIt's also advisable to import the pandas library if you are using it, with the following line as well:\\n\\n```python\\nimport pandas as pd\\n``` \\n\\nMake sure these import statements are included before any other code that uses 'np' or 'pd'.\",\n",
       "  'answer_orig': \"Pandas and numpy libraries are not being imported\\nNameError: name 'np' is not defined\\nNameError: name 'pd' is not defined\\nIf you're using numpy or pandas, make sure you use the first few lines before anything else.\\nimport pandas as pd\\nimport numpy as np\\nAdded by Manuel Alejandro Aponte\",\n",
       "  'document': '4e584d06',\n",
       "  'question': \"What should I do if I get a NameError for 'np' in my code?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To fix a NameError for 'pd' when using pandas, make sure you have imported the pandas library at the beginning of your script. You should include the following line of code before any usage of 'pd':\\n\\n```python\\nimport pandas as pd\\n```\\nIf you are also using numpy, you should import it as well:\\n\\n```python\\nimport numpy as np\\n``` \\n\\nThis ensures that both libraries are properly imported and available for use in your code.\",\n",
       "  'answer_orig': \"Pandas and numpy libraries are not being imported\\nNameError: name 'np' is not defined\\nNameError: name 'pd' is not defined\\nIf you're using numpy or pandas, make sure you use the first few lines before anything else.\\nimport pandas as pd\\nimport numpy as np\\nAdded by Manuel Alejandro Aponte\",\n",
       "  'document': '4e584d06',\n",
       "  'question': \"How can I fix a NameError for 'pd' when using pandas?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If you receive a NameError for 'np', it means that the numpy library has not been imported.\",\n",
       "  'answer_orig': \"Pandas and numpy libraries are not being imported\\nNameError: name 'np' is not defined\\nNameError: name 'pd' is not defined\\nIf you're using numpy or pandas, make sure you use the first few lines before anything else.\\nimport pandas as pd\\nimport numpy as np\\nAdded by Manuel Alejandro Aponte\",\n",
       "  'document': '4e584d06',\n",
       "  'question': \"What libraries might not be imported if I receive a NameError for 'np'?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"You are seeing a NameError for 'pd' in your machine learning script because the pandas library has not been imported. To resolve this issue, make sure to include the following line at the beginning of your script:\\n\\n```python\\nimport pandas as pd\\n```\\n\\nThis will properly define 'pd' so that you can use it in your code.\",\n",
       "  'answer_orig': \"Pandas and numpy libraries are not being imported\\nNameError: name 'np' is not defined\\nNameError: name 'pd' is not defined\\nIf you're using numpy or pandas, make sure you use the first few lines before anything else.\\nimport pandas as pd\\nimport numpy as np\\nAdded by Manuel Alejandro Aponte\",\n",
       "  'document': '4e584d06',\n",
       "  'question': \"Why am I seeing a NameError for 'pd' in my machine learning script?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The solution to the NameError issue in the FAQ section was added by Manuel Alejandro Aponte.',\n",
       "  'answer_orig': \"Pandas and numpy libraries are not being imported\\nNameError: name 'np' is not defined\\nNameError: name 'pd' is not defined\\nIf you're using numpy or pandas, make sure you use the first few lines before anything else.\\nimport pandas as pd\\nimport numpy as np\\nAdded by Manuel Alejandro Aponte\",\n",
       "  'document': '4e584d06',\n",
       "  'question': 'Who added the solution to the NameError issue in the FAQ section?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To select columns by data type in a pandas dataframe, you can use the `select_dtypes` method. For example, to get all columns with numeric data types, you can use:\\n\\n```python\\ndf.select_dtypes(include=np.number).columns.tolist()\\n```\\n\\nTo select columns with object data types, you can use:\\n\\n```python\\ndf.select_dtypes(include='object').columns.tolist()\\n```\",\n",
       "  'answer_orig': \"What if there were hundreds of columns? How do you get the columns only with numeric or object data in a more concise way?\\ndf.select_dtypes(include=np.number).columns.tolist()\\ndf.select_dtypes(include='object').columns.tolist()\\nAdded by Gregory Morris\",\n",
       "  'document': 'ff4da2b6',\n",
       "  'question': 'How can I select columns by data type in pandas dataframe?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'A concise method to get numeric columns in a dataframe is to use the following code:\\n\\n```python\\ndf.select_dtypes(include=np.number).columns.tolist()\\n```',\n",
       "  'answer_orig': \"What if there were hundreds of columns? How do you get the columns only with numeric or object data in a more concise way?\\ndf.select_dtypes(include=np.number).columns.tolist()\\ndf.select_dtypes(include='object').columns.tolist()\\nAdded by Gregory Morris\",\n",
       "  'document': 'ff4da2b6',\n",
       "  'question': 'What is a concise method to get numeric columns in a dataframe?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To list columns with object data type in a dataframe, you can use the following code:\\n\\n```python\\ndf.select_dtypes(include='object').columns.tolist()\\n```\",\n",
       "  'answer_orig': \"What if there were hundreds of columns? How do you get the columns only with numeric or object data in a more concise way?\\ndf.select_dtypes(include=np.number).columns.tolist()\\ndf.select_dtypes(include='object').columns.tolist()\\nAdded by Gregory Morris\",\n",
       "  'document': 'ff4da2b6',\n",
       "  'question': 'How do I list columns with object data type in a dataframe?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"The pandas function to filter columns by dtype is `df.select_dtypes(include=np.number).columns.tolist()` for numeric data and `df.select_dtypes(include='object').columns.tolist()` for object data.\",\n",
       "  'answer_orig': \"What if there were hundreds of columns? How do you get the columns only with numeric or object data in a more concise way?\\ndf.select_dtypes(include=np.number).columns.tolist()\\ndf.select_dtypes(include='object').columns.tolist()\\nAdded by Gregory Morris\",\n",
       "  'document': 'ff4da2b6',\n",
       "  'question': \"What's the pandas function to filter columns by dtype?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The solution for selecting columns by dtype was contributed by Gregory Morris.',\n",
       "  'answer_orig': \"What if there were hundreds of columns? How do you get the columns only with numeric or object data in a more concise way?\\ndf.select_dtypes(include=np.number).columns.tolist()\\ndf.select_dtypes(include='object').columns.tolist()\\nAdded by Gregory Morris\",\n",
       "  'document': 'ff4da2b6',\n",
       "  'question': 'Who contributed the solution for selecting columns by dtype?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To determine the structure of a dataset in Pandas, you can use the `.shape` attribute. This attribute provides information about the number of rows and columns in the dataset. For example, you can identify the number of rows with `df.shape[0]` and the number of columns with `df.shape[1]`. Additionally, you can use `df.info()` to get a detailed summary of the dataset, which includes index datatype, number of entries, column information with not-null count and datatype, and memory usage.',\n",
       "  'answer_orig': 'There are many ways to identify the shape of dataset, one of them is using .shape attribute!\\ndf.shape\\ndf.shape[0] # for identify the number of rows\\ndf.shape[1] # for identify the number of columns\\nAdded by Radikal Lukafiardi',\n",
       "  'document': '58c1c168',\n",
       "  'question': 'How can I determine the structure of a dataset in Pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The attribute in Pandas that helps identify the number of rows in a dataset is the `.shape` attribute. You can use `df.shape[0]` to get the number of rows.',\n",
       "  'answer_orig': 'There are many ways to identify the shape of dataset, one of them is using .shape attribute!\\ndf.shape\\ndf.shape[0] # for identify the number of rows\\ndf.shape[1] # for identify the number of columns\\nAdded by Radikal Lukafiardi',\n",
       "  'document': '58c1c168',\n",
       "  'question': 'What attribute in Pandas helps identify the number of rows in a dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You would use the `.shape` attribute to identify the number of columns in a Pandas DataFrame. Specifically, you can access it with `df.shape[1]` to get the number of columns.',\n",
       "  'answer_orig': 'There are many ways to identify the shape of dataset, one of them is using .shape attribute!\\ndf.shape\\ndf.shape[0] # for identify the number of rows\\ndf.shape[1] # for identify the number of columns\\nAdded by Radikal Lukafiardi',\n",
       "  'document': '58c1c168',\n",
       "  'question': 'Which attribute would you use to identify the number of columns in a Pandas DataFrame?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The information about identifying the shape of a dataset was contributed by Radikal Lukafiardi.',\n",
       "  'answer_orig': 'There are many ways to identify the shape of dataset, one of them is using .shape attribute!\\ndf.shape\\ndf.shape[0] # for identify the number of rows\\ndf.shape[1] # for identify the number of columns\\nAdded by Radikal Lukafiardi',\n",
       "  'document': '58c1c168',\n",
       "  'question': 'Who contributed the information about identifying the shape of a dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'One method to find the shape of a dataset in Pandas is by using the `.shape` attribute. For example, you can use `df.shape` to get the overall shape, `df.shape[0]` to identify the number of rows, and `df.shape[1]` to identify the number of columns.',\n",
       "  'answer_orig': 'There are many ways to identify the shape of dataset, one of them is using .shape attribute!\\ndf.shape\\ndf.shape[0] # for identify the number of rows\\ndf.shape[1] # for identify the number of columns\\nAdded by Radikal Lukafiardi',\n",
       "  'document': '58c1c168',\n",
       "  'question': 'What is one method to find the shape of a dataset in Pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To avoid value errors in your homework when performing matrix multiplication, you should use `np.dot()` or the `@` operator (or `np.matmul()`). It's essential to ensure that the number of columns in the first matrix matches the number of rows in the second matrix for the multiplication to be valid. Remember that the order of multiplication matters and can affect the result.\",\n",
       "  'answer_orig': 'First of all use np.dot for matrix multiplication. When you compute matrix-matrix multiplication you should understand that order of multiplying is crucial and affects the result of the multiplication!\\nDimension Mismatch\\nTo perform matrix multiplication, the number of columns in the 1st matrix should match the number of rows in the 2nd matrix. You can rearrange the order to make sure that this satisfies the condition.\\nAdded by Leah Gotladera',\n",
       "  'document': '96076a1a',\n",
       "  'question': 'What function should I use for matrix multiplication to avoid value errors in our homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The order of matrices is important in matrix multiplication because changing the order changes the result, as they can yield matrices of different sizes and usually different values. Specifically, if you have two matrices A (m x n) and B (n x p), the product A * B results in a matrix C (m x p), while the product B * A results in a matrix D (n x n). Since C and D can be of different dimensions and values, the order of multiplication must be respected to achieve the correct result.',\n",
       "  'answer_orig': 'First of all use np.dot for matrix multiplication. When you compute matrix-matrix multiplication you should understand that order of multiplying is crucial and affects the result of the multiplication!\\nDimension Mismatch\\nTo perform matrix multiplication, the number of columns in the 1st matrix should match the number of rows in the 2nd matrix. You can rearrange the order to make sure that this satisfies the condition.\\nAdded by Leah Gotladera',\n",
       "  'document': '96076a1a',\n",
       "  'question': 'Why is the order of matrices important in matrix multiplication?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To check if the dimensions of two matrices are compatible for multiplication, you need to ensure that the number of columns in the first matrix matches the number of rows in the second matrix. If you encounter a dimension mismatch, consider rearranging the order of the matrices to satisfy this condition.',\n",
       "  'answer_orig': 'First of all use np.dot for matrix multiplication. When you compute matrix-matrix multiplication you should understand that order of multiplying is crucial and affects the result of the multiplication!\\nDimension Mismatch\\nTo perform matrix multiplication, the number of columns in the 1st matrix should match the number of rows in the 2nd matrix. You can rearrange the order to make sure that this satisfies the condition.\\nAdded by Leah Gotladera',\n",
       "  'document': '96076a1a',\n",
       "  'question': 'How can I check if the dimensions of two matrices are compatible for multiplication?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The number of columns in the first matrix should match the number of rows in the second matrix when doing matrix multiplication.',\n",
       "  'answer_orig': 'First of all use np.dot for matrix multiplication. When you compute matrix-matrix multiplication you should understand that order of multiplying is crucial and affects the result of the multiplication!\\nDimension Mismatch\\nTo perform matrix multiplication, the number of columns in the 1st matrix should match the number of rows in the 2nd matrix. You can rearrange the order to make sure that this satisfies the condition.\\nAdded by Leah Gotladera',\n",
       "  'document': '96076a1a',\n",
       "  'question': 'What should the number of columns in the first matrix match when doing matrix multiplication?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The information on avoiding Value errors with array shapes was provided by Leah Gotladera.',\n",
       "  'answer_orig': 'First of all use np.dot for matrix multiplication. When you compute matrix-matrix multiplication you should understand that order of multiplying is crucial and affects the result of the multiplication!\\nDimension Mismatch\\nTo perform matrix multiplication, the number of columns in the 1st matrix should match the number of rows in the 2nd matrix. You can rearrange the order to make sure that this satisfies the condition.\\nAdded by Leah Gotladera',\n",
       "  'document': '96076a1a',\n",
       "  'question': 'Who provided the information on avoiding Value errors with array shapes?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To handle NaN values in a column, you can replace them with the average of that column. First, calculate the average and save it to a variable. Then, replace the NaN values with this average variable. This process is known as imputing, and it allows you to retain rows with valuable information despite the presence of NaN values.',\n",
       "  'answer_orig': 'You would first get the average of the column and save it to a variable, then replace the NaN values with the average variable.\\nThis method is called imputing - when you have NaN/ null values in a column, but you do not want to get rid of the row because it has valuable information contributing to other columns.\\nAdded by Anneysha Sarkar',\n",
       "  'document': '3218389a',\n",
       "  'question': 'How do I handle NaN values in a column?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'We should keep rows with NaN values because they may contain valuable information that contributes to other columns in the dataset. Instead of discarding these rows, we can impute the NaN values (for example, by replacing them with the average of the column) to retain that useful information while still making the dataset usable for analysis.',\n",
       "  'answer_orig': 'You would first get the average of the column and save it to a variable, then replace the NaN values with the average variable.\\nThis method is called imputing - when you have NaN/ null values in a column, but you do not want to get rid of the row because it has valuable information contributing to other columns.\\nAdded by Anneysha Sarkar',\n",
       "  'document': '3218389a',\n",
       "  'question': 'Why should we keep rows with NaN values?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"In machine learning, 'imputing' refers to the method of replacing NaN (null) values in a dataset with a specific value, often the average of the column. This is done instead of removing rows with NaN values to retain valuable information that may contribute to other columns.\",\n",
       "  'answer_orig': 'You would first get the average of the column and save it to a variable, then replace the NaN values with the average variable.\\nThis method is called imputing - when you have NaN/ null values in a column, but you do not want to get rid of the row because it has valuable information contributing to other columns.\\nAdded by Anneysha Sarkar',\n",
       "  'document': '3218389a',\n",
       "  'question': \"What is meant by 'imputing' in machine learning?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Before replacing NaN values, you need to first calculate the average of the column where the NaN values are present and save it to a variable. Then, you can use that average variable to replace the NaN values. This process is known as imputing.',\n",
       "  'answer_orig': 'You would first get the average of the column and save it to a variable, then replace the NaN values with the average variable.\\nThis method is called imputing - when you have NaN/ null values in a column, but you do not want to get rid of the row because it has valuable information contributing to other columns.\\nAdded by Anneysha Sarkar',\n",
       "  'document': '3218389a',\n",
       "  'question': 'What needs to be done before replacing NaN values?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Replacing NaN values with the column average is done through a method called imputing. This is important because it allows you to retain rows that contain valuable information for other columns, rather than discarding those rows just because they have NaN values. By replacing the NaN values with the average of the column, you maintain the integrity of your dataset while addressing the missing data issue.',\n",
       "  'answer_orig': 'You would first get the average of the column and save it to a variable, then replace the NaN values with the average variable.\\nThis method is called imputing - when you have NaN/ null values in a column, but you do not want to get rid of the row because it has valuable information contributing to other columns.\\nAdded by Anneysha Sarkar',\n",
       "  'document': '3218389a',\n",
       "  'question': 'Why replace NaN values with the column average?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The mathematical formula for linear regression mentioned in Question 7 can be summarized as follows: a matrix \\\\( X \\\\) is multiplied by some unknown weights \\\\( w \\\\) resulting in the target \\\\( y \\\\).',\n",
       "  'answer_orig': 'In Question 7 we are asked to calculate\\nThe initial problem  can be solved by this, where a Matrix X is multiplied by some unknown weights w resulting in the target y.\\nAdditional reading and videos:\\nOrdinary least squares\\nMultiple Linear Regression in Matrix Form\\nPseudoinverse Solution to OLS\\nAdded by Sylvia Schmitt\\nwith commends from Dmytro Durach',\n",
       "  'document': '183a1c90',\n",
       "  'question': 'What is the mathematical formula for linear regression mentioned in Question 7?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To solve the initial problem involving a Matrix X in linear regression, you need to multiply the Matrix X by some unknown weights w to obtain the target y. This process is fundamental to setting up the linear regression model. For further insights, you may want to explore additional readings such as \"Ordinary least squares,\" \"Multiple Linear Regression in Matrix Form,\" and \"Pseudoinverse Solution to OLS.\"',\n",
       "  'answer_orig': 'In Question 7 we are asked to calculate\\nThe initial problem  can be solved by this, where a Matrix X is multiplied by some unknown weights w resulting in the target y.\\nAdditional reading and videos:\\nOrdinary least squares\\nMultiple Linear Regression in Matrix Form\\nPseudoinverse Solution to OLS\\nAdded by Sylvia Schmitt\\nwith commends from Dmytro Durach',\n",
       "  'document': '183a1c90',\n",
       "  'question': 'How can I solve the initial problem involving a Matrix X in linear regression?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The additional reading recommended for understanding ordinary least squares includes:\\n\\n- Ordinary least squares\\n- Multiple Linear Regression in Matrix Form\\n- Pseudoinverse Solution to OLS\\n\\nThese materials were added by Sylvia Schmitt and received comments from Dmytro Durach.',\n",
       "  'answer_orig': 'In Question 7 we are asked to calculate\\nThe initial problem  can be solved by this, where a Matrix X is multiplied by some unknown weights w resulting in the target y.\\nAdditional reading and videos:\\nOrdinary least squares\\nMultiple Linear Regression in Matrix Form\\nPseudoinverse Solution to OLS\\nAdded by Sylvia Schmitt\\nwith commends from Dmytro Durach',\n",
       "  'document': '183a1c90',\n",
       "  'question': 'What additional reading is recommended for understanding ordinary least squares?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find more resources about multiple linear regression in matrix form in the additional reading and videos section of the course material. Here are some specific resources mentioned: \\n\\n- Ordinary least squares\\n- Multiple Linear Regression in Matrix Form\\n- Pseudoinverse Solution to OLS\\n\\nThese resources will provide you with valuable information on the topic.',\n",
       "  'answer_orig': 'In Question 7 we are asked to calculate\\nThe initial problem  can be solved by this, where a Matrix X is multiplied by some unknown weights w resulting in the target y.\\nAdditional reading and videos:\\nOrdinary least squares\\nMultiple Linear Regression in Matrix Form\\nPseudoinverse Solution to OLS\\nAdded by Sylvia Schmitt\\nwith commends from Dmytro Durach',\n",
       "  'document': '183a1c90',\n",
       "  'question': 'Where can I find more resources about multiple linear regression in matrix form?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The information about the mathematical formula for linear regression was added by Sylvia Schmitt, with comments from Dmytro Durach.',\n",
       "  'answer_orig': 'In Question 7 we are asked to calculate\\nThe initial problem  can be solved by this, where a Matrix X is multiplied by some unknown weights w resulting in the target y.\\nAdditional reading and videos:\\nOrdinary least squares\\nMultiple Linear Regression in Matrix Form\\nPseudoinverse Solution to OLS\\nAdded by Sylvia Schmitt\\nwith commends from Dmytro Durach',\n",
       "  'document': '183a1c90',\n",
       "  'question': 'Who added the information about the mathematical formula for linear regression?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The final multiplication does not have 5 columns in section 1 because it is likely that the first step of the multiplication was interchanged, which would lead to an incorrect shape of the resulting matrix.',\n",
       "  'answer_orig': 'This is most likely that you interchanged the first step of the multiplication\\nYou used  instead of\\nAdded by Emmanuel Ikpesu',\n",
       "  'document': 'f0bc1c19',\n",
       "  'question': 'Why does the final multiplication not have 5 columns in section 1?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The issue with the final multiplication missing columns is most likely caused by interchanging the first step of the multiplication. This can lead to incorrect dimensions in the resulting matrix.',\n",
       "  'answer_orig': 'This is most likely that you interchanged the first step of the multiplication\\nYou used  instead of\\nAdded by Emmanuel Ikpesu',\n",
       "  'document': 'f0bc1c19',\n",
       "  'question': 'What likely caused the issue with the final multiplication missing columns?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, interchanging the first step of multiplication can cause errors. In matrix multiplication, the order is important, as changing the order results in matrices of different sizes and usually different values. This can lead to errors if the dimensions do not align correctly for the intended calculation.',\n",
       "  'answer_orig': 'This is most likely that you interchanged the first step of the multiplication\\nYou used  instead of\\nAdded by Emmanuel Ikpesu',\n",
       "  'document': 'f0bc1c19',\n",
       "  'question': 'Can interchanging the first step of multiplication cause errors?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The note about the multiplication step error was added by Emmanuel Ikpesu.',\n",
       "  'answer_orig': 'This is most likely that you interchanged the first step of the multiplication\\nYou used  instead of\\nAdded by Emmanuel Ikpesu',\n",
       "  'document': 'f0bc1c19',\n",
       "  'question': 'Who added the note about the multiplication step error?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If your final multiplication in the first section is incorrect, you should check if you interchanged the first step of the multiplication. This may cause issues such as not having the correct number of columns. Additionally, remember that the order of multiplication is crucial when performing matrix operations, as it affects the result. Make sure the number of columns in the first matrix matches the number of rows in the second matrix for proper matrix multiplication.',\n",
       "  'answer_orig': 'This is most likely that you interchanged the first step of the multiplication\\nYou used  instead of\\nAdded by Emmanuel Ikpesu',\n",
       "  'document': 'f0bc1c19',\n",
       "  'question': 'What should I check if my final multiplication is incorrect in the first section?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'When performing matrix-matrix multiplication in Python, the preferred operators are `@` or `np.matmul()`.',\n",
       "  'answer_orig': 'Note, that matrix multiplication (matrix-matrix, matrix-vector multiplication) can be written as * operator in some sources, but performed as @ operator or np.matmul() via numpy. * operator performs element-wise multiplication (Hadamard product).\\nnumpy.dot() or ndarray.dot() can be used, but for matrix-matrix multiplication @ or np.matmul() is preferred (as per numpy doc).\\nIf multiplying by a scalar numpy.multiply() or * is preferred.\\nAdded by Andrii Larkin',\n",
       "  'document': '735e6c78',\n",
       "  'question': 'When performing matrix-matrix multiplication in Python, which operator is preferred?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Matrix-vector multiplication can be written as the * operator in some sources, but it is performed as the @ operator or np.matmul() via numpy. It is important to note that the * operator performs element-wise multiplication (Hadamard product).',\n",
       "  'answer_orig': 'Note, that matrix multiplication (matrix-matrix, matrix-vector multiplication) can be written as * operator in some sources, but performed as @ operator or np.matmul() via numpy. * operator performs element-wise multiplication (Hadamard product).\\nnumpy.dot() or ndarray.dot() can be used, but for matrix-matrix multiplication @ or np.matmul() is preferred (as per numpy doc).\\nIf multiplying by a scalar numpy.multiply() or * is preferred.\\nAdded by Andrii Larkin',\n",
       "  'document': '735e6c78',\n",
       "  'question': 'How can matrix-vector multiplication be written in some sources?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The * symbol in numpy performs element-wise multiplication (Hadamard product).',\n",
       "  'answer_orig': 'Note, that matrix multiplication (matrix-matrix, matrix-vector multiplication) can be written as * operator in some sources, but performed as @ operator or np.matmul() via numpy. * operator performs element-wise multiplication (Hadamard product).\\nnumpy.dot() or ndarray.dot() can be used, but for matrix-matrix multiplication @ or np.matmul() is preferred (as per numpy doc).\\nIf multiplying by a scalar numpy.multiply() or * is preferred.\\nAdded by Andrii Larkin',\n",
       "  'document': '735e6c78',\n",
       "  'question': 'What operator does the * symbol perform in numpy?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'For scalar multiplication in numpy, you can use `numpy.multiply()` or the `*` operator.',\n",
       "  'answer_orig': 'Note, that matrix multiplication (matrix-matrix, matrix-vector multiplication) can be written as * operator in some sources, but performed as @ operator or np.matmul() via numpy. * operator performs element-wise multiplication (Hadamard product).\\nnumpy.dot() or ndarray.dot() can be used, but for matrix-matrix multiplication @ or np.matmul() is preferred (as per numpy doc).\\nIf multiplying by a scalar numpy.multiply() or * is preferred.\\nAdded by Andrii Larkin',\n",
       "  'document': '735e6c78',\n",
       "  'question': 'What functions can be used for scalar multiplication in numpy?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The information about multiplication operators was provided by Andrii Larkin.',\n",
       "  'answer_orig': 'Note, that matrix multiplication (matrix-matrix, matrix-vector multiplication) can be written as * operator in some sources, but performed as @ operator or np.matmul() via numpy. * operator performs element-wise multiplication (Hadamard product).\\nnumpy.dot() or ndarray.dot() can be used, but for matrix-matrix multiplication @ or np.matmul() is preferred (as per numpy doc).\\nIf multiplying by a scalar numpy.multiply() or * is preferred.\\nAdded by Andrii Larkin',\n",
       "  'document': '735e6c78',\n",
       "  'question': 'Who provided the information about multiplication operators?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If you encounter an ImportError related to Jinja2 when launching a new Jupyter notebook in a new environment, you should switch to the main environment and run the following command: \\n\\n```\\npip install nbconvert --upgrade\\n```',\n",
       "  'answer_orig': 'If you face an error kind of ImportError: cannot import name \\'contextfilter\\' from \\'jinja2\\' (anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\__init__.py) when launching a new notebook for a brand new environment.\\nSwitch to the main environment and run \"pip install nbconvert --upgrade\".\\nAdded by George Chizhmak',\n",
       "  'document': 'b8ca1cd3',\n",
       "  'question': 'What should I do if I encounter an ImportError when launching a new Jupyter notebook in a new environment?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To resolve the error related to 'contextfilter' from 'jinja2' when starting a Jupyter notebook, switch to the main environment and run the command `pip install nbconvert --upgrade`.\",\n",
       "  'answer_orig': 'If you face an error kind of ImportError: cannot import name \\'contextfilter\\' from \\'jinja2\\' (anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\__init__.py) when launching a new notebook for a brand new environment.\\nSwitch to the main environment and run \"pip install nbconvert --upgrade\".\\nAdded by George Chizhmak',\n",
       "  'document': 'b8ca1cd3',\n",
       "  'question': \"How can I resolve an error related to 'contextfilter' from 'jinja2' when starting a Jupyter notebook?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To fix the ImportError involving 'contextfilter' from 'jinja2', you should switch to the main environment and run the command:\\n\\n```\\npip install nbconvert --upgrade\\n```\",\n",
       "  'answer_orig': 'If you face an error kind of ImportError: cannot import name \\'contextfilter\\' from \\'jinja2\\' (anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\__init__.py) when launching a new notebook for a brand new environment.\\nSwitch to the main environment and run \"pip install nbconvert --upgrade\".\\nAdded by George Chizhmak',\n",
       "  'document': 'b8ca1cd3',\n",
       "  'question': \"What command should I run to fix the ImportError involving 'contextfilter' from 'jinja2'?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The solution for ImportError issues when launching Jupyter notebooks was added by George Chizhmak.',\n",
       "  'answer_orig': 'If you face an error kind of ImportError: cannot import name \\'contextfilter\\' from \\'jinja2\\' (anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\__init__.py) when launching a new notebook for a brand new environment.\\nSwitch to the main environment and run \"pip install nbconvert --upgrade\".\\nAdded by George Chizhmak',\n",
       "  'document': 'b8ca1cd3',\n",
       "  'question': 'Who added the solution for ImportError issues when launching Jupyter notebooks?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To solve the \\'contextfilter\\' ImportError in Jupyter notebook, you need to switch to the main environment and run the command: \"pip install nbconvert --upgrade\".',\n",
       "  'answer_orig': 'If you face an error kind of ImportError: cannot import name \\'contextfilter\\' from \\'jinja2\\' (anaconda\\\\lib\\\\site-packages\\\\jinja2\\\\__init__.py) when launching a new notebook for a brand new environment.\\nSwitch to the main environment and run \"pip install nbconvert --upgrade\".\\nAdded by George Chizhmak',\n",
       "  'document': 'b8ca1cd3',\n",
       "  'question': \"Which package do I need to upgrade to solve the 'contextfilter' ImportError in Jupyter notebook?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If you encounter wget hanging on MacOS Ventura M1 and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. After making this change, try running wget again.',\n",
       "  'answer_orig': 'If you face this situation and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. Then try again',\n",
       "  'document': 'efdb235f',\n",
       "  'question': 'How do I fix wget hanging on MacOS Ventura M1?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If `wget` shows IPv6 addresses and hangs, you should go to your System Settings > Network > your network connection > Details > Configure IPv6, set it to Manually, then click OK. After doing this, try using `wget` again.',\n",
       "  'answer_orig': 'If you face this situation and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. Then try again',\n",
       "  'document': 'efdb235f',\n",
       "  'question': 'What should I do if wget shows IPv6 addresses and hangs?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To configure IPv6 settings on MacOS Ventura M1, go to your System Settings, then select Network. Choose your network connection, click on Details, and under Configure IPv6, set it to Manually. Finally, click OK and try your action again.',\n",
       "  'answer_orig': 'If you face this situation and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. Then try again',\n",
       "  'document': 'efdb235f',\n",
       "  'question': 'How do I configure IPv6 settings on MacOS Ventura M1?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To set IPv6 to Manually on MacOS Ventura, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK.',\n",
       "  'answer_orig': 'If you face this situation and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. Then try again',\n",
       "  'document': 'efdb235f',\n",
       "  'question': 'Where can I find the option to set IPv6 to Manually on MacOS Ventura?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Wget does not come pre-installed with macOS, including MacOS M1. If you are facing issues with wget, you can use alternatives such as curl to download files. The recommended command to use with curl is:\\n\\n```bash\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\nIf you specifically want to use wget, you can install it using Homebrew by running:\\n\\n```bash\\nbrew install wget\\n```\\n\\nThis should help resolve any issues you're experiencing with wget on your MacOS M1 device.\",\n",
       "  'answer_orig': 'If you face this situation and see IPv6 addresses in the terminal, go to your System Settings > Network > your network connection > Details > Configure IPv6 > set to Manually > OK. Then try again',\n",
       "  'document': 'efdb235f',\n",
       "  'question': 'Is there a network setting adjustment for wget issues on MacOS M1?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If you are using macOS and having trouble with Wget, you can use `curl` as an alternative. Here is an example of how to use it:\\n\\n```bash\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\n`curl` is a utility for retrieving information from the internet, and this command will store the downloaded file with the name you provide.',\n",
       "  'answer_orig': \"Wget doesn't ship with macOS, so there are other alternatives to use.\\nNo worries, we got curl:\\nexample:\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nExplanations:\\ncurl: a utility for retrieving information from the internet.\\n-o: Tell it to store the result as a file.\\nfilename: You choose the file's name.\\nLinks: Put the web address (URL) here, and cURL will extract data from it and save it under the name you provide.\\nMore about it at:\\nCurl Documentation\\nAdded by David Espejo\",\n",
       "  'document': '355348f0',\n",
       "  'question': 'What alternative can I use to Wget if I am using macOS?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To download a file using curl on macOS, you can use the following command:\\n\\n```bash\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\nIn this command:\\n- `curl` is a utility for retrieving information from the internet.\\n- `-o` tells curl to store the result as a file.\\n- `./housing.csv` is the name you choose for the downloaded file.\\n- The URL provided is the location of the file you want to download. \\n\\nThis command will extract data from the specified URL and save it as `housing.csv` in your current directory.',\n",
       "  'answer_orig': \"Wget doesn't ship with macOS, so there are other alternatives to use.\\nNo worries, we got curl:\\nexample:\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nExplanations:\\ncurl: a utility for retrieving information from the internet.\\n-o: Tell it to store the result as a file.\\nfilename: You choose the file's name.\\nLinks: Put the web address (URL) here, and cURL will extract data from it and save it under the name you provide.\\nMore about it at:\\nCurl Documentation\\nAdded by David Espejo\",\n",
       "  'document': '355348f0',\n",
       "  'question': 'Can you provide an example of using curl to download a file on macOS?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The -o option in the curl command is used to tell curl to store the result as a file. You can choose the filename for the saved file, and curl will extract data from the specified web address (URL) and save it under the name you provide.',\n",
       "  'answer_orig': \"Wget doesn't ship with macOS, so there are other alternatives to use.\\nNo worries, we got curl:\\nexample:\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nExplanations:\\ncurl: a utility for retrieving information from the internet.\\n-o: Tell it to store the result as a file.\\nfilename: You choose the file's name.\\nLinks: Put the web address (URL) here, and cURL will extract data from it and save it under the name you provide.\\nMore about it at:\\nCurl Documentation\\nAdded by David Espejo\",\n",
       "  'document': '355348f0',\n",
       "  'question': 'What does the -o option do in the curl command?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To specify the name of the file when using curl on macOS, you can use the `-o` option followed by the desired filename. For example, the command would look like this: \\n\\n```bash\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\nIn this command, `-o` tells curl to store the result as a file, and `housing.csv` is the name you choose for the file.',\n",
       "  'answer_orig': \"Wget doesn't ship with macOS, so there are other alternatives to use.\\nNo worries, we got curl:\\nexample:\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nExplanations:\\ncurl: a utility for retrieving information from the internet.\\n-o: Tell it to store the result as a file.\\nfilename: You choose the file's name.\\nLinks: Put the web address (URL) here, and cURL will extract data from it and save it under the name you provide.\\nMore about it at:\\nCurl Documentation\\nAdded by David Espejo\",\n",
       "  'document': '355348f0',\n",
       "  'question': 'How do you specify the name of the file when using curl on macOS?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find more information about using curl in the Curl Documentation, as mentioned in the context provided.',\n",
       "  'answer_orig': \"Wget doesn't ship with macOS, so there are other alternatives to use.\\nNo worries, we got curl:\\nexample:\\ncurl -o ./housing.csv https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nExplanations:\\ncurl: a utility for retrieving information from the internet.\\n-o: Tell it to store the result as a file.\\nfilename: You choose the file's name.\\nLinks: Put the web address (URL) here, and cURL will extract data from it and save it under the name you provide.\\nMore about it at:\\nCurl Documentation\\nAdded by David Espejo\",\n",
       "  'document': '355348f0',\n",
       "  'question': 'Where can I find more information about using curl?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"You can use the `round()` function or f-strings to limit the number of decimal places. For example, you can round a number to 4 decimal places using `round(number, 4)`. Alternatively, you can use f-strings like `print(f'Average mark for the Homework is {avg:.3f}')` to format a number to 3 decimal places. Additionally, if you want to round values in a whole Series, you can use `pandas.Series.round()`. Please refer to the documentation for more details: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round.\",\n",
       "  'answer_orig': \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\",\n",
       "  'document': '67afabf5',\n",
       "  'question': 'What function can I use to limit a number of decimal places?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To round a number to 4 decimal places in Python, you can use the `round()` function like this:\\n\\n```python\\nrounded_number = round(number, 4)\\n```\\n\\nAdditionally, if you want to format a number while printing, you can use f-strings:\\n\\n```python\\nprint(f'Your number is {number:.4f}')\\n```\\n\\nIf you're working with a pandas Series and want to round all values in the Series, you can utilize the `round()` method available in pandas. For more details, check the pandas documentation at [pandas.Series.round](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round).\",\n",
       "  'answer_orig': \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\",\n",
       "  'document': '67afabf5',\n",
       "  'question': 'How can I round a number to 4 decimal places in Python?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To format a number to 3 decimal places using f-strings, you can use the following syntax:\\n\\n```python\\nprint(f'Average mark for the Homework is {avg:.3f}')\\n```\\n\\nThis will display the value of `avg` rounded to 3 decimal places.\",\n",
       "  'answer_orig': \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\",\n",
       "  'document': '67afabf5',\n",
       "  'question': 'Can you demonstrate using f-strings to format a number to 3 decimal places?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is a function to round an entire Series in pandas. You can use the `pandas.Series.round()` method to round the values in the whole Series. For more details, you can check the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round).',\n",
       "  'answer_orig': \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\",\n",
       "  'document': '67afabf5',\n",
       "  'question': 'Is there a function to round an entire Series in pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find more information about rounding values in pandas Series by checking the documentation for the `pandas.Series.round` function at the following link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round. This function allows you to round the values in the entire Series.',\n",
       "  'answer_orig': \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\",\n",
       "  'document': '67afabf5',\n",
       "  'question': 'Where can I find more information about rounding values in pandas Series?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can ask questions for the Live Sessions for Week 2 at the following link: [Ask questions for Live Sessions](https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions).',\n",
       "  'answer_orig': 'Here are the crucial links for this Week 2 that starts September 18, 2023\\nAsk questions for Live Sessions: https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions\\nCalendar for weekly meetings: https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1\\nWeek 2 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md\\nSubmit HW Week 2: https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform (also available at the bottom of the above link)\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 2.X --- https://www.youtube.com/watch?v=vM3SqPNlStE&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=12\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~Nukta Bhatia~~',\n",
       "  'document': '50d737e7',\n",
       "  'question': 'Where can I ask questions for the Live Sessions for Week 2?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The start date for Week 2 of the Machine Learning for Regression course is September 18, 2023.',\n",
       "  'answer_orig': 'Here are the crucial links for this Week 2 that starts September 18, 2023\\nAsk questions for Live Sessions: https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions\\nCalendar for weekly meetings: https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1\\nWeek 2 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md\\nSubmit HW Week 2: https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform (also available at the bottom of the above link)\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 2.X --- https://www.youtube.com/watch?v=vM3SqPNlStE&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=12\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~Nukta Bhatia~~',\n",
       "  'document': '50d737e7',\n",
       "  'question': 'What is the start date for Week 2 of the Machine Learning for Regression course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find the Week 2 homework for the course at the following link: [Week 2 HW](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md).',\n",
       "  'answer_orig': 'Here are the crucial links for this Week 2 that starts September 18, 2023\\nAsk questions for Live Sessions: https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions\\nCalendar for weekly meetings: https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1\\nWeek 2 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md\\nSubmit HW Week 2: https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform (also available at the bottom of the above link)\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 2.X --- https://www.youtube.com/watch?v=vM3SqPNlStE&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=12\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~Nukta Bhatia~~',\n",
       "  'document': '50d737e7',\n",
       "  'question': 'Where can I find the Week 2 homework for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can submit the Week 2 homework using the following link: [Submit HW Week 2](https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform). This link is also available at the bottom of the Week 2 homework page: [Week 2 HW](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md).',\n",
       "  'answer_orig': 'Here are the crucial links for this Week 2 that starts September 18, 2023\\nAsk questions for Live Sessions: https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions\\nCalendar for weekly meetings: https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1\\nWeek 2 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md\\nSubmit HW Week 2: https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform (also available at the bottom of the above link)\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 2.X --- https://www.youtube.com/watch?v=vM3SqPNlStE&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=12\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~Nukta Bhatia~~',\n",
       "  'document': '50d737e7',\n",
       "  'question': 'How can I submit the Week 2 homework?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can check the calendar for the weekly meetings at this link: [Calendar for weekly meetings](https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1).',\n",
       "  'answer_orig': 'Here are the crucial links for this Week 2 that starts September 18, 2023\\nAsk questions for Live Sessions: https://app.sli.do/event/vsUpjYsayZ8A875Hq8dpUa/live/questions\\nCalendar for weekly meetings: https://calendar.google.com/calendar/u/0/r?cid=cGtjZ2tkbGc1OG9yb2lxa2Vwc2g4YXMzMmNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&pli=1\\nWeek 2 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/02-regression/homework.md\\nSubmit HW Week 2: https://docs.google.com/forms/d/e/1FAIpQLSf8eMtnErPFqzzFsEdLap_GZ2sMih-H-Y7F_IuPGqt4fOmOJw/viewform (also available at the bottom of the above link)\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYoutube Link: 2.X --- https://www.youtube.com/watch?v=vM3SqPNlStE&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=12\\nFAQs: https://docs.google.com/document/d/1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8/edit#heading=h.lpz96zg7l47j\\n~~Nukta Bhatia~~',\n",
       "  'document': '50d737e7',\n",
       "  'question': 'Where can I check the calendar for the weekly meetings?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To visualize the distribution of the `median_house_value` in the housing dataset, you can use a histogram. Here\\'s an example of how to do this using Python:\\n\\n```python\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\n```\\n\\nAlternatively, you can check the skewness of the `median_house_value` and use the `describe` method:\\n\\n```python\\n# Check skewness and describe\\nprint(df[\\'median_house_value\\'].describe())\\n\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n```',\n",
       "  'answer_orig': 'We can use histogram:\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\nOR ceck skewness and describe:\\nprint(df[\\'median_house_value\\'].describe())\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\n# Print the skewness value\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n(Mohammad Emad Sharifi)',\n",
       "  'document': 'bbc0fca3',\n",
       "  'question': 'How can we visualize the distribution of the median_house_value in the housing dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To check the skewness of the `median_house_value` variable from the dataset, you can use the following method:\\n\\n1. Calculate the skewness of the variable using the `skew()` function in pandas:\\n   ```python\\n   skewness = df[\\'median_house_value\\'].skew()\\n   ```\\n\\n2. Print the skewness value:\\n   ```python\\n   print(\"Skewness of \\'median_house_value\\':\", skewness)\\n   ```\\n\\nAdditionally, you can visualize the distribution of the variable using a histogram with seaborn:\\n```python\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\n```\\n\\nThese methods will help you check the skewness of the `median_house_value` variable in the dataset.',\n",
       "  'answer_orig': 'We can use histogram:\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\nOR ceck skewness and describe:\\nprint(df[\\'median_house_value\\'].describe())\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\n# Print the skewness value\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n(Mohammad Emad Sharifi)',\n",
       "  'document': 'bbc0fca3',\n",
       "  'question': 'What is a method to check the skewness of the median_house_value variable from the dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To generate a histogram for the `median_house_value`, the following Python libraries are needed:\\n\\n1. `pandas` - for data manipulation and analysis.\\n2. `matplotlib.pyplot` - for plotting graphs.\\n3. `seaborn` - for advanced data visualization.\\n\\nYou can use them as shown in the example:\\n\\n```python\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n```',\n",
       "  'answer_orig': 'We can use histogram:\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\nOR ceck skewness and describe:\\nprint(df[\\'median_house_value\\'].describe())\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\n# Print the skewness value\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n(Mohammad Emad Sharifi)',\n",
       "  'document': 'bbc0fca3',\n",
       "  'question': 'Which Python libraries are needed to generate a histogram for the median_house_value?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"The command `sns.histplot(df['median_house_value'], kde=False)` creates a histogram of the 'median_house_value' column from the DataFrame `df`. The parameter `kde=False` indicates that no Kernel Density Estimate (KDE) curve will be added to the plot. This visual representation helps to understand the distribution and potential long tail of the 'median_house_value' data.\",\n",
       "  'answer_orig': 'We can use histogram:\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\nOR ceck skewness and describe:\\nprint(df[\\'median_house_value\\'].describe())\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\n# Print the skewness value\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n(Mohammad Emad Sharifi)',\n",
       "  'document': 'bbc0fca3',\n",
       "  'question': \"What does the command sns.histplot(df['median_house_value'], kde=False) do?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Checking the distribution or skewness of the target variable is important in machine learning for regression because it helps to understand the characteristics of the data set. If the target variable is highly skewed, transforming it using logarithm distribution can be beneficial. This transformation can help to stabilize variance and make the model's assumptions more valid, thus potentially improving the performance of the regression model. Plotting the distribution of the target variable is the easiest way to evaluate its skewness.\",\n",
       "  'answer_orig': 'We can use histogram:\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n# Load the data\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\ndf = pd.read_csv(url)\\n# EDA\\nsns.histplot(df[\\'median_house_value\\'], kde=False)\\nplt.show()\\nOR ceck skewness and describe:\\nprint(df[\\'median_house_value\\'].describe())\\n# Calculate the skewness of the \\'median_house_value\\' variable\\nskewness = df[\\'median_house_value\\'].skew()\\n# Print the skewness value\\nprint(\"Skewness of \\'median_house_value\\':\", skewness)\\n(Mohammad Emad Sharifi)',\n",
       "  'document': 'bbc0fca3',\n",
       "  'question': 'Why is checking the distribution or skewness important in machine learning for regression?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"You might encounter a LinAlgError: Singular matrix error while following course videos due to a few reasons. Firstly, it can happen because not every matrix can be inverted, which is one of the main causes of a singular matrix error. Specifically, in the course, it often occurs when dealing with matrix multiplication, as the order in which matrices are multiplied is crucial. Make sure to respect the order of multiplication, as X.dot(Y) is not necessarily equal to Y.dot(X). \\n\\nAdditionally, if you have performed the inverse of X once in your code and attempt to do it again, that could also trigger the error. It's a normal part of the learning process, and the reason for this error will be further explained in the Regularization video.\",\n",
       "  'answer_orig': 'It’s possible that when you follow the videos, you’ll get a Singular Matrix error. We will explain why it happens in the Regularization video. Don’t worry, it’s normal that you have it.\\nYou can also have an error because you did the inverse of X once in your code and you’re doing it a second time.\\n(Added by Cécile Guillot)',\n",
       "  'document': '6f3bdd20',\n",
       "  'question': 'Why might I encounter a LinAlgError: Singular matrix error while following course videos?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, the Regularization video will explain why the LinAlgError: Singular matrix issue happens.',\n",
       "  'answer_orig': 'It’s possible that when you follow the videos, you’ll get a Singular Matrix error. We will explain why it happens in the Regularization video. Don’t worry, it’s normal that you have it.\\nYou can also have an error because you did the inverse of X once in your code and you’re doing it a second time.\\n(Added by Cécile Guillot)',\n",
       "  'document': '6f3bdd20',\n",
       "  'question': 'Will the Regularization video explain the LinAlgError: Singular matrix issue?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, it is normal to encounter a Singular Matrix error when following the course. It may happen during the lessons, and you will receive an explanation for it in the Regularization video. Don't worry, it's a common occurrence in the course.\",\n",
       "  'answer_orig': 'It’s possible that when you follow the videos, you’ll get a Singular Matrix error. We will explain why it happens in the Regularization video. Don’t worry, it’s normal that you have it.\\nYou can also have an error because you did the inverse of X once in your code and you’re doing it a second time.\\n(Added by Cécile Guillot)',\n",
       "  'document': '6f3bdd20',\n",
       "  'question': 'Is it normal to get a Singular Matrix error when following the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, performing the inverse of X twice in your code can cause a LinAlgError, specifically a Singular Matrix error. This can occur because not every matrix can be inverted, and if you attempt to invert it again after already performing the inverse, it may lead to such an error.',\n",
       "  'answer_orig': 'It’s possible that when you follow the videos, you’ll get a Singular Matrix error. We will explain why it happens in the Regularization video. Don’t worry, it’s normal that you have it.\\nYou can also have an error because you did the inverse of X once in your code and you’re doing it a second time.\\n(Added by Cécile Guillot)',\n",
       "  'document': '6f3bdd20',\n",
       "  'question': 'Can performing the inverse of X twice in my code cause a LinAlgError?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The additional information regarding the Singular Matrix error was provided by Cécile Guillot.',\n",
       "  'answer_orig': 'It’s possible that when you follow the videos, you’ll get a Singular Matrix error. We will explain why it happens in the Regularization video. Don’t worry, it’s normal that you have it.\\nYou can also have an error because you did the inverse of X once in your code and you’re doing it a second time.\\n(Added by Cécile Guillot)',\n",
       "  'document': '6f3bdd20',\n",
       "  'question': 'Who provided the additional information regarding the Singular Matrix error?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The context provided does not specify a particular dataset used for regression in the course. However, it mentions several general sources for datasets, including Kaggle, UCI Machine Learning Repository, and others. You may need to choose an appropriate dataset from those sources for your regression tasks.',\n",
       "  'answer_orig': 'You can find a detailed description of the dataset ere https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\\nKS',\n",
       "  'document': '27c2d90a',\n",
       "  'question': 'What dataset is used for regression in the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can find a detailed description of the California housing dataset [here](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html).',\n",
       "  'answer_orig': 'You can find a detailed description of the dataset ere https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\\nKS',\n",
       "  'document': '27c2d90a',\n",
       "  'question': 'Where can I find information about the California housing dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, details on the dataset used in Section 2, specifically the California housing dataset, can be found in the following link: [California housing dataset](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html).',\n",
       "  'answer_orig': 'You can find a detailed description of the dataset ere https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\\nKS',\n",
       "  'document': '27c2d90a',\n",
       "  'question': 'Do you provide details on the datasets used in Section 2?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, you can learn more about the California housing dataset by visiting the following link: [California housing dataset description](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html).',\n",
       "  'answer_orig': 'You can find a detailed description of the dataset ere https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\\nKS',\n",
       "  'document': '27c2d90a',\n",
       "  'question': 'Is there a link to learn more about the California housing dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To access the description for the dataset in Machine Learning for Regression, you will need to read the dataset directly from GitHub. You can do this by using the following code to load it into a pandas dataframe:\\n\\n```python\\ndfh = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\n```',\n",
       "  'answer_orig': 'You can find a detailed description of the dataset ere https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\\nKS',\n",
       "  'document': '27c2d90a',\n",
       "  'question': 'How can I access the description for the dataset in Machine Learning for Regression?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You got NaNs after applying .mean() when using for loops to calculate RMSE because there were NaN values present in your data. This issue occurred during the mean step of your RMSE function, specifically after squaring the errors. The root of the problem was that you only applied fillna(0) to the training data, not to the validation and test datasets. After applying fillna(0) to all datasets (train, val, test), the issue was resolved, and your for loops to calculate RMSE worked correctly.',\n",
       "  'answer_orig': 'I was using for loops to apply rmse to list of y_val and y_pred. But the resulting rmse is all nan.\\nI found out that the problem was when my data reached the mean step after squaring the error in the rmse function. Turned out there were nan in the array, then I traced the problem back to where I first started to split the data: I had only use fillna(0) on the train data, not on the validation and test data. So the problem was fixed after I applied fillna(0) to all the dataset (train, val, test). Voila, my for loops to get rmse from all the seed values work now.\\nAdded by Sasmito Yudha Husada',\n",
       "  'document': '88e9600a',\n",
       "  'question': 'Why did I get NaNs after applying .mean() when using for loops to calculate RMSE?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'I identified the cause of NaNs in my RMSE calculation by tracing the problem back to where I first started to split the data. Initially, I had used `fillna(0)` only on the train data and not on the validation and test data. This resulted in NaNs appearing in the array after squaring the errors in the RMSE function. Once I applied `fillna(0)` to all the datasets (train, validation, and test), the issue was resolved and my for loops to calculate RMSE from all the seed values worked correctly.',\n",
       "  'answer_orig': 'I was using for loops to apply rmse to list of y_val and y_pred. But the resulting rmse is all nan.\\nI found out that the problem was when my data reached the mean step after squaring the error in the rmse function. Turned out there were nan in the array, then I traced the problem back to where I first started to split the data: I had only use fillna(0) on the train data, not on the validation and test data. So the problem was fixed after I applied fillna(0) to all the dataset (train, val, test). Voila, my for loops to get rmse from all the seed values work now.\\nAdded by Sasmito Yudha Husada',\n",
       "  'document': '88e9600a',\n",
       "  'question': 'How did you identify the cause of NaNs in your RMSE calculation?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The issue leading to NaNs in the RMSE function was due to NaN values in the data array. This occurred because the user had only applied `fillna(0)` to the training data and not to the validation and test data. Once `fillna(0)` was applied to all datasets (train, validation, and test), the NaN issue was resolved, and the RMSE calculations worked correctly.',\n",
       "  'answer_orig': 'I was using for loops to apply rmse to list of y_val and y_pred. But the resulting rmse is all nan.\\nI found out that the problem was when my data reached the mean step after squaring the error in the rmse function. Turned out there were nan in the array, then I traced the problem back to where I first started to split the data: I had only use fillna(0) on the train data, not on the validation and test data. So the problem was fixed after I applied fillna(0) to all the dataset (train, val, test). Voila, my for loops to get rmse from all the seed values work now.\\nAdded by Sasmito Yudha Husada',\n",
       "  'document': '88e9600a',\n",
       "  'question': 'What was the issue with the data that led to NaNs in the RMSE function?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The problem of getting NaNs in the RMSE calculation was resolved by applying `fillna(0)` to all the datasets (train, validation, and test), instead of just the train data.',\n",
       "  'answer_orig': 'I was using for loops to apply rmse to list of y_val and y_pred. But the resulting rmse is all nan.\\nI found out that the problem was when my data reached the mean step after squaring the error in the rmse function. Turned out there were nan in the array, then I traced the problem back to where I first started to split the data: I had only use fillna(0) on the train data, not on the validation and test data. So the problem was fixed after I applied fillna(0) to all the dataset (train, val, test). Voila, my for loops to get rmse from all the seed values work now.\\nAdded by Sasmito Yudha Husada',\n",
       "  'document': '88e9600a',\n",
       "  'question': 'What step resolved the problem of getting NaNs in the RMSE calculation?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You needed to apply `fillna(0)` on all datasets, including train, validation, and test, because if you only applied it to the training data, any NaNs left in the validation and test datasets would result in errors or NaN values during subsequent calculations, such as when computing metrics like RMSE. Ensuring that all datasets are filled eliminates the risk of encountering NaN values during analysis, which can disrupt the processing and evaluation of your machine learning models.',\n",
       "  'answer_orig': 'I was using for loops to apply rmse to list of y_val and y_pred. But the resulting rmse is all nan.\\nI found out that the problem was when my data reached the mean step after squaring the error in the rmse function. Turned out there were nan in the array, then I traced the problem back to where I first started to split the data: I had only use fillna(0) on the train data, not on the validation and test data. So the problem was fixed after I applied fillna(0) to all the dataset (train, val, test). Voila, my for loops to get rmse from all the seed values work now.\\nAdded by Sasmito Yudha Husada',\n",
       "  'document': '88e9600a',\n",
       "  'question': 'Why did you need to apply fillna(0) on all datasets, including train, val, and test?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"We should transform the target variable to logarithm distribution when the target variable is highly skewed. This transformation helps to manage long tail distributions, such as prices, by stabilizing variance and making the data more normally distributed. The easiest way to evaluate this is by plotting the distribution of the target variable to assess skewness. However, it's important to note that if the target variable contains negative values, the logarithmic transformation cannot be applied.\",\n",
       "  'answer_orig': 'Why should we transform the target variable to logarithm distribution? Do we do this for all machine learning projects?\\nOnly if you see that your target is highly skewed. The easiest way to evaluate this is by plotting the distribution of the target variable.\\nThis can help to understand skewness and how it can be applied to the distribution of your data set.\\nhttps://en.wikipedia.org/wiki/Skewness\\nPastor Soto',\n",
       "  'document': 'd59d8df7',\n",
       "  'question': 'Why should we transform the target variable to logarithm distribution?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'We do not transform the target variable to logarithm distribution for all machine learning projects. This transformation is only applied if the target variable is highly skewed. The easiest way to evaluate skewness is by plotting the distribution of the target variable. If it has a long tail distribution, like in prices, you can transform it using the np.log1p() method, but this method cannot be used if the target variable has negative values.',\n",
       "  'answer_orig': 'Why should we transform the target variable to logarithm distribution? Do we do this for all machine learning projects?\\nOnly if you see that your target is highly skewed. The easiest way to evaluate this is by plotting the distribution of the target variable.\\nThis can help to understand skewness and how it can be applied to the distribution of your data set.\\nhttps://en.wikipedia.org/wiki/Skewness\\nPastor Soto',\n",
       "  'document': 'd59d8df7',\n",
       "  'question': 'Do we transform the target variable to logarithm distribution for all machine learning projects?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You should transform the target variable to a logarithm distribution when the target variable has a long tail distribution, such as prices, and exhibits a wide range. This can be done using the np.log1p() method. However, be cautious if your target variable has negative values, as this method will not be effective in that case. Additionally, transformation is beneficial if the target is highly skewed, which can be assessed by plotting its distribution.',\n",
       "  'answer_orig': 'Why should we transform the target variable to logarithm distribution? Do we do this for all machine learning projects?\\nOnly if you see that your target is highly skewed. The easiest way to evaluate this is by plotting the distribution of the target variable.\\nThis can help to understand skewness and how it can be applied to the distribution of your data set.\\nhttps://en.wikipedia.org/wiki/Skewness\\nPastor Soto',\n",
       "  'document': 'd59d8df7',\n",
       "  'question': 'When should we transform the target variable?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To evaluate if the target variable is highly skewed, you can plot the distribution of the target variable using a histogram. This visual representation will help you understand the skewness of the data. Additionally, you can calculate the skewness value using the `.skew()` method in Python. A significantly skewed value indicates that the target variable may need transformation.',\n",
       "  'answer_orig': 'Why should we transform the target variable to logarithm distribution? Do we do this for all machine learning projects?\\nOnly if you see that your target is highly skewed. The easiest way to evaluate this is by plotting the distribution of the target variable.\\nThis can help to understand skewness and how it can be applied to the distribution of your data set.\\nhttps://en.wikipedia.org/wiki/Skewness\\nPastor Soto',\n",
       "  'document': 'd59d8df7',\n",
       "  'question': 'How can we evaluate if the target variable is highly skewed?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Understanding the skewness of the target variable is important because it helps determine whether transformation, such as applying a logarithmic distribution, is needed. This is particularly relevant when the target variable has a long tail distribution, as in the case of prices. Evaluating the skewness by plotting the distribution of the target variable can guide decisions on how to transform the data, which can subsequently enhance the performance of machine learning models.',\n",
       "  'answer_orig': 'Why should we transform the target variable to logarithm distribution? Do we do this for all machine learning projects?\\nOnly if you see that your target is highly skewed. The easiest way to evaluate this is by plotting the distribution of the target variable.\\nThis can help to understand skewness and how it can be applied to the distribution of your data set.\\nhttps://en.wikipedia.org/wiki/Skewness\\nPastor Soto',\n",
       "  'document': 'd59d8df7',\n",
       "  'question': 'Why is it important to understand the skewness of the target variable?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can read a dataset directly from GitHub into a pandas dataframe using the following code:\\n\\n```python\\ndfh = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\n```',\n",
       "  'answer_orig': 'The dataset can be read directly to pandas dataframe from the github link using the technique shown below\\ndfh=pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\nKrishna Anand',\n",
       "  'document': '0b3eaf92',\n",
       "  'question': 'How can I read a dataset directly from GitHub into a pandas dataframe?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can load data from a GitHub link into pandas by using the following method:\\n\\n```python\\ndfh = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\n```\\n\\nThis reads the dataset directly into a pandas DataFrame.',\n",
       "  'answer_orig': 'The dataset can be read directly to pandas dataframe from the github link using the technique shown below\\ndfh=pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\nKrishna Anand',\n",
       "  'document': '0b3eaf92',\n",
       "  'question': 'What method allows me to load data from a GitHub link into pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To read data from a GitHub URL using pandas, you can use the following code:\\n\\n```python\\ndf = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\n```\\n\\nThis will directly load the dataset into a pandas dataframe from the provided GitHub link.',\n",
       "  'answer_orig': 'The dataset can be read directly to pandas dataframe from the github link using the technique shown below\\ndfh=pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\nKrishna Anand',\n",
       "  'document': '0b3eaf92',\n",
       "  'question': 'Could you explain how to read data from a GitHub URL using pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To import a dataset from a GitHub link into a pandas dataframe, you can use the following code:\\n\\n```python\\ndfh = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\n```',\n",
       "  'answer_orig': 'The dataset can be read directly to pandas dataframe from the github link using the technique shown below\\ndfh=pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\nKrishna Anand',\n",
       "  'document': '0b3eaf92',\n",
       "  'question': 'What is the code to import a dataset from a GitHub link into a pandas dataframe?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To fetch data from a GitHub repository into a pandas dataframe, you can use the following method:\\n\\n```python\\ndfh = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\n```\\n\\nAlternatively, you can also use the `requests` library to download the dataset first and then read it into a pandas dataframe:\\n\\n```python\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\n    with open(\\'housing.csv\\', \\'wb\\') as file:\\n        file.write(response.content)\\n        \\ndf = pd.read_csv(\\'housing.csv\\')\\n```\\n\\nBoth methods will allow you to load the data from the GitHub repository into a pandas dataframe.',\n",
       "  'answer_orig': 'The dataset can be read directly to pandas dataframe from the github link using the technique shown below\\ndfh=pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")\\nKrishna Anand',\n",
       "  'document': '0b3eaf92',\n",
       "  'question': 'How do I fetch data from a GitHub repository into a pandas dataframe?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To load the dataset directly into Kaggle Notebooks, you can use the following command:\\n\\n```bash\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\nMake sure to include the `!` before `wget`, as it is essential. Once the dataset is loaded to the Kaggle notebook server, you can read it using the following pandas command:\\n\\n```python\\ndf = pd.read_csv('housing.csv')\\n```\",\n",
       "  'answer_orig': \"For users of kaggle notebooks, the dataset can be loaded through widget using the below command. Please remember that ! before wget is essential\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nOnce the dataset is loaded to the kaggle notebook server, it can be read through the below pandas command\\ndf = pd.read_csv('housing.csv')\\nHarish Balasundaram\",\n",
       "  'document': '8fe56032',\n",
       "  'question': 'How can I load the dataset directly into Kaggle Notebooks?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'To download the dataset to Kaggle Notebooks, use the following command:\\n\\n```\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n```\\n\\nMake sure to include the `!` before the `wget` command.',\n",
       "  'answer_orig': \"For users of kaggle notebooks, the dataset can be loaded through widget using the below command. Please remember that ! before wget is essential\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nOnce the dataset is loaded to the kaggle notebook server, it can be read through the below pandas command\\ndf = pd.read_csv('housing.csv')\\nHarish Balasundaram\",\n",
       "  'document': '8fe56032',\n",
       "  'question': 'What command do I need to use to download the dataset to Kaggle Notebooks?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'Yes, there is a specific symbol you need to use before the wget command when using it in Google Colab. You should use the exclamation mark `!` to indicate that you are running a shell command. For example, the command would look like this: `!wget -P /content/drive/My\\\\ Drive/Downloads/ URL`.',\n",
       "  'answer_orig': \"For users of kaggle notebooks, the dataset can be loaded through widget using the below command. Please remember that ! before wget is essential\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nOnce the dataset is loaded to the kaggle notebook server, it can be read through the below pandas command\\ndf = pd.read_csv('housing.csv')\\nHarish Balasundaram\",\n",
       "  'document': '8fe56032',\n",
       "  'question': 'Is there a specific symbol I need to use before the wget command?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"To read the dataset in a Kaggle Notebook after downloading, you can use the following commands:\\n\\n1. Load the dataset using the `wget` command:\\n   ```python\\n   !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\n   ```\\n\\n2. Once the dataset is loaded, read it using the pandas library:\\n   ```python\\n   df = pd.read_csv('housing.csv')\\n   ``` \\n\\nMake sure to include the `!` before `wget` when using the command in the notebook.\",\n",
       "  'answer_orig': \"For users of kaggle notebooks, the dataset can be loaded through widget using the below command. Please remember that ! before wget is essential\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nOnce the dataset is loaded to the kaggle notebook server, it can be read through the below pandas command\\ndf = pd.read_csv('housing.csv')\\nHarish Balasundaram\",\n",
       "  'document': '8fe56032',\n",
       "  'question': 'After downloading, how do I read the dataset in a Kaggle Notebook?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The instructions for loading the dataset in Kaggle Notebooks were provided by Harish Balasundaram.',\n",
       "  'answer_orig': \"For users of kaggle notebooks, the dataset can be loaded through widget using the below command. Please remember that ! before wget is essential\\n!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\nOnce the dataset is loaded to the kaggle notebook server, it can be read through the below pandas command\\ndf = pd.read_csv('housing.csv')\\nHarish Balasundaram\",\n",
       "  'document': '8fe56032',\n",
       "  'question': 'Who provided the instructions for loading the dataset in Kaggle Notebooks?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can filter a dataset by specific values in a column using the following methods:\\n\\n1. Using logical operators:\\n```python\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\n```\\nHere, `|` is used for \\'OR\\' conditions.\\n\\n2. Using the `isin` method:\\n```python\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\n```\\n\\nBoth approaches allow you to filter the dataset based on specific values in the \\'ocean_proximity\\' column.',\n",
       "  'answer_orig': 'We can filter a dataset by using its values as below.\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\nYou can use | for ‘OR’, and & for ‘AND’\\nAlternative:\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\nRadikal Lukafiardi',\n",
       "  'document': 'af833e0a',\n",
       "  'question': 'How can I filter a dataset by specific values in a column?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"The symbols used for 'OR' and 'AND' operations when filtering a dataset in Pandas are | for 'OR' and & for 'AND'.\",\n",
       "  'answer_orig': 'We can filter a dataset by using its values as below.\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\nYou can use | for ‘OR’, and & for ‘AND’\\nAlternative:\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\nRadikal Lukafiardi',\n",
       "  'document': 'af833e0a',\n",
       "  'question': \"What are the symbols used for 'OR' and 'AND' operations when filtering a dataset?\",\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"Yes, there is an alternative method to filter a dataset by specific column values. You can use the `isin` method as follows:\\n\\n```python\\ndf = df[df['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]\\n```\\n\\nThis allows you to filter the dataset for multiple values in the specified column, instead of using `|` for 'OR' conditions.\",\n",
       "  'answer_orig': 'We can filter a dataset by using its values as below.\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\nYou can use | for ‘OR’, and & for ‘AND’\\nAlternative:\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\nRadikal Lukafiardi',\n",
       "  'document': 'af833e0a',\n",
       "  'question': 'Is there an alternative method to filter a dataset by specific column values?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can filter a dataset using multiple conditions in Pandas by employing logical operators. For example, to filter a dataset for rows where the \"ocean_proximity\" is either \"<1H OCEAN\" or \"INLAND\", you can use the following syntax:\\n\\n```python\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\n```\\n\\nAlternatively, you can use the `isin` method for a more concise approach:\\n\\n```python\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\n```\\n\\nTo combine conditions using logical AND, you would use the `&` operator.',\n",
       "  'answer_orig': 'We can filter a dataset by using its values as below.\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\nYou can use | for ‘OR’, and & for ‘AND’\\nAlternative:\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\nRadikal Lukafiardi',\n",
       "  'document': 'af833e0a',\n",
       "  'question': 'Can you provide an example of filtering a dataset using multiple conditions?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'The `isin()` method in the context of filtering a dataset is used to filter rows based on whether the values in a specified column are within a given list of values. For example, you can use it as follows:\\n\\n```python\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\n```\\n\\nThis will return a subset of the dataset where the values in the `\"ocean_proximity\"` column are either `\"<1H OCEAN\"` or `\"INLAND\"`.',\n",
       "  'answer_orig': 'We can filter a dataset by using its values as below.\\ndf = df[(df[\"ocean_proximity\"] == \"<1H OCEAN\") | (df[\"ocean_proximity\"] == \"INLAND\")]\\nYou can use | for ‘OR’, and & for ‘AND’\\nAlternative:\\ndf = df[df[\\'ocean_proximity\\'].isin([\\'<1H OCEAN\\', \\'INLAND\\'])]\\nRadikal Lukafiardi',\n",
       "  'document': 'af833e0a',\n",
       "  'question': 'What does the isin() method do in the context of filtering a dataset?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'An alternative way to load the data using the requests library is as follows:\\n\\n```python\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\n    with open(\\'housing.csv\\', \\'wb\\') as file:\\n        file.write(response.content)\\nelse:\\n    print(\"Download failed.\")\\n```\\n\\nThis approach retrieves the dataset from the specified URL and saves it to a file named `housing.csv`.',\n",
       "  'answer_orig': 'Above users showed how to load the dataset directly from github. Here is another useful way of doing this using the `requests` library:\\n# Get data for homework\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\nwith open(\\'housing.csv\\', \\'wb\\') as file:\\nfile.write(response.content)\\nelse:\\nprint(\"Download failed.\")\\nTyler Simpson',\n",
       "  'document': '8d209d6d',\n",
       "  'question': 'What is an alternative way to load the data using the requests library?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can directly download the dataset from GitHub without using pandas by using the `requests` library in Python. Here’s how you can do it:\\n\\n```python\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\n    with open(\\'housing.csv\\', \\'wb\\') as file:\\n        file.write(response.content)\\nelse:\\n    print(\"Download failed.\")\\n```\\n\\nThis code sends a GET request to the dataset\\'s URL and saves the content to a file named \\'housing.csv\\' if the download is successful.',\n",
       "  'answer_orig': 'Above users showed how to load the dataset directly from github. Here is another useful way of doing this using the `requests` library:\\n# Get data for homework\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\nwith open(\\'housing.csv\\', \\'wb\\') as file:\\nfile.write(response.content)\\nelse:\\nprint(\"Download failed.\")\\nTyler Simpson',\n",
       "  'document': '8d209d6d',\n",
       "  'question': 'How can I directly download the dataset from GitHub without using pandas?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'You can fetch data for homework using the `requests` library with the following method:\\n\\n```python\\nimport requests\\n\\n# Get data for homework\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\n\\nif response.status_code == 200:\\n    with open(\\'housing.csv\\', \\'wb\\') as file:\\n        file.write(response.content)\\nelse:\\n    print(\"Download failed.\")\\n```\\n\\nThis code retrieves the dataset from GitHub and saves it as \\'housing.csv\\' on your local machine.',\n",
       "  'answer_orig': 'Above users showed how to load the dataset directly from github. Here is another useful way of doing this using the `requests` library:\\n# Get data for homework\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\nwith open(\\'housing.csv\\', \\'wb\\') as file:\\nfile.write(response.content)\\nelse:\\nprint(\"Download failed.\")\\nTyler Simpson',\n",
       "  'document': '8d209d6d',\n",
       "  'question': 'Could you share a method to fetch data for homework using the requests library?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': \"If the status code is 200 when downloading data with requests, you should open a file in write-binary mode and write the content of the response to that file. Here's how you can do it:\\n\\n```python\\nwith open('housing.csv', 'wb') as file:\\n    file.write(response.content)\\n```\\n\\nThis indicates that the download was successful, and you can proceed to save the downloaded data into a file.\",\n",
       "  'answer_orig': 'Above users showed how to load the dataset directly from github. Here is another useful way of doing this using the `requests` library:\\n# Get data for homework\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\nwith open(\\'housing.csv\\', \\'wb\\') as file:\\nfile.write(response.content)\\nelse:\\nprint(\"Download failed.\")\\nTyler Simpson',\n",
       "  'document': '8d209d6d',\n",
       "  'question': 'What should I do if the status code is 200 when downloading data with requests?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'answer_llm': 'If the file download fails when using the requests library, the code will print \"Download failed.\" This occurs when the response status code is not 200.',\n",
       "  'answer_orig': 'Above users showed how to load the dataset directly from github. Here is another useful way of doing this using the `requests` library:\\n# Get data for homework\\nimport requests\\nurl = \\'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\\'\\nresponse = requests.get(url)\\nif response.status_code == 200:\\nwith open(\\'housing.csv\\', \\'wb\\') as file:\\nfile.write(response.content)\\nelse:\\nprint(\"Download failed.\")\\nTyler Simpson',\n",
       "  'document': '8d209d6d',\n",
       "  'question': 'What does the code using the requests library do if the file download fails?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gpt4omini_list = df.to_dict(orient=\"records\")\n",
    "results_gpt4omini_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62c56c3-6176-4fd2-8f5e-b4b8a1196b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gpt4omini_list[0]['answer_llm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b05e2081-72fe-4ba4-94f5-38dda2ab88fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['answer_llm', 'answer_orig', 'document', 'question', 'course'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86171b4f-289e-4a75-9778-2103934df7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1380bfba-b7e7-4900-b611-324b0b7c3d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3604bb0e0e24dc788db2ef38411f22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(results_gpt4omini_list):\n",
    "    v_llm = embedding_model.encode(record['answer_llm'])\n",
    "    v_orig = embedding_model.encode(record['answer_orig'])\n",
    "    dp = v_llm.dot(v_orig)\n",
    "    evaluations.append(dp) #dotproduct = compute_similarity(record)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d022bdbf-474f-4006-9cfc-e1cd589a761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations= pd.DataFrame()\n",
    "df_evaluations['score'] = evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89d1e86e-a50e-43e9-8795-46a8f84676b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.495996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.384743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.547926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.307844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.336861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.674304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.476013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "count  300.000000\n",
       "mean    27.495996\n",
       "std      6.384743\n",
       "min      4.547926\n",
       "25%     24.307844\n",
       "50%     28.336861\n",
       "75%     31.674304\n",
       "max     39.476013"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c615ff-0a96-43df-9b3e-f1a696da592b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d099fa-ca35-4087-bd6b-c151e5fab962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd16902-7fb7-4512-a9a8-9d2c5d53cb9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q3. Computing the cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae73a230-a8a6-4360-bb2b-f0d9dab71f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0a2183b-5727-413b-9217-b5ebaac46dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    return v_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "733c2346-94c5-43e9-b0e3-1dda5f97b070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.11306959e-02, -1.53223593e-02, -3.43620703e-02,  1.98937692e-02,\n",
       "        2.64813774e-04, -2.77096275e-02, -1.63180511e-02,  3.27728651e-02,\n",
       "        1.02764834e-02,  4.32049185e-02,  2.97470968e-02, -1.64741985e-02,\n",
       "        4.28259596e-02,  8.87097139e-03,  2.40928703e-03, -4.06071218e-03,\n",
       "       -2.75038555e-02,  2.57525593e-02, -6.17438108e-02,  1.62241049e-02,\n",
       "       -3.53289098e-02,  5.32247871e-02,  5.25180344e-03,  2.28471104e-02,\n",
       "        3.92429205e-03,  1.27627961e-02,  1.35364877e-02,  7.77296051e-02,\n",
       "       -3.22006419e-02, -6.01691008e-02, -1.34758176e-02,  1.85390767e-02,\n",
       "       -1.31161604e-03,  2.39917058e-02, -1.60573945e-05, -1.42468023e-03,\n",
       "        9.87560004e-02, -1.14630526e-02, -3.72214094e-02, -3.54782380e-02,\n",
       "       -5.72972447e-02, -4.96582240e-02, -2.75296974e-03, -4.27222028e-02,\n",
       "        5.11458032e-02,  1.45730404e-02,  4.68182117e-02,  3.17602456e-02,\n",
       "        5.42251505e-02,  4.59975377e-02,  5.68841100e-02,  1.83609016e-02,\n",
       "        2.98353862e-02, -3.24024968e-02,  5.41718192e-02, -1.63467806e-02,\n",
       "        6.29811198e-04,  3.11492123e-02,  4.70835045e-02,  2.31318921e-02,\n",
       "       -8.46489239e-03,  1.33872571e-04,  3.18432115e-02,  3.31482179e-02,\n",
       "       -8.26483686e-03, -1.56679712e-02,  1.79711487e-02, -3.54666822e-02,\n",
       "        4.18729633e-02,  1.50031550e-02,  8.01149905e-02,  2.53812689e-02,\n",
       "        2.27106474e-02,  1.22047998e-02, -3.67775932e-02, -2.30282452e-02,\n",
       "        8.49403217e-02,  9.00111161e-03, -7.14501040e-03, -8.55221413e-03,\n",
       "       -3.21762674e-02,  2.03220057e-03, -3.85318324e-02,  4.88246465e-03,\n",
       "       -7.25077419e-03, -2.98444577e-03, -2.10257657e-02,  2.02412717e-02,\n",
       "       -7.52859423e-03,  2.77286731e-02,  5.31572476e-03,  6.75280578e-03,\n",
       "       -2.60883160e-02, -8.73529539e-03, -9.09537729e-03,  8.18100292e-03,\n",
       "        1.79951712e-02,  9.99110658e-03,  4.45813648e-02,  1.99396312e-02,\n",
       "        5.27160801e-02,  1.12725509e-04, -1.32769125e-03,  2.42050644e-02,\n",
       "        3.80980261e-02, -1.10945152e-02,  3.31491679e-02, -5.30739091e-02,\n",
       "        6.26145750e-02,  4.31150943e-02, -1.65331562e-03, -2.81008203e-02,\n",
       "        3.10667586e-02, -9.78925172e-03, -2.02849489e-02, -4.50967206e-03,\n",
       "        4.19694819e-02, -3.91752757e-02, -1.76575799e-02,  3.07020377e-02,\n",
       "       -4.81954068e-02, -8.99644475e-03, -2.22911984e-02,  3.24964747e-02,\n",
       "       -3.11031025e-02, -2.05608886e-02,  4.83186953e-02, -1.43219726e-02,\n",
       "        7.88380764e-03, -4.39192308e-03, -1.65364854e-02, -4.43966389e-02,\n",
       "       -4.22270820e-02, -2.29851343e-02,  3.46679948e-02, -5.88380359e-03,\n",
       "        5.91432489e-02, -2.98480932e-02,  3.73175927e-02, -2.17127558e-02,\n",
       "        6.75091892e-02,  1.70230549e-02,  1.77479684e-02,  9.50950459e-02,\n",
       "        2.29800493e-02,  8.34188331e-03,  3.56504880e-03,  3.67179736e-02,\n",
       "        6.68452028e-03,  8.96488223e-03, -4.16700728e-02, -8.18571635e-03,\n",
       "        2.76095439e-02,  6.47153929e-02, -8.52214545e-03, -5.20284334e-03,\n",
       "        1.68968551e-02, -2.68035289e-02, -5.21521941e-02, -3.44283655e-02,\n",
       "        5.37538528e-02, -1.99586675e-02,  2.84620672e-02, -1.14446087e-02,\n",
       "       -2.36016568e-02,  6.33683130e-02, -4.53997403e-02, -6.83913939e-03,\n",
       "        1.52745936e-02, -9.63552371e-02,  2.14549806e-02, -2.09308765e-03,\n",
       "       -1.20930402e-02, -1.90969910e-02, -5.40111996e-02,  7.55033121e-02,\n",
       "        4.14545350e-02, -2.55553164e-02, -3.83373387e-02,  5.91196865e-02,\n",
       "       -1.68528389e-02, -3.79348136e-02, -7.59430113e-04,  2.23977566e-02,\n",
       "        2.63417549e-02, -3.06184813e-02, -5.20173926e-03,  1.44081993e-03,\n",
       "        1.54217994e-02, -1.76848262e-03, -3.71117555e-02, -1.54140173e-02,\n",
       "       -3.47809494e-02,  1.21466536e-03,  1.68848485e-02, -7.80687435e-04,\n",
       "        4.60632592e-02, -9.35098249e-03,  9.83869657e-03,  3.66058685e-02,\n",
       "       -3.09528317e-03, -2.57379562e-03, -1.73776317e-03,  1.78437512e-02,\n",
       "        4.07574102e-02,  3.28406505e-02,  2.87236739e-02,  3.73708047e-02,\n",
       "       -8.94216597e-02, -2.09742542e-02,  2.76562124e-02,  1.26270752e-03,\n",
       "       -5.87341860e-02, -2.21676920e-02, -1.63521636e-02,  3.51784229e-02,\n",
       "        5.91804832e-02, -6.93627633e-03,  1.71188414e-02,  2.06318051e-02,\n",
       "       -2.22572982e-02,  1.80194620e-02, -1.02618955e-01,  5.95752569e-03,\n",
       "        1.86442770e-02, -1.69780746e-03, -2.08500382e-02, -1.99235752e-02,\n",
       "        3.22898105e-03, -6.76854774e-02,  2.44104881e-02, -1.49447275e-02,\n",
       "       -2.80260257e-02,  7.46359527e-02, -3.09600383e-02, -1.74658257e-03,\n",
       "        4.04557064e-02,  1.77383572e-02,  2.43751463e-02,  1.11731105e-02,\n",
       "       -1.29780872e-02,  8.74722078e-02,  2.57369466e-02,  5.84426057e-03,\n",
       "        2.42244694e-02, -4.68549281e-02, -3.61080207e-02, -1.07354894e-02,\n",
       "       -6.65898202e-03, -1.97749082e-02,  4.60527949e-02, -8.07998795e-03,\n",
       "       -2.50613932e-02,  2.55216211e-02,  4.57697697e-02,  2.35263016e-02,\n",
       "        1.34155564e-02, -7.03908280e-02, -2.14082580e-02, -2.47225221e-02,\n",
       "        5.20548634e-02, -5.86605296e-02,  1.43546788e-02,  2.63849106e-02,\n",
       "        5.97594772e-03,  9.99047048e-03,  1.88063830e-02,  4.92711104e-02,\n",
       "        9.35189947e-02,  1.36883184e-02,  1.71099175e-02,  6.63761189e-03,\n",
       "       -2.77416757e-03, -9.17123407e-02,  1.38650266e-02, -9.15683992e-03,\n",
       "       -3.30321081e-02,  3.21374275e-02, -3.05073317e-02, -1.31863914e-02,\n",
       "       -7.83279613e-02, -3.84540223e-02, -3.13955476e-03,  3.44636501e-03,\n",
       "       -3.08231283e-02, -2.03628875e-02, -1.08468463e-03, -6.33690283e-02,\n",
       "        8.46508332e-03,  2.40144506e-02, -3.89749743e-02, -1.47891510e-02,\n",
       "        4.59508859e-02,  1.17808012e-02, -6.30203113e-02, -1.42653589e-03,\n",
       "       -1.88991409e-02,  2.86193267e-02,  2.24058740e-02,  1.30714029e-02,\n",
       "       -3.49942483e-02,  2.57567670e-02, -4.08812128e-02,  4.62082922e-02,\n",
       "        5.57374861e-03, -1.32450201e-02,  4.71071675e-02, -8.24062228e-02,\n",
       "        2.06338475e-03, -5.47280610e-02,  1.23899607e-02,  3.46348770e-02,\n",
       "        1.57304164e-02, -3.52931991e-02,  3.93259563e-02,  5.34946509e-02,\n",
       "        4.13837172e-02,  5.26788086e-02,  2.28934716e-02, -3.79876904e-02,\n",
       "       -3.08844652e-02, -8.07494670e-03,  4.94750254e-02, -2.84403819e-03,\n",
       "       -7.29378387e-02, -3.42237987e-02,  1.47015536e-02, -4.31775935e-02,\n",
       "        1.91658530e-02,  1.30131897e-02,  2.08538342e-02,  2.24831682e-02,\n",
       "        1.37112588e-02,  5.18520623e-02, -1.81678031e-02, -1.02190003e-02,\n",
       "       -4.91344854e-02, -7.51880333e-02,  1.40858823e-02, -1.67288259e-02,\n",
       "       -7.66339451e-02,  4.79095168e-02,  5.90087473e-02,  2.60586366e-02,\n",
       "        1.67333279e-02, -4.48898859e-02, -5.40948026e-02,  7.92140048e-03,\n",
       "        2.43107858e-03, -2.90038176e-02,  1.49202012e-02,  7.13638216e-02,\n",
       "       -3.19939964e-02, -6.63953647e-02, -4.35652919e-02,  1.42246224e-02,\n",
       "        3.66908647e-02,  2.24842187e-02,  6.24883957e-02, -1.50674898e-02,\n",
       "        3.46734305e-04, -2.75728796e-02,  4.68070917e-02, -1.56481545e-02,\n",
       "        9.43956617e-03,  8.93686861e-02,  3.86360660e-02,  6.52365386e-02,\n",
       "        1.67384204e-02,  5.64238243e-02,  1.61375050e-02,  5.12066903e-03,\n",
       "       -3.18973027e-02,  3.75502259e-02,  2.25698184e-02, -4.45748344e-02,\n",
       "       -2.41184961e-02, -5.33949435e-02, -6.49871379e-02, -2.02469854e-03,\n",
       "       -4.40740259e-03,  4.75952141e-02,  1.41608678e-02,  8.96411482e-03,\n",
       "        2.16509104e-02,  6.82501346e-02,  3.03213019e-02,  2.96162236e-02,\n",
       "        5.44841476e-02,  5.09786755e-02, -2.07217373e-02,  1.60161052e-02,\n",
       "       -4.33484539e-02, -2.72889361e-02,  4.54508625e-02,  3.43527808e-03,\n",
       "       -1.25996303e-02, -6.21351600e-02,  5.97827695e-03,  6.42211689e-03,\n",
       "       -1.31513188e-02,  5.64741604e-02, -1.70647316e-02, -5.59062790e-03,\n",
       "       -1.21478019e-02,  2.82570142e-02,  4.69437763e-02, -4.93100546e-02,\n",
       "       -4.53400351e-02,  2.84811947e-02,  4.76193614e-02, -1.53266983e-02,\n",
       "       -5.61300330e-02,  1.31885335e-02, -3.91004942e-02, -1.90747366e-03,\n",
       "       -4.03336668e-03, -5.17429747e-02, -5.38696684e-02, -6.92168623e-02,\n",
       "       -7.96502233e-02,  4.18203212e-02, -2.32170452e-03, -4.65691909e-02,\n",
       "       -4.02262583e-02, -6.32020012e-02,  4.97814901e-02, -1.12783331e-02,\n",
       "       -4.85018417e-02,  2.21897215e-02, -1.93072055e-02, -1.41031770e-02,\n",
       "       -2.99676247e-02, -1.39215752e-03,  8.60504527e-03,  2.96307895e-02,\n",
       "        2.49980167e-02,  4.60648425e-02,  4.09025364e-02,  4.76703793e-02,\n",
       "       -2.05445066e-02, -4.41348925e-02,  2.74266638e-02, -6.91467710e-03,\n",
       "       -1.29305106e-03,  4.22992110e-02,  2.33272724e-02,  2.96329614e-02,\n",
       "       -1.02244979e-02,  6.51022792e-02, -3.49236503e-02,  3.83795844e-03,\n",
       "       -1.37026776e-02,  6.12161793e-02, -3.96440998e-02,  4.45691636e-03,\n",
       "        2.34881360e-02,  1.95712447e-02, -5.24401758e-03, -4.90038022e-02,\n",
       "        1.49582373e-02,  1.12838939e-01, -1.92837196e-03, -3.57967429e-03,\n",
       "       -1.71943605e-02, -6.51225001e-02,  6.86428770e-02, -1.17598213e-02,\n",
       "       -6.96777308e-04, -7.55034527e-03, -1.36340978e-02, -3.02756466e-02,\n",
       "        3.91655089e-03,  4.59793583e-02,  7.05575524e-03, -8.33517388e-02,\n",
       "        1.98215097e-02, -9.82170366e-03,  5.45179937e-03,  1.17115872e-02,\n",
       "        2.05010325e-02, -8.30699652e-02,  1.39913643e-02, -5.82459196e-02,\n",
       "        5.92276081e-02,  4.22990276e-03,  3.77329551e-02, -4.75160815e-02,\n",
       "       -3.47453691e-02,  8.99394974e-03, -4.18277308e-02, -2.29576733e-02,\n",
       "        2.78687257e-05, -2.92809717e-02, -3.26813012e-02, -2.25580446e-02,\n",
       "        1.00581562e-02, -2.26077829e-02, -1.61315072e-02, -5.57542639e-03,\n",
       "        1.89781170e-02, -4.12024595e-02,  4.09707315e-02, -5.16870953e-02,\n",
       "       -2.32519861e-02, -1.65148254e-03, -1.00876708e-02, -9.47692059e-03,\n",
       "       -5.48657030e-02, -4.37970087e-02,  4.01654691e-02, -2.31270306e-02,\n",
       "       -2.31997129e-02,  1.46242678e-02,  4.52802107e-02, -3.39664742e-02,\n",
       "       -2.40242854e-02,  8.50960333e-03, -3.39425765e-02, -7.84971863e-02,\n",
       "        1.39802406e-02,  4.14604284e-02,  2.53345370e-02, -1.63873881e-02,\n",
       "        1.30748283e-02,  3.09007820e-02, -1.05585353e-02, -4.88268547e-02,\n",
       "        2.87440047e-02, -2.21910253e-02, -3.62559818e-02,  2.54858006e-02,\n",
       "       -2.84193512e-02,  2.91994633e-03, -3.19681875e-02, -2.95182932e-02,\n",
       "       -5.30059598e-02, -4.39237840e-02,  3.42158377e-02,  3.47388498e-02,\n",
       "        1.06290902e-03, -3.75689827e-02,  5.02476357e-02,  9.52891912e-03,\n",
       "        2.68511362e-02, -1.19266436e-02, -4.09233682e-02, -2.45425235e-02,\n",
       "       -1.85878705e-02,  8.83122906e-03,  3.30209471e-02,  5.70924394e-03,\n",
       "       -2.12908722e-02,  7.95485005e-02, -4.77071665e-02, -6.98971748e-02,\n",
       "        1.37128374e-02, -7.88955018e-02, -1.45206731e-02, -1.44107454e-02,\n",
       "        2.29496206e-03,  1.57590136e-02, -1.71215180e-02,  3.01661268e-02,\n",
       "        7.34565407e-02, -4.31336239e-02, -5.45877777e-02, -1.02260988e-02,\n",
       "        7.46937282e-03,  2.36920640e-02, -2.03218963e-02,  2.51537329e-03,\n",
       "       -3.24345082e-02, -7.12451525e-03,  5.20505272e-02,  2.38259276e-03,\n",
       "       -2.60895584e-02, -3.80725674e-02, -2.87707895e-02,  4.42598462e-02,\n",
       "        3.15623656e-02, -3.41619328e-02,  2.70485021e-02, -2.75516398e-02,\n",
       "        6.92788064e-02, -2.96621695e-02, -5.00889262e-03, -2.50462424e-02,\n",
       "       -1.75702590e-02,  5.48605062e-03,  1.98363736e-02,  2.29198784e-02,\n",
       "        1.09094232e-02,  3.85529883e-02, -2.20176429e-02, -1.36113521e-02,\n",
       "       -1.84807219e-02,  6.83538914e-02,  5.86498342e-02, -3.26897344e-03,\n",
       "       -7.73717463e-02,  1.62199605e-02,  6.19378686e-02, -5.66031504e-03,\n",
       "        2.51480397e-02, -5.62479906e-03, -9.94769577e-03,  5.81580307e-03,\n",
       "       -8.86386726e-03,  1.57683939e-02, -5.54259717e-02,  6.16815388e-02,\n",
       "        5.94400652e-02,  3.80097367e-02,  1.59576237e-02, -4.10188362e-02,\n",
       "       -1.81704704e-02, -4.32400815e-02,  6.37712628e-02,  6.78045955e-03,\n",
       "       -5.92683144e-02,  3.33313122e-02, -1.37779600e-04, -2.06050910e-02,\n",
       "        1.57843214e-02,  1.74496882e-02,  5.55459447e-02, -4.23908159e-02,\n",
       "       -2.08360255e-02,  1.12296073e-02, -1.12460286e-03, -2.64167674e-02,\n",
       "        4.94405553e-02,  4.82321046e-02,  2.96059567e-02, -5.78580834e-02,\n",
       "        2.87214220e-02, -5.05626053e-02,  7.98703730e-03, -9.94560681e-03,\n",
       "        4.71072160e-02, -5.35482764e-02, -4.20093946e-02, -1.59418397e-02,\n",
       "        1.77849308e-02,  1.44229196e-02,  4.14634980e-02,  2.95456257e-02,\n",
       "        1.53276194e-02, -1.42393000e-02, -2.49292403e-02, -3.65284644e-02,\n",
       "       -2.64467429e-02, -1.07968850e-02, -3.83402221e-02, -5.66987367e-03,\n",
       "        7.41722062e-02,  2.04548519e-03,  7.65292123e-02,  4.01378945e-02,\n",
       "        5.89364469e-02,  4.31923680e-02,  8.77965335e-03,  2.41685004e-04,\n",
       "        1.88476872e-02,  1.38472402e-02, -2.31850054e-02,  5.38901836e-02,\n",
       "        8.86067376e-02,  1.98084535e-03,  3.39444391e-02,  4.11213748e-02,\n",
       "       -5.99208549e-02,  2.41467338e-02, -6.25041798e-02, -2.16482002e-02,\n",
       "       -2.42391918e-02,  8.84196348e-03, -8.16205423e-03,  3.27250846e-02,\n",
       "       -6.51320741e-02, -1.45175932e-02, -1.16264097e-01,  1.32612698e-03,\n",
       "       -1.49899526e-02, -2.24451185e-03,  5.25494688e-04, -2.56792568e-02,\n",
       "        2.67145783e-02, -2.08824258e-02,  8.82358849e-02,  7.59239718e-02,\n",
       "        6.04949631e-02, -1.83617007e-02, -7.74816144e-03, -5.04010022e-02,\n",
       "        5.23919798e-02, -1.04295984e-02,  5.51448800e-02, -2.72309501e-02,\n",
       "        8.52695946e-03, -1.47415018e-02,  1.76266842e-02,  6.44240826e-02,\n",
       "        6.41189341e-04,  2.18756255e-02,  1.37881301e-02,  1.61015429e-02,\n",
       "       -4.32464946e-03,  7.84128997e-03, -1.21808108e-02, -2.47262698e-02,\n",
       "       -2.22270060e-02,  5.09146787e-02, -4.89335917e-02,  4.44964170e-02,\n",
       "        4.27893130e-03, -4.21271622e-02, -9.53078270e-03, -1.53086800e-02,\n",
       "        6.82983100e-02,  5.31823263e-02,  5.90701215e-02, -4.82736453e-02,\n",
       "       -4.11199443e-02,  1.79872904e-02,  2.30891146e-02,  4.78609372e-03,\n",
       "       -5.78164421e-02,  2.33832803e-02,  2.10929886e-02,  5.68993986e-02,\n",
       "        5.69851045e-03, -2.98431981e-02,  9.99758691e-02, -9.52224061e-03,\n",
       "        2.61733942e-02,  3.81460227e-03, -2.94302274e-02, -2.44853701e-02,\n",
       "       -1.98679511e-02, -1.32425195e-02,  1.71878245e-02,  1.00467280e-02,\n",
       "       -1.20644793e-02, -6.15471378e-02, -1.73938349e-02,  5.79589829e-02,\n",
       "       -2.13369709e-02, -1.18786758e-02, -1.57838892e-02,  2.11497433e-02,\n",
       "        7.26078916e-03,  1.94071084e-02, -2.36190967e-02,  1.93420667e-02,\n",
       "        2.44921092e-02, -9.03189648e-03, -3.51028554e-02,  3.34617645e-02,\n",
       "       -1.48809627e-02, -1.97614059e-02,  1.57857705e-02,  2.33233236e-02,\n",
       "        3.11737843e-02, -2.58034691e-02,  2.62350421e-02, -3.86959761e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizing(v_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cca8a372-8f82-4ed4-80f2-6570b01015d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.515997,\n",
       " 13.4184065,\n",
       " 25.31325,\n",
       " 12.147419,\n",
       " 18.747728,\n",
       " 33.970398,\n",
       " 30.251701,\n",
       " 29.521585,\n",
       " 35.2722,\n",
       " 27.751759,\n",
       " 32.34471,\n",
       " 31.441847,\n",
       " 36.38073,\n",
       " 33.340515,\n",
       " 30.606163,\n",
       " 32.503044,\n",
       " 29.674446,\n",
       " 24.353462,\n",
       " 20.13246,\n",
       " 23.995468,\n",
       " 30.880272,\n",
       " 32.692432,\n",
       " 30.049168,\n",
       " 16.078167,\n",
       " 31.796417,\n",
       " 37.98001,\n",
       " 20.839043,\n",
       " 32.612854,\n",
       " 38.894203,\n",
       " 34.051826,\n",
       " 28.26388,\n",
       " 27.124832,\n",
       " 23.975266,\n",
       " 26.34014,\n",
       " 18.658117,\n",
       " 25.016396,\n",
       " 21.101133,\n",
       " 33.726788,\n",
       " 29.340345,\n",
       " 28.65449,\n",
       " 29.608582,\n",
       " 30.810736,\n",
       " 33.3312,\n",
       " 26.220486,\n",
       " 26.550077,\n",
       " 13.148602,\n",
       " 12.962549,\n",
       " 12.275612,\n",
       " 9.974444,\n",
       " 10.883927,\n",
       " 29.84507,\n",
       " 32.36179,\n",
       " 22.187178,\n",
       " 30.268929,\n",
       " 25.091877,\n",
       " 32.742783,\n",
       " 28.22099,\n",
       " 27.274975,\n",
       " 24.208641,\n",
       " 22.568905,\n",
       " 19.767452,\n",
       " 18.679333,\n",
       " 20.422318,\n",
       " 22.051323,\n",
       " 18.188011,\n",
       " 28.455889,\n",
       " 25.919704,\n",
       " 23.332329,\n",
       " 22.205935,\n",
       " 28.296305,\n",
       " 39.23055,\n",
       " 36.758514,\n",
       " 31.913893,\n",
       " 31.202858,\n",
       " 36.91305,\n",
       " 30.514198,\n",
       " 36.261467,\n",
       " 27.397549,\n",
       " 37.7928,\n",
       " 23.297688,\n",
       " 34.25258,\n",
       " 34.550613,\n",
       " 30.316456,\n",
       " 35.70352,\n",
       " 31.012527,\n",
       " 35.459606,\n",
       " 35.075764,\n",
       " 35.429825,\n",
       " 29.881172,\n",
       " 30.037115,\n",
       " 31.247982,\n",
       " 29.89394,\n",
       " 28.52552,\n",
       " 31.754606,\n",
       " 32.59006,\n",
       " 39.476013,\n",
       " 34.973724,\n",
       " 28.725086,\n",
       " 30.6841,\n",
       " 37.26411,\n",
       " 35.626842,\n",
       " 33.202927,\n",
       " 25.320385,\n",
       " 32.188915,\n",
       " 22.51867,\n",
       " 30.810644,\n",
       " 37.474186,\n",
       " 27.127542,\n",
       " 27.558426,\n",
       " 33.077446,\n",
       " 25.819044,\n",
       " 35.047585,\n",
       " 34.910133,\n",
       " 35.862923,\n",
       " 35.66462,\n",
       " 23.890945,\n",
       " 26.650799,\n",
       " 19.03632,\n",
       " 23.732626,\n",
       " 36.686493,\n",
       " 23.632248,\n",
       " 26.224363,\n",
       " 28.331976,\n",
       " 28.205883,\n",
       " 29.783936,\n",
       " 27.14346,\n",
       " 14.999909,\n",
       " 18.169992,\n",
       " 18.22865,\n",
       " 20.363129,\n",
       " 5.448556,\n",
       " 5.932483,\n",
       " 7.870978,\n",
       " 4.547926,\n",
       " 5.385088,\n",
       " 27.713978,\n",
       " 20.70014,\n",
       " 27.329466,\n",
       " 16.532581,\n",
       " 19.901352,\n",
       " 31.073858,\n",
       " 29.63746,\n",
       " 28.450882,\n",
       " 24.889107,\n",
       " 26.59752,\n",
       " 26.664059,\n",
       " 33.775314,\n",
       " 28.7658,\n",
       " 19.707882,\n",
       " 17.306507,\n",
       " 34.357483,\n",
       " 30.779724,\n",
       " 30.170496,\n",
       " 27.354588,\n",
       " 32.209927,\n",
       " 26.880234,\n",
       " 28.167713,\n",
       " 29.976238,\n",
       " 28.072685,\n",
       " 31.957588,\n",
       " 30.330582,\n",
       " 29.305618,\n",
       " 27.504326,\n",
       " 27.409878,\n",
       " 26.012466,\n",
       " 31.341301,\n",
       " 29.24813,\n",
       " 34.054394,\n",
       " 29.529327,\n",
       " 27.144753,\n",
       " 26.034893,\n",
       " 31.496738,\n",
       " 32.259842,\n",
       " 21.932495,\n",
       " 30.88007,\n",
       " 39.092705,\n",
       " 32.14211,\n",
       " 25.34589,\n",
       " 23.977585,\n",
       " 27.314087,\n",
       " 30.87744,\n",
       " 28.470531,\n",
       " 28.86776,\n",
       " 28.17321,\n",
       " 27.834417,\n",
       " 33.211502,\n",
       " 27.782202,\n",
       " 28.150196,\n",
       " 27.548817,\n",
       " 29.624218,\n",
       " 28.466618,\n",
       " 27.704876,\n",
       " 27.51704,\n",
       " 26.017353,\n",
       " 16.815933,\n",
       " 29.18188,\n",
       " 30.130188,\n",
       " 27.391752,\n",
       " 28.57114,\n",
       " 21.442024,\n",
       " 29.0719,\n",
       " 27.174828,\n",
       " 26.663849,\n",
       " 26.153393,\n",
       " 29.611273,\n",
       " 27.712759,\n",
       " 17.301191,\n",
       " 25.073742,\n",
       " 26.105171,\n",
       " 15.056329,\n",
       " 32.224457,\n",
       " 26.998768,\n",
       " 24.001842,\n",
       " 30.299423,\n",
       " 31.251953,\n",
       " 24.931458,\n",
       " 27.136257,\n",
       " 20.048168,\n",
       " 22.204578,\n",
       " 18.39867,\n",
       " 23.471605,\n",
       " 23.65659,\n",
       " 20.096872,\n",
       " 27.78518,\n",
       " 23.721882,\n",
       " 29.47656,\n",
       " 31.923643,\n",
       " 27.786556,\n",
       " 25.28249,\n",
       " 21.090363,\n",
       " 34.241966,\n",
       " 34.5661,\n",
       " 35.93258,\n",
       " 22.799603,\n",
       " 33.241447,\n",
       " 19.981958,\n",
       " 22.636581,\n",
       " 24.131182,\n",
       " 23.120184,\n",
       " 11.905024,\n",
       " 32.218346,\n",
       " 29.58118,\n",
       " 22.276997,\n",
       " 26.254911,\n",
       " 18.278994,\n",
       " 33.623142,\n",
       " 29.776499,\n",
       " 30.866945,\n",
       " 26.539066,\n",
       " 26.438843,\n",
       " 23.820015,\n",
       " 27.360676,\n",
       " 29.637075,\n",
       " 31.316284,\n",
       " 20.207516,\n",
       " 34.520557,\n",
       " 33.354904,\n",
       " 28.474087,\n",
       " 27.6943,\n",
       " 21.486216,\n",
       " 29.00384,\n",
       " 26.53431,\n",
       " 28.94831,\n",
       " 27.005249,\n",
       " 24.340912,\n",
       " 21.608488,\n",
       " 33.209812,\n",
       " 31.647537,\n",
       " 30.631363,\n",
       " 25.52513,\n",
       " 31.80573,\n",
       " 34.976177,\n",
       " 29.750322,\n",
       " 28.022009,\n",
       " 24.982285,\n",
       " 34.44129,\n",
       " 33.405495,\n",
       " 30.952478,\n",
       " 25.19504,\n",
       " 29.613966,\n",
       " 31.487972,\n",
       " 29.713959,\n",
       " 28.341745,\n",
       " 28.797325,\n",
       " 28.471718,\n",
       " 38.855076,\n",
       " 35.335587,\n",
       " 13.9045925,\n",
       " 38.246567,\n",
       " 30.029453,\n",
       " 33.36308,\n",
       " 25.7122,\n",
       " 32.535797,\n",
       " 31.411255,\n",
       " 30.524258,\n",
       " 34.001778,\n",
       " 33.690865,\n",
       " 34.491535,\n",
       " 27.53835,\n",
       " 18.414099]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa21c635-e3cd-4700-938d-206353c8d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04ef71b15c3493caafbe4b671dedb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_q3 = []\n",
    "\n",
    "for record in tqdm(results_gpt4omini_list):\n",
    "    v_llm = embedding_model.encode(record['answer_llm'])\n",
    "    v_orig = embedding_model.encode(record['answer_orig'])\n",
    "    #dp = v_llm.dot(v_orig)\n",
    "    n_v_llm= normalizing(v_llm)\n",
    "    n_v_orig= normalizing(v_orig) \n",
    "    dp2 = n_v_llm.dot(n_v_orig)\n",
    "    evaluations_q3.append(dp2) #dotproduct = compute_similarity(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b08623d3-92d1-4967-8b2b-72baaf20ef96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(evaluations_q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eb6a16e-41ba-4947-a12e-192f68bd7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_q3= pd.DataFrame()\n",
    "df_evaluations_q3['normalized_score'] = evaluations_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85175208-8612-4e99-ab18-52df5657c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.728392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.157755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.125357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.651273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.763761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.836235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.958796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized_score\n",
       "count        300.000000\n",
       "mean           0.728392\n",
       "std            0.157755\n",
       "min            0.125357\n",
       "25%            0.651273\n",
       "50%            0.763761\n",
       "75%            0.836235\n",
       "max            0.958796"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_q3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e6581-7a91-46a9-88de-44e80bb4c293",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q4. Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca11f19e-ea21-4cac-9b77-b84246a2e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/hhammad/miniconda3/envs/llm_zoomcamp/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f0ab61c-320d-4c0e-a609-d6099c472c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': \"Yes, all sessions are recorded, so if you miss one, you won't miss anything. You can catch up on the content later. Additionally, you can submit your questions in advance for office hours, and those sessions are also recorded.\",\n",
       " 'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       " 'document': '5170565b',\n",
       " 'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = results_gpt4omini_list[10]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c474d45-53cd-4492-899d-b3d11e7b7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0df686d4-9516-46fd-ac78-d96987719c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e49a6-ec10-4577-87e1-9687d43a977b",
   "metadata": {},
   "source": [
    "#### What's the F score for rouge-1?\n",
    "\n",
    " 'f': 0.45454544954545456},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd856c-bdb9-4f79-bd27-9af888111a15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q5. Average rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645d89b-96d5-48a0-8832-c90e8ce4f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_F_score = scores['rouge1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22aa25e3-9b78-4a30-8619-f1b84d64d40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4542df4f-3341-47d6-a466-10c098ac4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fscores = [scores[k]['f'] for k in scores.keys() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a284b7c1-fd5c-4dfb-a437-091fcb6bd749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45454544954545456, 0.21621621121621637, 0.393939388939394]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "242aa8c2-499d-43ae-84ce-0bf9d2c5f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_f_score = sum(fscores)/len(fscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5b77217-b5ee-47bf-a61d-294473848878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018bac3-f5a0-4ab1-a45c-7049c4a0355b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Q6. Average rouge score for all the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2721102-b115-457e-a111-b9bf3ea96b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84501235851b44ca80c876bd822ed190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge_scores = []\n",
    "\n",
    "\n",
    "for record in tqdm(results_gpt4omini_list):\n",
    "   #v_llm = embedding_model.encode(record['answer_llm'])\n",
    "    #v_orig = embedding_model.encode(record['answer_orig'])\n",
    "\n",
    "    rouge_score = rouge_scorer.get_scores(record['answer_llm'], record['answer_orig'])[0]\n",
    "    rouge_scores.append(rouge_score)\n",
    "    #dp = v_llm.dot(v_orig)\n",
    "    #n_v_llm= normalizing(v_llm)\n",
    "    #n_v_orig= normalizing(v_orig) \n",
    "    #dp2 = n_v_llm.dot(n_v_orig)\n",
    "    #evaluations_q3.append(dp2) #dotproduct = compute_similarity(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41e067e6-d87b-4cda-9e55-25e04cb87ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,\n",
       " [{'rouge-1': {'r': 0.061224489795918366,\n",
       "    'p': 0.21428571428571427,\n",
       "    'f': 0.09523809178130524},\n",
       "   'rouge-2': {'r': 0.017543859649122806,\n",
       "    'p': 0.07142857142857142,\n",
       "    'f': 0.028169010918468917},\n",
       "   'rouge-l': {'r': 0.061224489795918366,\n",
       "    'p': 0.21428571428571427,\n",
       "    'f': 0.09523809178130524}},\n",
       "  {'rouge-1': {'r': 0.08163265306122448,\n",
       "    'p': 0.26666666666666666,\n",
       "    'f': 0.12499999641113292},\n",
       "   'rouge-2': {'r': 0.03508771929824561,\n",
       "    'p': 0.13333333333333333,\n",
       "    'f': 0.05555555225694465},\n",
       "   'rouge-l': {'r': 0.061224489795918366, 'p': 0.2, 'f': 0.09374999641113295}},\n",
       "  {'rouge-1': {'r': 0.32653061224489793,\n",
       "    'p': 0.5714285714285714,\n",
       "    'f': 0.41558441095631643},\n",
       "   'rouge-2': {'r': 0.14035087719298245,\n",
       "    'p': 0.24242424242424243,\n",
       "    'f': 0.17777777313333343},\n",
       "   'rouge-l': {'r': 0.30612244897959184,\n",
       "    'p': 0.5357142857142857,\n",
       "    'f': 0.3896103849822905}},\n",
       "  {'rouge-1': {'r': 0.16326530612244897, 'p': 0.32, 'f': 0.2162162117421476},\n",
       "   'rouge-2': {'r': 0.03508771929824561,\n",
       "    'p': 0.07142857142857142,\n",
       "    'f': 0.047058819111419105},\n",
       "   'rouge-l': {'r': 0.14285714285714285, 'p': 0.28, 'f': 0.18918918471512064}},\n",
       "  {'rouge-1': {'r': 0.2653061224489796,\n",
       "    'p': 0.09701492537313433,\n",
       "    'f': 0.14207649881095297},\n",
       "   'rouge-2': {'r': 0.07017543859649122,\n",
       "    'p': 0.0223463687150838,\n",
       "    'f': 0.03389830142092829},\n",
       "   'rouge-l': {'r': 0.22448979591836735,\n",
       "    'p': 0.08208955223880597,\n",
       "    'f': 0.12021857531368524}},\n",
       "  {'rouge-1': {'r': 0.2894736842105263,\n",
       "    'p': 0.8461538461538461,\n",
       "    'f': 0.43137254522106894},\n",
       "   'rouge-2': {'r': 0.16, 'p': 0.6666666666666666, 'f': 0.2580645130072841},\n",
       "   'rouge-l': {'r': 0.2894736842105263,\n",
       "    'p': 0.8461538461538461,\n",
       "    'f': 0.43137254522106894}},\n",
       "  {'rouge-1': {'r': 0.34210526315789475, 'p': 0.52, 'f': 0.41269840791131274},\n",
       "   'rouge-2': {'r': 0.14, 'p': 0.25, 'f': 0.17948717488494426},\n",
       "   'rouge-l': {'r': 0.2894736842105263, 'p': 0.44, 'f': 0.34920634441924925}},\n",
       "  {'rouge-1': {'r': 0.18421052631578946, 'p': 0.875, 'f': 0.30434782321361065},\n",
       "   'rouge-2': {'r': 0.08, 'p': 0.5714285714285714, 'f': 0.1403508750384734},\n",
       "   'rouge-l': {'r': 0.15789473684210525, 'p': 0.75, 'f': 0.26086956234404535}},\n",
       "  {'rouge-1': {'r': 0.39473684210526316, 'p': 0.75, 'f': 0.5172413747919143},\n",
       "   'rouge-2': {'r': 0.24, 'p': 0.5, 'f': 0.3243243199415632},\n",
       "   'rouge-l': {'r': 0.3157894736842105, 'p': 0.6, 'f': 0.4137930989298454}},\n",
       "  {'rouge-1': {'r': 0.2894736842105263,\n",
       "    'p': 0.4230769230769231,\n",
       "    'f': 0.34374999517578125},\n",
       "   'rouge-2': {'r': 0.18, 'p': 0.2647058823529412, 'f': 0.21428570946712028},\n",
       "   'rouge-l': {'r': 0.2894736842105263,\n",
       "    'p': 0.4230769230769231,\n",
       "    'f': 0.34374999517578125}},\n",
       "  {'rouge-1': {'r': 0.45454545454545453,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.45454544954545456},\n",
       "   'rouge-2': {'r': 0.21621621621621623,\n",
       "    'p': 0.21621621621621623,\n",
       "    'f': 0.21621621121621637},\n",
       "   'rouge-l': {'r': 0.3939393939393939,\n",
       "    'p': 0.3939393939393939,\n",
       "    'f': 0.393939388939394}},\n",
       "  {'rouge-1': {'r': 0.6060606060606061,\n",
       "    'p': 0.6060606060606061,\n",
       "    'f': 0.6060606010606061},\n",
       "   'rouge-2': {'r': 0.43243243243243246,\n",
       "    'p': 0.41025641025641024,\n",
       "    'f': 0.42105262658241},\n",
       "   'rouge-l': {'r': 0.5757575757575758,\n",
       "    'p': 0.5757575757575758,\n",
       "    'f': 0.5757575707575758}},\n",
       "  {'rouge-1': {'r': 0.7878787878787878,\n",
       "    'p': 0.7222222222222222,\n",
       "    'f': 0.753623183415249},\n",
       "   'rouge-2': {'r': 0.6486486486486487,\n",
       "    'p': 0.5714285714285714,\n",
       "    'f': 0.6075949317288897},\n",
       "   'rouge-l': {'r': 0.7575757575757576,\n",
       "    'p': 0.6944444444444444,\n",
       "    'f': 0.7246376761688721}},\n",
       "  {'rouge-1': {'r': 0.8181818181818182,\n",
       "    'p': 0.6585365853658537,\n",
       "    'f': 0.7297297247881666},\n",
       "   'rouge-2': {'r': 0.6486486486486487,\n",
       "    'p': 0.5106382978723404,\n",
       "    'f': 0.5714285664994332},\n",
       "   'rouge-l': {'r': 0.7878787878787878,\n",
       "    'p': 0.6341463414634146,\n",
       "    'f': 0.7027026977611397}},\n",
       "  {'rouge-1': {'r': 0.7575757575757576, 'p': 0.625, 'f': 0.6849315018952901},\n",
       "   'rouge-2': {'r': 0.5405405405405406,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.4878048730963712},\n",
       "   'rouge-l': {'r': 0.6666666666666666, 'p': 0.55, 'f': 0.6027397210733721}},\n",
       "  {'rouge-1': {'r': 0.4772727272727273,\n",
       "    'p': 0.4772727272727273,\n",
       "    'f': 0.4772727222727273},\n",
       "   'rouge-2': {'r': 0.2692307692307692,\n",
       "    'p': 0.2641509433962264,\n",
       "    'f': 0.2666666616671202},\n",
       "   'rouge-l': {'r': 0.4318181818181818,\n",
       "    'p': 0.4318181818181818,\n",
       "    'f': 0.43181817681818185}},\n",
       "  {'rouge-1': {'r': 0.4090909090909091,\n",
       "    'p': 0.5806451612903226,\n",
       "    'f': 0.47999999515022235},\n",
       "   'rouge-2': {'r': 0.23076923076923078,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.28235293642629766},\n",
       "   'rouge-l': {'r': 0.38636363636363635,\n",
       "    'p': 0.5483870967741935,\n",
       "    'f': 0.45333332848355556}},\n",
       "  {'rouge-1': {'r': 0.3181818181818182, 'p': 0.5, 'f': 0.3888888841358025},\n",
       "   'rouge-2': {'r': 0.09615384615384616,\n",
       "    'p': 0.15625,\n",
       "    'f': 0.11904761433106596},\n",
       "   'rouge-l': {'r': 0.29545454545454547,\n",
       "    'p': 0.4642857142857143,\n",
       "    'f': 0.36111110635802474}},\n",
       "  {'rouge-1': {'r': 0.2727272727272727, 'p': 0.3, 'f': 0.2857142807256236},\n",
       "   'rouge-2': {'r': 0.057692307692307696,\n",
       "    'p': 0.075,\n",
       "    'f': 0.06521738638941436},\n",
       "   'rouge-l': {'r': 0.2727272727272727, 'p': 0.3, 'f': 0.2857142807256236}},\n",
       "  {'rouge-1': {'r': 0.3409090909090909,\n",
       "    'p': 0.4166666666666667,\n",
       "    'f': 0.37499999505},\n",
       "   'rouge-2': {'r': 0.19230769230769232,\n",
       "    'p': 0.2631578947368421,\n",
       "    'f': 0.22222221734320996},\n",
       "   'rouge-l': {'r': 0.3409090909090909,\n",
       "    'p': 0.4166666666666667,\n",
       "    'f': 0.37499999505}},\n",
       "  {'rouge-1': {'r': 0.1746031746031746,\n",
       "    'p': 0.4230769230769231,\n",
       "    'f': 0.24719100710011369},\n",
       "   'rouge-2': {'r': 0.05714285714285714,\n",
       "    'p': 0.14814814814814814,\n",
       "    'f': 0.08247422278669378},\n",
       "   'rouge-l': {'r': 0.15873015873015872,\n",
       "    'p': 0.38461538461538464,\n",
       "    'f': 0.22471909698775408}},\n",
       "  {'rouge-1': {'r': 0.1746031746031746,\n",
       "    'p': 0.5789473684210527,\n",
       "    'f': 0.2682926793664485},\n",
       "   'rouge-2': {'r': 0.08571428571428572,\n",
       "    'p': 0.3157894736842105,\n",
       "    'f': 0.13483145731599552},\n",
       "   'rouge-l': {'r': 0.1746031746031746,\n",
       "    'p': 0.5789473684210527,\n",
       "    'f': 0.2682926793664485}},\n",
       "  {'rouge-1': {'r': 0.42857142857142855, 'p': 0.675, 'f': 0.5242718399095109},\n",
       "   'rouge-2': {'r': 0.2714285714285714,\n",
       "    'p': 0.41304347826086957,\n",
       "    'f': 0.3275862021105827},\n",
       "   'rouge-l': {'r': 0.3968253968253968, 'p': 0.625, 'f': 0.4854368884532002}},\n",
       "  {'rouge-1': {'r': 0.1111111111111111,\n",
       "    'p': 0.6363636363636364,\n",
       "    'f': 0.18918918665814466},\n",
       "   'rouge-2': {'r': 0.04285714285714286, 'p': 0.3, 'f': 0.07499999781250007},\n",
       "   'rouge-l': {'r': 0.09523809523809523,\n",
       "    'p': 0.5454545454545454,\n",
       "    'f': 0.16216215963111763}},\n",
       "  {'rouge-1': {'r': 0.4126984126984127, 'p': 0.65, 'f': 0.5048543641813555},\n",
       "   'rouge-2': {'r': 0.21428571428571427,\n",
       "    'p': 0.36585365853658536,\n",
       "    'f': 0.27027026561155754},\n",
       "   'rouge-l': {'r': 0.3968253968253968, 'p': 0.625, 'f': 0.4854368884532002}},\n",
       "  {'rouge-1': {'r': 0.6206896551724138,\n",
       "    'p': 0.6206896551724138,\n",
       "    'f': 0.6206896501724138},\n",
       "   'rouge-2': {'r': 0.391304347826087, 'p': 0.36, 'f': 0.3749999950086806},\n",
       "   'rouge-l': {'r': 0.603448275862069,\n",
       "    'p': 0.603448275862069,\n",
       "    'f': 0.603448270862069}},\n",
       "  {'rouge-1': {'r': 0.2413793103448276,\n",
       "    'p': 0.5384615384615384,\n",
       "    'f': 0.3333333290589569},\n",
       "   'rouge-2': {'r': 0.13043478260869565, 'p': 0.3, 'f': 0.18181817759412314},\n",
       "   'rouge-l': {'r': 0.2413793103448276,\n",
       "    'p': 0.5384615384615384,\n",
       "    'f': 0.3333333290589569}},\n",
       "  {'rouge-1': {'r': 0.3275862068965517,\n",
       "    'p': 0.5588235294117647,\n",
       "    'f': 0.4130434736011342},\n",
       "   'rouge-2': {'r': 0.17391304347826086, 'p': 0.3, 'f': 0.22018348159245865},\n",
       "   'rouge-l': {'r': 0.3275862068965517,\n",
       "    'p': 0.5588235294117647,\n",
       "    'f': 0.4130434736011342}},\n",
       "  {'rouge-1': {'r': 0.5517241379310345,\n",
       "    'p': 0.7441860465116279,\n",
       "    'f': 0.633663361446917},\n",
       "   'rouge-2': {'r': 0.391304347826087,\n",
       "    'p': 0.4909090909090909,\n",
       "    'f': 0.43548386603147765},\n",
       "   'rouge-l': {'r': 0.5517241379310345,\n",
       "    'p': 0.7441860465116279,\n",
       "    'f': 0.633663361446917}},\n",
       "  {'rouge-1': {'r': 0.27586206896551724,\n",
       "    'p': 0.5161290322580645,\n",
       "    'f': 0.359550557257922},\n",
       "   'rouge-2': {'r': 0.15942028985507245,\n",
       "    'p': 0.3142857142857143,\n",
       "    'f': 0.21153845707285512},\n",
       "   'rouge-l': {'r': 0.25862068965517243,\n",
       "    'p': 0.4838709677419355,\n",
       "    'f': 0.3370786471455625}},\n",
       "  {'rouge-1': {'r': 0.55, 'p': 0.3793103448275862, 'f': 0.4489795870054144},\n",
       "   'rouge-2': {'r': 0.25, 'p': 0.17857142857142858, 'f': 0.20833332847222233},\n",
       "   'rouge-l': {'r': 0.55, 'p': 0.3793103448275862, 'f': 0.4489795870054144}},\n",
       "  {'rouge-1': {'r': 0.6, 'p': 0.46153846153846156, 'f': 0.5217391255198489},\n",
       "   'rouge-2': {'r': 0.3, 'p': 0.2222222222222222, 'f': 0.2553191440470802},\n",
       "   'rouge-l': {'r': 0.6, 'p': 0.46153846153846156, 'f': 0.5217391255198489}},\n",
       "  {'rouge-1': {'r': 0.45, 'p': 0.375, 'f': 0.4090909041322315},\n",
       "   'rouge-2': {'r': 0.15, 'p': 0.13043478260869565, 'f': 0.13953487874526788},\n",
       "   'rouge-l': {'r': 0.4, 'p': 0.3333333333333333, 'f': 0.36363635867768596}},\n",
       "  {'rouge-1': {'r': 0.45, 'p': 0.18, 'f': 0.25714285306122453},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.07017543859649122, 'f': 0.10389610005059889},\n",
       "   'rouge-l': {'r': 0.45, 'p': 0.18, 'f': 0.25714285306122453}},\n",
       "  {'rouge-1': {'r': 0.15, 'p': 0.1875, 'f': 0.16666666172839517},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.15, 'p': 0.1875, 'f': 0.16666666172839517}},\n",
       "  {'rouge-1': {'r': 0.13793103448275862,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.19999999601250007},\n",
       "   'rouge-2': {'r': 0.10344827586206896, 'p': 0.3, 'f': 0.15384615003287322},\n",
       "   'rouge-l': {'r': 0.13793103448275862,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.19999999601250007}},\n",
       "  {'rouge-1': {'r': 0.20689655172413793,\n",
       "    'p': 0.5454545454545454,\n",
       "    'f': 0.29999999601250005},\n",
       "   'rouge-2': {'r': 0.06896551724137931, 'p': 0.2, 'f': 0.10256409875082198},\n",
       "   'rouge-l': {'r': 0.13793103448275862,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.19999999601250007}},\n",
       "  {'rouge-1': {'r': 0.3103448275862069,\n",
       "    'p': 0.6923076923076923,\n",
       "    'f': 0.42857142429705225},\n",
       "   'rouge-2': {'r': 0.20689655172413793,\n",
       "    'p': 0.46153846153846156,\n",
       "    'f': 0.28571428143990935},\n",
       "   'rouge-l': {'r': 0.3103448275862069,\n",
       "    'p': 0.6923076923076923,\n",
       "    'f': 0.42857142429705225}},\n",
       "  {'rouge-1': {'r': 0.1724137931034483,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.23255813514332083},\n",
       "   'rouge-2': {'r': 0.06896551724137931,\n",
       "    'p': 0.15384615384615385,\n",
       "    'f': 0.09523809096371902},\n",
       "   'rouge-l': {'r': 0.1724137931034483,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.23255813514332083}},\n",
       "  {'rouge-1': {'r': 0.7586206896551724,\n",
       "    'p': 0.6666666666666666,\n",
       "    'f': 0.7096774143756504},\n",
       "   'rouge-2': {'r': 0.6206896551724138,\n",
       "    'p': 0.5142857142857142,\n",
       "    'f': 0.5624999950439454},\n",
       "   'rouge-l': {'r': 0.6551724137931034,\n",
       "    'p': 0.5757575757575758,\n",
       "    'f': 0.6129032208272632}},\n",
       "  {'rouge-1': {'r': 0.47058823529411764, 'p': 0.5, 'f': 0.4848484798530762},\n",
       "   'rouge-2': {'r': 0.3157894736842105,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.3243243193279767},\n",
       "   'rouge-l': {'r': 0.47058823529411764, 'p': 0.5, 'f': 0.4848484798530762}},\n",
       "  {'rouge-1': {'r': 0.35294117647058826,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.3934426180166622},\n",
       "   'rouge-2': {'r': 0.18421052631578946,\n",
       "    'p': 0.23333333333333334,\n",
       "    'f': 0.20588234801038074},\n",
       "   'rouge-l': {'r': 0.35294117647058826,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.3934426180166622}},\n",
       "  {'rouge-1': {'r': 0.47058823529411764,\n",
       "    'p': 0.5925925925925926,\n",
       "    'f': 0.5245901590002687},\n",
       "   'rouge-2': {'r': 0.34210526315789475,\n",
       "    'p': 0.41935483870967744,\n",
       "    'f': 0.3768115892543584},\n",
       "   'rouge-l': {'r': 0.47058823529411764,\n",
       "    'p': 0.5925925925925926,\n",
       "    'f': 0.5245901590002687}},\n",
       "  {'rouge-1': {'r': 0.35294117647058826,\n",
       "    'p': 0.3870967741935484,\n",
       "    'f': 0.3692307642414202},\n",
       "   'rouge-2': {'r': 0.18421052631578946,\n",
       "    'p': 0.19444444444444445,\n",
       "    'f': 0.18918918419284161},\n",
       "   'rouge-l': {'r': 0.3235294117647059,\n",
       "    'p': 0.3548387096774194,\n",
       "    'f': 0.3384615334721894}},\n",
       "  {'rouge-1': {'r': 0.14705882352941177,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.22222221852839513},\n",
       "   'rouge-2': {'r': 0.05263157894736842,\n",
       "    'p': 0.18181818181818182,\n",
       "    'f': 0.08163264957934209},\n",
       "   'rouge-l': {'r': 0.14705882352941177,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.22222221852839513}},\n",
       "  {'rouge-1': {'r': 0.2857142857142857,\n",
       "    'p': 0.06896551724137931,\n",
       "    'f': 0.11111110797839514},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.2857142857142857,\n",
       "    'p': 0.06896551724137931,\n",
       "    'f': 0.11111110797839514}},\n",
       "  {'rouge-1': {'r': 0.42857142857142855,\n",
       "    'p': 0.0967741935483871,\n",
       "    'f': 0.15789473383656513},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.42857142857142855,\n",
       "    'p': 0.0967741935483871,\n",
       "    'f': 0.15789473383656513}},\n",
       "  {'rouge-1': {'r': 0.2857142857142857,\n",
       "    'p': 0.06060606060606061,\n",
       "    'f': 0.09999999711250009},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.2857142857142857,\n",
       "    'p': 0.06060606060606061,\n",
       "    'f': 0.09999999711250009}},\n",
       "  {'rouge-1': {'r': 0.14285714285714285,\n",
       "    'p': 0.03333333333333333,\n",
       "    'f': 0.054054050986121434},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.14285714285714285,\n",
       "    'p': 0.03333333333333333,\n",
       "    'f': 0.054054050986121434}},\n",
       "  {'rouge-1': {'r': 0.2857142857142857,\n",
       "    'p': 0.05555555555555555,\n",
       "    'f': 0.09302325308815583},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.2857142857142857,\n",
       "    'p': 0.05555555555555555,\n",
       "    'f': 0.09302325308815583}},\n",
       "  {'rouge-1': {'r': 0.4520547945205479,\n",
       "    'p': 0.44594594594594594,\n",
       "    'f': 0.44897958683696615},\n",
       "   'rouge-2': {'r': 0.21212121212121213,\n",
       "    'p': 0.21649484536082475,\n",
       "    'f': 0.214285709286235},\n",
       "   'rouge-l': {'r': 0.4246575342465753,\n",
       "    'p': 0.4189189189189189,\n",
       "    'f': 0.4217687024832246}},\n",
       "  {'rouge-1': {'r': 0.4794520547945205, 'p': 0.5, 'f': 0.48951048451269014},\n",
       "   'rouge-2': {'r': 0.21212121212121213,\n",
       "    'p': 0.22105263157894736,\n",
       "    'f': 0.2164948403629505},\n",
       "   'rouge-l': {'r': 0.4246575342465753,\n",
       "    'p': 0.44285714285714284,\n",
       "    'f': 0.4335664285686342}},\n",
       "  {'rouge-1': {'r': 0.2328767123287671,\n",
       "    'p': 0.2463768115942029,\n",
       "    'f': 0.23943661472227742},\n",
       "   'rouge-2': {'r': 0.08080808080808081,\n",
       "    'p': 0.09302325581395349,\n",
       "    'f': 0.08648648151117633},\n",
       "   'rouge-l': {'r': 0.2191780821917808,\n",
       "    'p': 0.2318840579710145,\n",
       "    'f': 0.2253521076800239}},\n",
       "  {'rouge-1': {'r': 0.3150684931506849,\n",
       "    'p': 0.696969696969697,\n",
       "    'f': 0.4339622598629406},\n",
       "   'rouge-2': {'r': 0.18181818181818182,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.2553191447532821},\n",
       "   'rouge-l': {'r': 0.2876712328767123,\n",
       "    'p': 0.6363636363636364,\n",
       "    'f': 0.3962264108063368}},\n",
       "  {'rouge-1': {'r': 0.3561643835616438,\n",
       "    'p': 0.49056603773584906,\n",
       "    'f': 0.41269840782438905},\n",
       "   'rouge-2': {'r': 0.12121212121212122,\n",
       "    'p': 0.17142857142857143,\n",
       "    'f': 0.14201182946675553},\n",
       "   'rouge-l': {'r': 0.3013698630136986,\n",
       "    'p': 0.41509433962264153,\n",
       "    'f': 0.3492063443323256}},\n",
       "  {'rouge-1': {'r': 0.6097560975609756,\n",
       "    'p': 0.7142857142857143,\n",
       "    'f': 0.6578947318732687},\n",
       "   'rouge-2': {'r': 0.46938775510204084,\n",
       "    'p': 0.5476190476190477,\n",
       "    'f': 0.5054945005240913},\n",
       "   'rouge-l': {'r': 0.5609756097560976,\n",
       "    'p': 0.6571428571428571,\n",
       "    'f': 0.6052631529259005}},\n",
       "  {'rouge-1': {'r': 0.3170731707317073, 'p': 0.8125, 'f': 0.45614034683902743},\n",
       "   'rouge-2': {'r': 0.16326530612244897,\n",
       "    'p': 0.5333333333333333,\n",
       "    'f': 0.24999999641113285},\n",
       "   'rouge-l': {'r': 0.3170731707317073,\n",
       "    'p': 0.8125,\n",
       "    'f': 0.45614034683902743}},\n",
       "  {'rouge-1': {'r': 0.5365853658536586,\n",
       "    'p': 0.5641025641025641,\n",
       "    'f': 0.5499999950031251},\n",
       "   'rouge-2': {'r': 0.32653061224489793,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.3298969022170263},\n",
       "   'rouge-l': {'r': 0.4878048780487805,\n",
       "    'p': 0.5128205128205128,\n",
       "    'f': 0.4999999950031251}},\n",
       "  {'rouge-1': {'r': 0.2926829268292683,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.3529411716825259},\n",
       "   'rouge-2': {'r': 0.10204081632653061,\n",
       "    'p': 0.16129032258064516,\n",
       "    'f': 0.1249999952531252},\n",
       "   'rouge-l': {'r': 0.24390243902439024,\n",
       "    'p': 0.37037037037037035,\n",
       "    'f': 0.29411764227076126}},\n",
       "  {'rouge-1': {'r': 0.2682926829268293,\n",
       "    'p': 0.39285714285714285,\n",
       "    'f': 0.31884057488762874},\n",
       "   'rouge-2': {'r': 0.08163265306122448, 'p': 0.125, 'f': 0.09876542731900649},\n",
       "   'rouge-l': {'r': 0.17073170731707318, 'p': 0.25, 'f': 0.2028985459021215}},\n",
       "  {'rouge-1': {'r': 0.1, 'p': 0.03225806451612903, 'f': 0.04878048411659754},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.1, 'p': 0.03225806451612903, 'f': 0.04878048411659754}},\n",
       "  {'rouge-1': {'r': 0.6, 'p': 0.12244897959183673, 'f': 0.2033898276931916},\n",
       "   'rouge-2': {'r': 0.4444444444444444,\n",
       "    'p': 0.06779661016949153,\n",
       "    'f': 0.11764705652681663},\n",
       "   'rouge-l': {'r': 0.6, 'p': 0.12244897959183673, 'f': 0.2033898276931916}},\n",
       "  {'rouge-1': {'r': 0.6, 'p': 0.12, 'f': 0.19999999722222223},\n",
       "   'rouge-2': {'r': 0.3333333333333333,\n",
       "    'p': 0.05084745762711865,\n",
       "    'f': 0.08823529182093431},\n",
       "   'rouge-l': {'r': 0.6, 'p': 0.12, 'f': 0.19999999722222223}},\n",
       "  {'rouge-1': {'r': 0.2, 'p': 0.07142857142857142, 'f': 0.10526315401662063},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.2, 'p': 0.07142857142857142, 'f': 0.10526315401662063}},\n",
       "  {'rouge-1': {'r': 0.1, 'p': 0.009345794392523364, 'f': 0.017094015530718237},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.1,\n",
       "    'p': 0.009345794392523364,\n",
       "    'f': 0.017094015530718237}},\n",
       "  {'rouge-1': {'r': 0.6029411764705882,\n",
       "    'p': 0.6612903225806451,\n",
       "    'f': 0.6307692257798817},\n",
       "   'rouge-2': {'r': 0.5161290322580645,\n",
       "    'p': 0.6153846153846154,\n",
       "    'f': 0.5614035038104033},\n",
       "   'rouge-l': {'r': 0.6029411764705882,\n",
       "    'p': 0.6612903225806451,\n",
       "    'f': 0.6307692257798817}},\n",
       "  {'rouge-1': {'r': 0.5588235294117647,\n",
       "    'p': 0.5757575757575758,\n",
       "    'f': 0.5671641741055915},\n",
       "   'rouge-2': {'r': 0.43010752688172044,\n",
       "    'p': 0.47058823529411764,\n",
       "    'f': 0.4494381972572908},\n",
       "   'rouge-l': {'r': 0.5588235294117647,\n",
       "    'p': 0.5757575757575758,\n",
       "    'f': 0.5671641741055915}},\n",
       "  {'rouge-1': {'r': 0.16176470588235295, 'p': 0.5, 'f': 0.24444444075061733},\n",
       "   'rouge-2': {'r': 0.07526881720430108,\n",
       "    'p': 0.2916666666666667,\n",
       "    'f': 0.11965811639710727},\n",
       "   'rouge-l': {'r': 0.14705882352941177,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.22222221852839513}},\n",
       "  {'rouge-1': {'r': 0.23529411764705882,\n",
       "    'p': 0.7619047619047619,\n",
       "    'f': 0.35955055819214743},\n",
       "   'rouge-2': {'r': 0.12903225806451613,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.19999999651250003},\n",
       "   'rouge-l': {'r': 0.20588235294117646,\n",
       "    'p': 0.6666666666666666,\n",
       "    'f': 0.31460673796742833}},\n",
       "  {'rouge-1': {'r': 0.6029411764705882,\n",
       "    'p': 0.6612903225806451,\n",
       "    'f': 0.6307692257798817},\n",
       "   'rouge-2': {'r': 0.4946236559139785,\n",
       "    'p': 0.6052631578947368,\n",
       "    'f': 0.5443786932754456},\n",
       "   'rouge-l': {'r': 0.6029411764705882,\n",
       "    'p': 0.6612903225806451,\n",
       "    'f': 0.6307692257798817}},\n",
       "  {'rouge-1': {'r': 0.5192307692307693,\n",
       "    'p': 0.7941176470588235,\n",
       "    'f': 0.6279069719632235},\n",
       "   'rouge-2': {'r': 0.4142857142857143,\n",
       "    'p': 0.6744186046511628,\n",
       "    'f': 0.5132743315686429},\n",
       "   'rouge-l': {'r': 0.4807692307692308,\n",
       "    'p': 0.7352941176470589,\n",
       "    'f': 0.5813953440562467}},\n",
       "  {'rouge-1': {'r': 0.46153846153846156,\n",
       "    'p': 0.7272727272727273,\n",
       "    'f': 0.5647058776027682},\n",
       "   'rouge-2': {'r': 0.32857142857142857, 'p': 0.575, 'f': 0.4181818135537191},\n",
       "   'rouge-l': {'r': 0.46153846153846156,\n",
       "    'p': 0.7272727272727273,\n",
       "    'f': 0.5647058776027682}},\n",
       "  {'rouge-1': {'r': 0.36538461538461536,\n",
       "    'p': 0.9047619047619048,\n",
       "    'f': 0.5205479411071496},\n",
       "   'rouge-2': {'r': 0.24285714285714285,\n",
       "    'p': 0.7727272727272727,\n",
       "    'f': 0.369565213752363},\n",
       "   'rouge-l': {'r': 0.36538461538461536,\n",
       "    'p': 0.9047619047619048,\n",
       "    'f': 0.5205479411071496}},\n",
       "  {'rouge-1': {'r': 0.28846153846153844,\n",
       "    'p': 0.6818181818181818,\n",
       "    'f': 0.4054054012271731},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.43478260869565216,\n",
       "    'f': 0.21505375971788648},\n",
       "   'rouge-l': {'r': 0.28846153846153844,\n",
       "    'p': 0.6818181818181818,\n",
       "    'f': 0.4054054012271731}},\n",
       "  {'rouge-1': {'r': 0.5576923076923077,\n",
       "    'p': 0.7073170731707317,\n",
       "    'f': 0.6236559090484449},\n",
       "   'rouge-2': {'r': 0.44285714285714284, 'p': 0.62, 'f': 0.5166666618055558},\n",
       "   'rouge-l': {'r': 0.5384615384615384,\n",
       "    'p': 0.6829268292682927,\n",
       "    'f': 0.6021505327043589}},\n",
       "  {'rouge-1': {'r': 0.36585365853658536,\n",
       "    'p': 0.8333333333333334,\n",
       "    'f': 0.5084745720310256},\n",
       "   'rouge-2': {'r': 0.19148936170212766, 'p': 0.5, 'f': 0.2769230729183432},\n",
       "   'rouge-l': {'r': 0.34146341463414637,\n",
       "    'p': 0.7777777777777778,\n",
       "    'f': 0.47457626694627986}},\n",
       "  {'rouge-1': {'r': 0.6585365853658537,\n",
       "    'p': 0.7297297297297297,\n",
       "    'f': 0.6923076873208417},\n",
       "   'rouge-2': {'r': 0.425531914893617,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.4395604345658737},\n",
       "   'rouge-l': {'r': 0.6341463414634146,\n",
       "    'p': 0.7027027027027027,\n",
       "    'f': 0.666666661679816}},\n",
       "  {'rouge-1': {'r': 0.3170731707317073,\n",
       "    'p': 0.5909090909090909,\n",
       "    'f': 0.41269840815318726},\n",
       "   'rouge-2': {'r': 0.10638297872340426,\n",
       "    'p': 0.22727272727272727,\n",
       "    'f': 0.14492753188825888},\n",
       "   'rouge-l': {'r': 0.2682926829268293, 'p': 0.5, 'f': 0.34920634466112377}},\n",
       "  {'rouge-1': {'r': 0.5853658536585366,\n",
       "    'p': 0.5714285714285714,\n",
       "    'f': 0.5783132480127741},\n",
       "   'rouge-2': {'r': 0.2978723404255319,\n",
       "    'p': 0.2916666666666667,\n",
       "    'f': 0.2947368371058172},\n",
       "   'rouge-l': {'r': 0.5609756097560976,\n",
       "    'p': 0.5476190476190477,\n",
       "    'f': 0.5542168624706055}},\n",
       "  {'rouge-1': {'r': 0.21951219512195122,\n",
       "    'p': 0.5294117647058824,\n",
       "    'f': 0.3103448234423306},\n",
       "   'rouge-2': {'r': 0.0851063829787234,\n",
       "    'p': 0.2222222222222222,\n",
       "    'f': 0.12307691907218948},\n",
       "   'rouge-l': {'r': 0.1951219512195122,\n",
       "    'p': 0.47058823529411764,\n",
       "    'f': 0.27586206482164094}},\n",
       "  {'rouge-1': {'r': 0.7, 'p': 0.5185185185185185, 'f': 0.5957446759619739},\n",
       "   'rouge-2': {'r': 0.5, 'p': 0.36666666666666664, 'f': 0.42307691819526627},\n",
       "   'rouge-l': {'r': 0.7, 'p': 0.5185185185185185, 'f': 0.5957446759619739}},\n",
       "  {'rouge-1': {'r': 0.7, 'p': 0.6666666666666666, 'f': 0.682926824271267},\n",
       "   'rouge-2': {'r': 0.5909090909090909, 'p': 0.52, 'f': 0.5531914843820736},\n",
       "   'rouge-l': {'r': 0.7, 'p': 0.6666666666666666, 'f': 0.682926824271267}},\n",
       "  {'rouge-1': {'r': 0.65, 'p': 0.4482758620689655, 'f': 0.530612240066639},\n",
       "   'rouge-2': {'r': 0.5909090909090909,\n",
       "    'p': 0.35135135135135137,\n",
       "    'f': 0.4406779614248779},\n",
       "   'rouge-l': {'r': 0.65, 'p': 0.4482758620689655, 'f': 0.530612240066639}},\n",
       "  {'rouge-1': {'r': 0.85, 'p': 0.85, 'f': 0.849999995},\n",
       "   'rouge-2': {'r': 0.7727272727272727,\n",
       "    'p': 0.7083333333333334,\n",
       "    'f': 0.7391304297920607},\n",
       "   'rouge-l': {'r': 0.85, 'p': 0.85, 'f': 0.849999995}},\n",
       "  {'rouge-1': {'r': 0.55, 'p': 0.3548387096774194, 'f': 0.4313725442522107},\n",
       "   'rouge-2': {'r': 0.36363636363636365,\n",
       "    'p': 0.2222222222222222,\n",
       "    'f': 0.2758620642568371},\n",
       "   'rouge-l': {'r': 0.5, 'p': 0.3225806451612903, 'f': 0.39215685797770095}},\n",
       "  {'rouge-1': {'r': 0.4426229508196721,\n",
       "    'p': 0.7105263157894737,\n",
       "    'f': 0.5454545407244159},\n",
       "   'rouge-2': {'r': 0.3472222222222222,\n",
       "    'p': 0.5681818181818182,\n",
       "    'f': 0.43103447804994055},\n",
       "   'rouge-l': {'r': 0.4426229508196721,\n",
       "    'p': 0.7105263157894737,\n",
       "    'f': 0.5454545407244159}},\n",
       "  {'rouge-1': {'r': 0.5737704918032787,\n",
       "    'p': 0.5932203389830508,\n",
       "    'f': 0.5833333283347223},\n",
       "   'rouge-2': {'r': 0.4027777777777778,\n",
       "    'p': 0.4027777777777778,\n",
       "    'f': 0.4027777727777778},\n",
       "   'rouge-l': {'r': 0.5737704918032787,\n",
       "    'p': 0.5932203389830508,\n",
       "    'f': 0.5833333283347223}},\n",
       "  {'rouge-1': {'r': 0.5901639344262295,\n",
       "    'p': 0.6206896551724138,\n",
       "    'f': 0.6050420118099005},\n",
       "   'rouge-2': {'r': 0.3472222222222222, 'p': 0.3125, 'f': 0.3289473634349031},\n",
       "   'rouge-l': {'r': 0.5573770491803278,\n",
       "    'p': 0.5862068965517241,\n",
       "    'f': 0.5714285664317493}},\n",
       "  {'rouge-1': {'r': 0.22950819672131148,\n",
       "    'p': 0.6363636363636364,\n",
       "    'f': 0.3373493936942953},\n",
       "   'rouge-2': {'r': 0.08333333333333333,\n",
       "    'p': 0.2608695652173913,\n",
       "    'f': 0.12631578580387823},\n",
       "   'rouge-l': {'r': 0.19672131147540983,\n",
       "    'p': 0.5454545454545454,\n",
       "    'f': 0.28915662260995795}},\n",
       "  {'rouge-1': {'r': 0.11475409836065574, 'p': 1.0, 'f': 0.2058823510942907},\n",
       "   'rouge-2': {'r': 0.08333333333333333, 'p': 1.0, 'f': 0.15384615242603553},\n",
       "   'rouge-l': {'r': 0.11475409836065574, 'p': 1.0, 'f': 0.2058823510942907}},\n",
       "  {'rouge-1': {'r': 0.35714285714285715,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.3571428521428572},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.1875, 'f': 0.19354838210197725},\n",
       "   'rouge-l': {'r': 0.35714285714285715,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.3571428521428572}},\n",
       "  {'rouge-1': {'r': 0.5, 'p': 0.4117647058823529, 'f': 0.4516128982726327},\n",
       "   'rouge-2': {'r': 0.4, 'p': 0.3333333333333333, 'f': 0.36363635867768596},\n",
       "   'rouge-l': {'r': 0.5, 'p': 0.4117647058823529, 'f': 0.4516128982726327}},\n",
       "  {'rouge-1': {'r': 0.5, 'p': 0.5, 'f': 0.4999999950000001},\n",
       "   'rouge-2': {'r': 0.3333333333333333,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.3333333283333334},\n",
       "   'rouge-l': {'r': 0.42857142857142855,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.4285714235714286}},\n",
       "  {'rouge-1': {'r': 0.42857142857142855, 'p': 0.5, 'f': 0.4615384565680473},\n",
       "   'rouge-2': {'r': 0.3333333333333333,\n",
       "    'p': 0.38461538461538464,\n",
       "    'f': 0.35714285216836733},\n",
       "   'rouge-l': {'r': 0.42857142857142855, 'p': 0.5, 'f': 0.4615384565680473}},\n",
       "  {'rouge-1': {'r': 0.6428571428571429, 'p': 0.5, 'f': 0.5624999950781251},\n",
       "   'rouge-2': {'r': 0.4, 'p': 0.3157894736842105, 'f': 0.35294117153979243},\n",
       "   'rouge-l': {'r': 0.5714285714285714,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.4999999950781251}},\n",
       "  {'rouge-1': {'r': 0.6206896551724138,\n",
       "    'p': 0.5142857142857142,\n",
       "    'f': 0.5624999950439454},\n",
       "   'rouge-2': {'r': 0.36363636363636365,\n",
       "    'p': 0.26666666666666666,\n",
       "    'f': 0.3076923028106509},\n",
       "   'rouge-l': {'r': 0.5862068965517241,\n",
       "    'p': 0.4857142857142857,\n",
       "    'f': 0.5312499950439454}},\n",
       "  {'rouge-1': {'r': 0.6206896551724138, 'p': 0.6, 'f': 0.6101694865268602},\n",
       "   'rouge-2': {'r': 0.5151515151515151,\n",
       "    'p': 0.4146341463414634,\n",
       "    'f': 0.4594594545178963},\n",
       "   'rouge-l': {'r': 0.5862068965517241,\n",
       "    'p': 0.5666666666666667,\n",
       "    'f': 0.5762711814421144}},\n",
       "  {'rouge-1': {'r': 0.20689655172413793, 'p': 0.5, 'f': 0.2926829226888757},\n",
       "   'rouge-2': {'r': 0.06060606060606061,\n",
       "    'p': 0.15384615384615385,\n",
       "    'f': 0.0869565176843102},\n",
       "   'rouge-l': {'r': 0.20689655172413793, 'p': 0.5, 'f': 0.2926829226888757}},\n",
       "  {'rouge-1': {'r': 0.3793103448275862,\n",
       "    'p': 0.5789473684210527,\n",
       "    'f': 0.45833332855034725},\n",
       "   'rouge-2': {'r': 0.09090909090909091,\n",
       "    'p': 0.14285714285714285,\n",
       "    'f': 0.11111110635802489},\n",
       "   'rouge-l': {'r': 0.2413793103448276,\n",
       "    'p': 0.3684210526315789,\n",
       "    'f': 0.2916666618836806}},\n",
       "  {'rouge-1': {'r': 0.5862068965517241,\n",
       "    'p': 0.7083333333333334,\n",
       "    'f': 0.6415094290067641},\n",
       "   'rouge-2': {'r': 0.5454545454545454, 'p': 0.5625, 'f': 0.5538461488473373},\n",
       "   'rouge-l': {'r': 0.5862068965517241,\n",
       "    'p': 0.7083333333333334,\n",
       "    'f': 0.6415094290067641}},\n",
       "  {'rouge-1': {'r': 0.8541666666666666,\n",
       "    'p': 0.7592592592592593,\n",
       "    'f': 0.803921563644752},\n",
       "   'rouge-2': {'r': 0.6229508196721312,\n",
       "    'p': 0.5428571428571428,\n",
       "    'f': 0.5801526667793252},\n",
       "   'rouge-l': {'r': 0.8125, 'p': 0.7222222222222222, 'f': 0.7647058773702423}},\n",
       "  {'rouge-1': {'r': 0.25, 'p': 0.6, 'f': 0.3529411723183391},\n",
       "   'rouge-2': {'r': 0.09836065573770492,\n",
       "    'p': 0.2608695652173913,\n",
       "    'f': 0.1428571388803856},\n",
       "   'rouge-l': {'r': 0.22916666666666666, 'p': 0.55, 'f': 0.32352940761245674}},\n",
       "  {'rouge-1': {'r': 0.22916666666666666,\n",
       "    'p': 0.4782608695652174,\n",
       "    'f': 0.3098591505494942},\n",
       "   'rouge-2': {'r': 0.14754098360655737,\n",
       "    'p': 0.32142857142857145,\n",
       "    'f': 0.20224718669864927},\n",
       "   'rouge-l': {'r': 0.20833333333333334,\n",
       "    'p': 0.43478260869565216,\n",
       "    'f': 0.28169013646498714}},\n",
       "  {'rouge-1': {'r': 0.4583333333333333,\n",
       "    'p': 0.5945945945945946,\n",
       "    'f': 0.5176470539072665},\n",
       "   'rouge-2': {'r': 0.22950819672131148,\n",
       "    'p': 0.34146341463414637,\n",
       "    'f': 0.27450979911380247},\n",
       "   'rouge-l': {'r': 0.375, 'p': 0.4864864864864865, 'f': 0.423529406848443}},\n",
       "  {'rouge-1': {'r': 0.125, 'p': 0.5454545454545454, 'f': 0.20338982747486356},\n",
       "   'rouge-2': {'r': 0.03278688524590164,\n",
       "    'p': 0.18181818181818182,\n",
       "    'f': 0.05555555296682112},\n",
       "   'rouge-l': {'r': 0.125, 'p': 0.5454545454545454, 'f': 0.20338982747486356}},\n",
       "  {'rouge-1': {'r': 0.16842105263157894,\n",
       "    'p': 0.9411764705882353,\n",
       "    'f': 0.2857142831393495},\n",
       "   'rouge-2': {'r': 0.1076923076923077,\n",
       "    'p': 0.8235294117647058,\n",
       "    'f': 0.19047618843074646},\n",
       "   'rouge-l': {'r': 0.16842105263157894,\n",
       "    'p': 0.9411764705882353,\n",
       "    'f': 0.2857142831393495}},\n",
       "  {'rouge-1': {'r': 0.42105263157894735,\n",
       "    'p': 0.5555555555555556,\n",
       "    'f': 0.47904191126250495},\n",
       "   'rouge-2': {'r': 0.15384615384615385,\n",
       "    'p': 0.21505376344086022,\n",
       "    'f': 0.1793721924470632},\n",
       "   'rouge-l': {'r': 0.3368421052631579,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.38323352802897204}},\n",
       "  {'rouge-1': {'r': 0.21052631578947367,\n",
       "    'p': 0.6896551724137931,\n",
       "    'f': 0.3225806415777836},\n",
       "   'rouge-2': {'r': 0.046153846153846156,\n",
       "    'p': 0.1875,\n",
       "    'f': 0.07407407090382578},\n",
       "   'rouge-l': {'r': 0.18947368421052632,\n",
       "    'p': 0.6206896551724138,\n",
       "    'f': 0.29032257706165454}},\n",
       "  {'rouge-1': {'r': 0.23157894736842105,\n",
       "    'p': 0.8148148148148148,\n",
       "    'f': 0.36065573425826397},\n",
       "   'rouge-2': {'r': 0.07692307692307693,\n",
       "    'p': 0.2702702702702703,\n",
       "    'f': 0.11976047559252762},\n",
       "   'rouge-l': {'r': 0.22105263157894736,\n",
       "    'p': 0.7777777777777778,\n",
       "    'f': 0.34426229163531313}},\n",
       "  {'rouge-1': {'r': 0.22105263157894736,\n",
       "    'p': 0.6774193548387096,\n",
       "    'f': 0.33333332962333084},\n",
       "   'rouge-2': {'r': 0.038461538461538464,\n",
       "    'p': 0.125,\n",
       "    'f': 0.058823525813149015},\n",
       "   'rouge-l': {'r': 0.18947368421052632,\n",
       "    'p': 0.5806451612903226,\n",
       "    'f': 0.2857142820042832}},\n",
       "  {'rouge-1': {'r': 0.34146341463414637,\n",
       "    'p': 0.2916666666666667,\n",
       "    'f': 0.3146067366039642},\n",
       "   'rouge-2': {'r': 0.14814814814814814,\n",
       "    'p': 0.12307692307692308,\n",
       "    'f': 0.1344537765553282},\n",
       "   'rouge-l': {'r': 0.3170731707317073,\n",
       "    'p': 0.2708333333333333,\n",
       "    'f': 0.2921348264916046}},\n",
       "  {'rouge-1': {'r': 0.6829268292682927,\n",
       "    'p': 0.7368421052631579,\n",
       "    'f': 0.7088607545008814},\n",
       "   'rouge-2': {'r': 0.5185185185185185,\n",
       "    'p': 0.509090909090909,\n",
       "    'f': 0.5137614628903292},\n",
       "   'rouge-l': {'r': 0.6341463414634146,\n",
       "    'p': 0.6842105263157895,\n",
       "    'f': 0.6582278431084763}},\n",
       "  {'rouge-1': {'r': 0.7317073170731707,\n",
       "    'p': 0.7692307692307693,\n",
       "    'f': 0.749999995003125},\n",
       "   'rouge-2': {'r': 0.7037037037037037,\n",
       "    'p': 0.7037037037037037,\n",
       "    'f': 0.7037036987037039},\n",
       "   'rouge-l': {'r': 0.7073170731707317,\n",
       "    'p': 0.7435897435897436,\n",
       "    'f': 0.7249999950031251}},\n",
       "  {'rouge-1': {'r': 0.7073170731707317, 'p': 0.725, 'f': 0.7160493777168117},\n",
       "   'rouge-2': {'r': 0.5, 'p': 0.4909090909090909, 'f': 0.4954128390371181},\n",
       "   'rouge-l': {'r': 0.6829268292682927, 'p': 0.7, 'f': 0.6913580196921202}},\n",
       "  {'rouge-1': {'r': 0.6585365853658537,\n",
       "    'p': 0.8181818181818182,\n",
       "    'f': 0.7297297247881666},\n",
       "   'rouge-2': {'r': 0.5185185185185185,\n",
       "    'p': 0.5490196078431373,\n",
       "    'f': 0.5333333283374151},\n",
       "   'rouge-l': {'r': 0.6585365853658537,\n",
       "    'p': 0.8181818181818182,\n",
       "    'f': 0.7297297247881666}},\n",
       "  {'rouge-1': {'r': 0.12162162162162163,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.18947368076675905},\n",
       "   'rouge-2': {'r': 0.023809523809523808,\n",
       "    'p': 0.08695652173913043,\n",
       "    'f': 0.03738317419512652},\n",
       "   'rouge-l': {'r': 0.10810810810810811,\n",
       "    'p': 0.38095238095238093,\n",
       "    'f': 0.1684210491878117}},\n",
       "  {'rouge-1': {'r': 0.3918918918918919,\n",
       "    'p': 0.5686274509803921,\n",
       "    'f': 0.46399999516928003},\n",
       "   'rouge-2': {'r': 0.23809523809523808,\n",
       "    'p': 0.3448275862068966,\n",
       "    'f': 0.28169013601269594},\n",
       "   'rouge-l': {'r': 0.35135135135135137,\n",
       "    'p': 0.5098039215686274,\n",
       "    'f': 0.41599999516928005}},\n",
       "  {'rouge-1': {'r': 0.13513513513513514,\n",
       "    'p': 0.3225806451612903,\n",
       "    'f': 0.19047618631473934},\n",
       "   'rouge-2': {'r': 0.03571428571428571,\n",
       "    'p': 0.08333333333333333,\n",
       "    'f': 0.049999995800000356},\n",
       "   'rouge-l': {'r': 0.13513513513513514,\n",
       "    'p': 0.3225806451612903,\n",
       "    'f': 0.19047618631473934}},\n",
       "  {'rouge-1': {'r': 0.24324324324324326,\n",
       "    'p': 0.5454545454545454,\n",
       "    'f': 0.3364485938649664},\n",
       "   'rouge-2': {'r': 0.08333333333333333,\n",
       "    'p': 0.18421052631578946,\n",
       "    'f': 0.11475409407148632},\n",
       "   'rouge-l': {'r': 0.21621621621621623,\n",
       "    'p': 0.48484848484848486,\n",
       "    'f': 0.299065416294873}},\n",
       "  {'rouge-1': {'r': 0.4594594594594595,\n",
       "    'p': 0.38202247191011235,\n",
       "    'f': 0.4171779091527721},\n",
       "   'rouge-2': {'r': 0.30952380952380953,\n",
       "    'p': 0.22608695652173913,\n",
       "    'f': 0.26130652778465197},\n",
       "   'rouge-l': {'r': 0.44594594594594594,\n",
       "    'p': 0.3707865168539326,\n",
       "    'f': 0.40490797050246535}},\n",
       "  {'rouge-1': {'r': 0.2088607594936709,\n",
       "    'p': 0.6111111111111112,\n",
       "    'f': 0.3113207509202564},\n",
       "   'rouge-2': {'r': 0.08571428571428572,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.13636363310950422},\n",
       "   'rouge-l': {'r': 0.189873417721519,\n",
       "    'p': 0.5555555555555556,\n",
       "    'f': 0.2830188641278035}},\n",
       "  {'rouge-1': {'r': 0.17088607594936708, 'p': 0.54, 'f': 0.2596153809633876},\n",
       "   'rouge-2': {'r': 0.07346938775510205,\n",
       "    'p': 0.2535211267605634,\n",
       "    'f': 0.11392404714889454},\n",
       "   'rouge-l': {'r': 0.15822784810126583, 'p': 0.5, 'f': 0.2403846117326184}},\n",
       "  {'rouge-1': {'r': 0.2848101265822785,\n",
       "    'p': 0.6617647058823529,\n",
       "    'f': 0.39823008428851125},\n",
       "   'rouge-2': {'r': 0.1673469387755102,\n",
       "    'p': 0.40594059405940597,\n",
       "    'f': 0.23699421551922892},\n",
       "   'rouge-l': {'r': 0.27848101265822783,\n",
       "    'p': 0.6470588235294118,\n",
       "    'f': 0.38938052676638735}},\n",
       "  {'rouge-1': {'r': 0.25949367088607594,\n",
       "    'p': 0.7884615384615384,\n",
       "    'f': 0.3904761867501135},\n",
       "   'rouge-2': {'r': 0.12653061224489795,\n",
       "    'p': 0.4626865671641791,\n",
       "    'f': 0.19871794534537315},\n",
       "   'rouge-l': {'r': 0.24050632911392406,\n",
       "    'p': 0.7307692307692307,\n",
       "    'f': 0.3619047581786848}},\n",
       "  {'rouge-1': {'r': 0.35443037974683544,\n",
       "    'p': 0.7567567567567568,\n",
       "    'f': 0.48275861634512496},\n",
       "   'rouge-2': {'r': 0.23265306122448978,\n",
       "    'p': 0.59375,\n",
       "    'f': 0.33431084639450986},\n",
       "   'rouge-l': {'r': 0.34177215189873417,\n",
       "    'p': 0.7297297297297297,\n",
       "    'f': 0.4655172370347801}},\n",
       "  {'rouge-1': {'r': 0.3684210526315789,\n",
       "    'p': 0.2692307692307692,\n",
       "    'f': 0.3111111062320988},\n",
       "   'rouge-2': {'r': 0.14705882352941177,\n",
       "    'p': 0.09345794392523364,\n",
       "    'f': 0.11428570953404102},\n",
       "   'rouge-l': {'r': 0.3684210526315789,\n",
       "    'p': 0.2692307692307692,\n",
       "    'f': 0.3111111062320988}},\n",
       "  {'rouge-1': {'r': 0.22807017543859648,\n",
       "    'p': 0.2653061224489796,\n",
       "    'f': 0.2452830138964045},\n",
       "   'rouge-2': {'r': 0.07352941176470588,\n",
       "    'p': 0.08333333333333333,\n",
       "    'f': 0.07812499501953157},\n",
       "   'rouge-l': {'r': 0.21052631578947367,\n",
       "    'p': 0.24489795918367346,\n",
       "    'f': 0.22641508936810262}},\n",
       "  {'rouge-1': {'r': 0.2807017543859649,\n",
       "    'p': 0.2077922077922078,\n",
       "    'f': 0.23880596526063722},\n",
       "   'rouge-2': {'r': 0.058823529411764705,\n",
       "    'p': 0.04040404040404041,\n",
       "    'f': 0.04790418678905711},\n",
       "   'rouge-l': {'r': 0.2631578947368421,\n",
       "    'p': 0.19480519480519481,\n",
       "    'f': 0.22388059212630887}},\n",
       "  {'rouge-1': {'r': 0.14035087719298245,\n",
       "    'p': 0.6153846153846154,\n",
       "    'f': 0.2285714255469388},\n",
       "   'rouge-2': {'r': 0.029411764705882353,\n",
       "    'p': 0.15384615384615385,\n",
       "    'f': 0.04938271335467169},\n",
       "   'rouge-l': {'r': 0.14035087719298245,\n",
       "    'p': 0.6153846153846154,\n",
       "    'f': 0.2285714255469388}},\n",
       "  {'rouge-1': {'r': 0.40350877192982454,\n",
       "    'p': 0.4339622641509434,\n",
       "    'f': 0.4181818131884298},\n",
       "   'rouge-2': {'r': 0.16176470588235295,\n",
       "    'p': 0.1506849315068493,\n",
       "    'f': 0.1560283638006138},\n",
       "   'rouge-l': {'r': 0.40350877192982454,\n",
       "    'p': 0.4339622641509434,\n",
       "    'f': 0.4181818131884298}},\n",
       "  {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       "  {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       "  {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       "  {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       "  {'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}},\n",
       "  {'rouge-1': {'r': 0.38202247191011235,\n",
       "    'p': 0.576271186440678,\n",
       "    'f': 0.4594594546649014},\n",
       "   'rouge-2': {'r': 0.18421052631578946,\n",
       "    'p': 0.2916666666666667,\n",
       "    'f': 0.2258064468678461},\n",
       "   'rouge-l': {'r': 0.34831460674157305,\n",
       "    'p': 0.5254237288135594,\n",
       "    'f': 0.4189189141243609}},\n",
       "  {'rouge-1': {'r': 0.16853932584269662,\n",
       "    'p': 0.7142857142857143,\n",
       "    'f': 0.2727272696380165},\n",
       "   'rouge-2': {'r': 0.05263157894736842, 'p': 0.3, 'f': 0.08955223626642911},\n",
       "   'rouge-l': {'r': 0.14606741573033707,\n",
       "    'p': 0.6190476190476191,\n",
       "    'f': 0.23636363327438017}},\n",
       "  {'rouge-1': {'r': 0.30337078651685395,\n",
       "    'p': 0.3698630136986301,\n",
       "    'f': 0.33333332838210644},\n",
       "   'rouge-2': {'r': 0.13157894736842105,\n",
       "    'p': 0.16853932584269662,\n",
       "    'f': 0.1477832463073602},\n",
       "   'rouge-l': {'r': 0.2696629213483146,\n",
       "    'p': 0.3287671232876712,\n",
       "    'f': 0.2962962913450694}},\n",
       "  {'rouge-1': {'r': 0.12359550561797752,\n",
       "    'p': 0.7857142857142857,\n",
       "    'f': 0.21359223066075975},\n",
       "   'rouge-2': {'r': 0.06140350877192982,\n",
       "    'p': 0.5384615384615384,\n",
       "    'f': 0.1102362186347573},\n",
       "   'rouge-l': {'r': 0.12359550561797752,\n",
       "    'p': 0.7857142857142857,\n",
       "    'f': 0.21359223066075975}},\n",
       "  {'rouge-1': {'r': 0.19101123595505617,\n",
       "    'p': 0.6538461538461539,\n",
       "    'f': 0.2956521704136106},\n",
       "   'rouge-2': {'r': 0.017543859649122806,\n",
       "    'p': 0.06451612903225806,\n",
       "    'f': 0.027586203534839884},\n",
       "   'rouge-l': {'r': 0.14606741573033707, 'p': 0.5, 'f': 0.22608695302230625}},\n",
       "  {'rouge-1': {'r': 0.36363636363636365,\n",
       "    'p': 0.425531914893617,\n",
       "    'f': 0.39215685777585546},\n",
       "   'rouge-2': {'r': 0.136986301369863,\n",
       "    'p': 0.16666666666666666,\n",
       "    'f': 0.15037593489739404},\n",
       "   'rouge-l': {'r': 0.32727272727272727,\n",
       "    'p': 0.3829787234042553,\n",
       "    'f': 0.3529411715013457}},\n",
       "  {'rouge-1': {'r': 0.4727272727272727,\n",
       "    'p': 0.4482758620689655,\n",
       "    'f': 0.46017698615396674},\n",
       "   'rouge-2': {'r': 0.2602739726027397, 'p': 0.2375, 'f': 0.2483660080823616},\n",
       "   'rouge-l': {'r': 0.45454545454545453,\n",
       "    'p': 0.43103448275862066,\n",
       "    'f': 0.44247787110971887}},\n",
       "  {'rouge-1': {'r': 0.41818181818181815,\n",
       "    'p': 0.5348837209302325,\n",
       "    'f': 0.46938775017700957},\n",
       "   'rouge-2': {'r': 0.1917808219178082,\n",
       "    'p': 0.24561403508771928,\n",
       "    'f': 0.21538461046035515},\n",
       "   'rouge-l': {'r': 0.41818181818181815,\n",
       "    'p': 0.5348837209302325,\n",
       "    'f': 0.46938775017700957}},\n",
       "  {'rouge-1': {'r': 0.3090909090909091,\n",
       "    'p': 0.3469387755102041,\n",
       "    'f': 0.326923071939719},\n",
       "   'rouge-2': {'r': 0.1232876712328767,\n",
       "    'p': 0.140625,\n",
       "    'f': 0.13138685633544694},\n",
       "   'rouge-l': {'r': 0.2909090909090909,\n",
       "    'p': 0.32653061224489793,\n",
       "    'f': 0.3076923027089497}},\n",
       "  {'rouge-1': {'r': 0.41818181818181815,\n",
       "    'p': 0.2839506172839506,\n",
       "    'f': 0.33823528930038926},\n",
       "   'rouge-2': {'r': 0.1917808219178082,\n",
       "    'p': 0.12173913043478261,\n",
       "    'f': 0.14893616546231342},\n",
       "   'rouge-l': {'r': 0.4, 'p': 0.2716049382716049, 'f': 0.32352940694744814}},\n",
       "  {'rouge-1': {'r': 0.43137254901960786,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.47311827461671874},\n",
       "   'rouge-2': {'r': 0.22033898305084745,\n",
       "    'p': 0.2653061224489796,\n",
       "    'f': 0.2407407357836078},\n",
       "   'rouge-l': {'r': 0.4117647058823529, 'p': 0.5, 'f': 0.4516128982726327}},\n",
       "  {'rouge-1': {'r': 0.2549019607843137,\n",
       "    'p': 0.4482758620689655,\n",
       "    'f': 0.324999995378125},\n",
       "   'rouge-2': {'r': 0.1016949152542373, 'p': 0.1875, 'f': 0.13186812730829625},\n",
       "   'rouge-l': {'r': 0.2549019607843137,\n",
       "    'p': 0.4482758620689655,\n",
       "    'f': 0.324999995378125}},\n",
       "  {'rouge-1': {'r': 0.17647058823529413,\n",
       "    'p': 0.2727272727272727,\n",
       "    'f': 0.2142857095153062},\n",
       "   'rouge-2': {'r': 0.03389830508474576,\n",
       "    'p': 0.05263157894736842,\n",
       "    'f': 0.0412371086364125},\n",
       "   'rouge-l': {'r': 0.13725490196078433,\n",
       "    'p': 0.21212121212121213,\n",
       "    'f': 0.16666666189625867}},\n",
       "  {'rouge-1': {'r': 0.09803921568627451,\n",
       "    'p': 0.38461538461538464,\n",
       "    'f': 0.1562499967626954},\n",
       "   'rouge-2': {'r': 0.01694915254237288,\n",
       "    'p': 0.07692307692307693,\n",
       "    'f': 0.027777774818673155},\n",
       "   'rouge-l': {'r': 0.0784313725490196,\n",
       "    'p': 0.3076923076923077,\n",
       "    'f': 0.1249999967626954}},\n",
       "  {'rouge-1': {'r': 0.09803921568627451,\n",
       "    'p': 0.14705882352941177,\n",
       "    'f': 0.1176470540235296},\n",
       "   'rouge-2': {'r': 0.01694915254237288,\n",
       "    'p': 0.023255813953488372,\n",
       "    'f': 0.01960783826028572},\n",
       "   'rouge-l': {'r': 0.09803921568627451,\n",
       "    'p': 0.14705882352941177,\n",
       "    'f': 0.1176470540235296}},\n",
       "  {'rouge-1': {'r': 0.39361702127659576,\n",
       "    'p': 0.5211267605633803,\n",
       "    'f': 0.4484848435820019},\n",
       "   'rouge-2': {'r': 0.19166666666666668,\n",
       "    'p': 0.25842696629213485,\n",
       "    'f': 0.2200956888899065},\n",
       "   'rouge-l': {'r': 0.3723404255319149,\n",
       "    'p': 0.49295774647887325,\n",
       "    'f': 0.42424241933957757}},\n",
       "  {'rouge-1': {'r': 0.30851063829787234,\n",
       "    'p': 0.5272727272727272,\n",
       "    'f': 0.38926174030899513},\n",
       "   'rouge-2': {'r': 0.10833333333333334, 'p': 0.2, 'f': 0.1405405359824691},\n",
       "   'rouge-l': {'r': 0.26595744680851063,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.33557046514120986}},\n",
       "  {'rouge-1': {'r': 0.43617021276595747,\n",
       "    'p': 0.6307692307692307,\n",
       "    'f': 0.5157232656065821},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.2823529411764706, 'f': 0.23414633660916132},\n",
       "   'rouge-l': {'r': 0.3829787234042553,\n",
       "    'p': 0.5538461538461539,\n",
       "    'f': 0.4528301838455758}},\n",
       "  {'rouge-1': {'r': 0.30851063829787234,\n",
       "    'p': 0.5178571428571429,\n",
       "    'f': 0.3866666619875556},\n",
       "   'rouge-2': {'r': 0.11666666666666667,\n",
       "    'p': 0.18666666666666668,\n",
       "    'f': 0.14358973885601592},\n",
       "   'rouge-l': {'r': 0.23404255319148937,\n",
       "    'p': 0.39285714285714285,\n",
       "    'f': 0.2933333286542223}},\n",
       "  {'rouge-1': {'r': 0.2872340425531915,\n",
       "    'p': 0.5869565217391305,\n",
       "    'f': 0.3857142813020409},\n",
       "   'rouge-2': {'r': 0.10833333333333334,\n",
       "    'p': 0.24528301886792453,\n",
       "    'f': 0.1502890130909821},\n",
       "   'rouge-l': {'r': 0.2553191489361702,\n",
       "    'p': 0.5217391304347826,\n",
       "    'f': 0.3428571384448979}},\n",
       "  {'rouge-1': {'r': 0.5238095238095238,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.5238095188095239},\n",
       "   'rouge-2': {'r': 0.3958333333333333,\n",
       "    'p': 0.3584905660377358,\n",
       "    'f': 0.37623761877462997},\n",
       "   'rouge-l': {'r': 0.47619047619047616,\n",
       "    'p': 0.47619047619047616,\n",
       "    'f': 0.4761904711904762}},\n",
       "  {'rouge-1': {'r': 0.40476190476190477,\n",
       "    'p': 0.4857142857142857,\n",
       "    'f': 0.44155843659976396},\n",
       "   'rouge-2': {'r': 0.2708333333333333, 'p': 0.325, 'f': 0.2954545404958678},\n",
       "   'rouge-l': {'r': 0.40476190476190477,\n",
       "    'p': 0.4857142857142857,\n",
       "    'f': 0.44155843659976396}},\n",
       "  {'rouge-1': {'r': 0.38095238095238093, 'p': 0.5, 'f': 0.43243242752373995},\n",
       "   'rouge-2': {'r': 0.2916666666666667,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.31111110613333337},\n",
       "   'rouge-l': {'r': 0.35714285714285715,\n",
       "    'p': 0.46875,\n",
       "    'f': 0.405405400496713}},\n",
       "  {'rouge-1': {'r': 0.7619047619047619,\n",
       "    'p': 0.5079365079365079,\n",
       "    'f': 0.6095238047238095},\n",
       "   'rouge-2': {'r': 0.5208333333333334,\n",
       "    'p': 0.2976190476190476,\n",
       "    'f': 0.37878787415977966},\n",
       "   'rouge-l': {'r': 0.7380952380952381,\n",
       "    'p': 0.49206349206349204,\n",
       "    'f': 0.5904761856761905}},\n",
       "  {'rouge-1': {'r': 0.5952380952380952,\n",
       "    'p': 0.5319148936170213,\n",
       "    'f': 0.5617977478247695},\n",
       "   'rouge-2': {'r': 0.4166666666666667,\n",
       "    'p': 0.3076923076923077,\n",
       "    'f': 0.3539822959981205},\n",
       "   'rouge-l': {'r': 0.5476190476190477,\n",
       "    'p': 0.48936170212765956,\n",
       "    'f': 0.5168539276000507}},\n",
       "  {'rouge-1': {'r': 0.6071428571428571,\n",
       "    'p': 0.576271186440678,\n",
       "    'f': 0.5913043428294897},\n",
       "   'rouge-2': {'r': 0.4142857142857143,\n",
       "    'p': 0.43283582089552236,\n",
       "    'f': 0.4233576592359743},\n",
       "   'rouge-l': {'r': 0.5714285714285714,\n",
       "    'p': 0.5423728813559322,\n",
       "    'f': 0.5565217341338374}},\n",
       "  {'rouge-1': {'r': 0.4107142857142857,\n",
       "    'p': 0.5476190476190477,\n",
       "    'f': 0.4693877502040817},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.3111111111111111, 'f': 0.2434782561058602},\n",
       "   'rouge-l': {'r': 0.39285714285714285,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.44897958693877554}},\n",
       "  {'rouge-1': {'r': 0.23214285714285715,\n",
       "    'p': 0.48148148148148145,\n",
       "    'f': 0.3132530076585862},\n",
       "   'rouge-2': {'r': 0.1, 'p': 0.2692307692307692, 'f': 0.14583332938368065},\n",
       "   'rouge-l': {'r': 0.21428571428571427,\n",
       "    'p': 0.4444444444444444,\n",
       "    'f': 0.2891566221164175}},\n",
       "  {'rouge-1': {'r': 0.32142857142857145,\n",
       "    'p': 0.34615384615384615,\n",
       "    'f': 0.3333333283401921},\n",
       "   'rouge-2': {'r': 0.1, 'p': 0.1, 'f': 0.09999999500000027},\n",
       "   'rouge-l': {'r': 0.32142857142857145,\n",
       "    'p': 0.34615384615384615,\n",
       "    'f': 0.3333333283401921}},\n",
       "  {'rouge-1': {'r': 0.2857142857142857,\n",
       "    'p': 0.41025641025641024,\n",
       "    'f': 0.33684210042326873},\n",
       "   'rouge-2': {'r': 0.12857142857142856, 'p': 0.2, 'f': 0.15652173436672984},\n",
       "   'rouge-l': {'r': 0.2857142857142857,\n",
       "    'p': 0.41025641025641024,\n",
       "    'f': 0.33684210042326873}},\n",
       "  {'rouge-1': {'r': 0.379746835443038,\n",
       "    'p': 0.6666666666666666,\n",
       "    'f': 0.48387096311784605},\n",
       "   'rouge-2': {'r': 0.24489795918367346,\n",
       "    'p': 0.42105263157894735,\n",
       "    'f': 0.30967741470468263},\n",
       "   'rouge-l': {'r': 0.34177215189873417, 'p': 0.6, 'f': 0.4354838663436525}},\n",
       "  {'rouge-1': {'r': 0.35443037974683544,\n",
       "    'p': 0.6511627906976745,\n",
       "    'f': 0.45901638887798996},\n",
       "   'rouge-2': {'r': 0.23469387755102042,\n",
       "    'p': 0.42592592592592593,\n",
       "    'f': 0.3026315743663436},\n",
       "   'rouge-l': {'r': 0.3291139240506329,\n",
       "    'p': 0.6046511627906976,\n",
       "    'f': 0.42622950363208817}},\n",
       "  {'rouge-1': {'r': 0.27848101265822783,\n",
       "    'p': 0.38596491228070173,\n",
       "    'f': 0.323529406895545},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.20588235294117646,\n",
       "    'f': 0.16867469395848467},\n",
       "   'rouge-l': {'r': 0.26582278481012656,\n",
       "    'p': 0.3684210526315789,\n",
       "    'f': 0.30882352454260387}},\n",
       "  {'rouge-1': {'r': 0.31645569620253167,\n",
       "    'p': 0.5681818181818182,\n",
       "    'f': 0.406504060445502},\n",
       "   'rouge-2': {'r': 0.22448979591836735, 'p': 0.4, 'f': 0.2875816947413389},\n",
       "   'rouge-l': {'r': 0.31645569620253167,\n",
       "    'p': 0.5681818181818182,\n",
       "    'f': 0.406504060445502}},\n",
       "  {'rouge-1': {'r': 0.22784810126582278, 'p': 0.6, 'f': 0.330275225368235},\n",
       "   'rouge-2': {'r': 0.1326530612244898,\n",
       "    'p': 0.3939393939393939,\n",
       "    'f': 0.198473278673737},\n",
       "   'rouge-l': {'r': 0.22784810126582278, 'p': 0.6, 'f': 0.330275225368235}},\n",
       "  {'rouge-1': {'r': 0.14772727272727273,\n",
       "    'p': 0.5909090909090909,\n",
       "    'f': 0.23636363316363643},\n",
       "   'rouge-2': {'r': 0.059322033898305086,\n",
       "    'p': 0.30434782608695654,\n",
       "    'f': 0.09929077741159908},\n",
       "   'rouge-l': {'r': 0.14772727272727273,\n",
       "    'p': 0.5909090909090909,\n",
       "    'f': 0.23636363316363643}},\n",
       "  {'rouge-1': {'r': 0.18181818181818182,\n",
       "    'p': 0.5714285714285714,\n",
       "    'f': 0.27586206530321045},\n",
       "   'rouge-2': {'r': 0.0847457627118644,\n",
       "    'p': 0.30303030303030304,\n",
       "    'f': 0.13245032771018825},\n",
       "   'rouge-l': {'r': 0.1590909090909091, 'p': 0.5, 'f': 0.24137930668252086}},\n",
       "  {'rouge-1': {'r': 0.4318181818181818,\n",
       "    'p': 0.6229508196721312,\n",
       "    'f': 0.5100671092581416},\n",
       "   'rouge-2': {'r': 0.2542372881355932,\n",
       "    'p': 0.36585365853658536,\n",
       "    'f': 0.29999999516200004},\n",
       "   'rouge-l': {'r': 0.3977272727272727,\n",
       "    'p': 0.5737704918032787,\n",
       "    'f': 0.4697986528823026}},\n",
       "  {'rouge-1': {'r': 0.11363636363636363,\n",
       "    'p': 0.5263157894736842,\n",
       "    'f': 0.1869158849296882},\n",
       "   'rouge-2': {'r': 0.0423728813559322,\n",
       "    'p': 0.2777777777777778,\n",
       "    'f': 0.07352940946799315},\n",
       "   'rouge-l': {'r': 0.10227272727272728,\n",
       "    'p': 0.47368421052631576,\n",
       "    'f': 0.16822429614464152}},\n",
       "  {'rouge-1': {'r': 0.32954545454545453,\n",
       "    'p': 0.42028985507246375,\n",
       "    'f': 0.36942674666558484},\n",
       "   'rouge-2': {'r': 0.1271186440677966,\n",
       "    'p': 0.18072289156626506,\n",
       "    'f': 0.14925372649488888},\n",
       "   'rouge-l': {'r': 0.32954545454545453,\n",
       "    'p': 0.42028985507246375,\n",
       "    'f': 0.36942674666558484}},\n",
       "  {'rouge-1': {'r': 0.35384615384615387,\n",
       "    'p': 0.6571428571428571,\n",
       "    'f': 0.45999999545000014},\n",
       "   'rouge-2': {'r': 0.24719101123595505,\n",
       "    'p': 0.4489795918367347,\n",
       "    'f': 0.3188405751302248},\n",
       "   'rouge-l': {'r': 0.3384615384615385,\n",
       "    'p': 0.6285714285714286,\n",
       "    'f': 0.43999999545000007}},\n",
       "  {'rouge-1': {'r': 0.16923076923076924, 'p': 0.6875, 'f': 0.2716049351013565},\n",
       "   'rouge-2': {'r': 0.0449438202247191,\n",
       "    'p': 0.23529411764705882,\n",
       "    'f': 0.07547169542007842},\n",
       "   'rouge-l': {'r': 0.15384615384615385,\n",
       "    'p': 0.625,\n",
       "    'f': 0.24691357707666517}},\n",
       "  {'rouge-1': {'r': 0.3384615384615385, 'p': 0.55, 'f': 0.4190476143310658},\n",
       "   'rouge-2': {'r': 0.1797752808988764,\n",
       "    'p': 0.3076923076923077,\n",
       "    'f': 0.22695034995422775},\n",
       "   'rouge-l': {'r': 0.3384615384615385, 'p': 0.55, 'f': 0.4190476143310658}},\n",
       "  {'rouge-1': {'r': 0.2, 'p': 0.65, 'f': 0.30588234934256053},\n",
       "   'rouge-2': {'r': 0.06741573033707865, 'p': 0.3, 'f': 0.11009174012288536},\n",
       "   'rouge-l': {'r': 0.16923076923076924, 'p': 0.55, 'f': 0.2588235258131488}},\n",
       "  {'rouge-1': {'r': 0.16923076923076924, 'p': 0.6875, 'f': 0.2716049351013565},\n",
       "   'rouge-2': {'r': 0.056179775280898875,\n",
       "    'p': 0.29411764705882354,\n",
       "    'f': 0.09433961994838029},\n",
       "   'rouge-l': {'r': 0.15384615384615385,\n",
       "    'p': 0.625,\n",
       "    'f': 0.24691357707666517}},\n",
       "  {'rouge-1': {'r': 0.38461538461538464,\n",
       "    'p': 0.3472222222222222,\n",
       "    'f': 0.36496349866268846},\n",
       "   'rouge-2': {'r': 0.20512820512820512,\n",
       "    'p': 0.1797752808988764,\n",
       "    'f': 0.19161676148875914},\n",
       "   'rouge-l': {'r': 0.35384615384615387,\n",
       "    'p': 0.3194444444444444,\n",
       "    'f': 0.3357664183707177}},\n",
       "  {'rouge-1': {'r': 0.3076923076923077,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.3199999950080001},\n",
       "   'rouge-2': {'r': 0.11538461538461539,\n",
       "    'p': 0.1232876712328767,\n",
       "    'f': 0.11920529301872745},\n",
       "   'rouge-l': {'r': 0.27692307692307694, 'p': 0.3, 'f': 0.2879999950080001}},\n",
       "  {'rouge-1': {'r': 0.4, 'p': 0.32098765432098764, 'f': 0.3561643786216927},\n",
       "   'rouge-2': {'r': 0.20512820512820512,\n",
       "    'p': 0.15841584158415842,\n",
       "    'f': 0.178770944803221},\n",
       "   'rouge-l': {'r': 0.38461538461538464,\n",
       "    'p': 0.30864197530864196,\n",
       "    'f': 0.34246574848470634}},\n",
       "  {'rouge-1': {'r': 0.2, 'p': 0.22807017543859648, 'f': 0.2131147491198604},\n",
       "   'rouge-2': {'r': 0.05128205128205128,\n",
       "    'p': 0.056338028169014086,\n",
       "    'f': 0.05369127017882125},\n",
       "   'rouge-l': {'r': 0.15384615384615385,\n",
       "    'p': 0.17543859649122806,\n",
       "    'f': 0.16393442125100796}},\n",
       "  {'rouge-1': {'r': 0.3384615384615385,\n",
       "    'p': 0.3384615384615385,\n",
       "    'f': 0.33846153346153857},\n",
       "   'rouge-2': {'r': 0.11538461538461539,\n",
       "    'p': 0.1111111111111111,\n",
       "    'f': 0.11320754217159153},\n",
       "   'rouge-l': {'r': 0.27692307692307694,\n",
       "    'p': 0.27692307692307694,\n",
       "    'f': 0.276923071923077}},\n",
       "  {'rouge-1': {'r': 0.36363636363636365,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.3636363586363637},\n",
       "   'rouge-2': {'r': 0.21621621621621623,\n",
       "    'p': 0.20512820512820512,\n",
       "    'f': 0.2105263107929364},\n",
       "   'rouge-l': {'r': 0.36363636363636365,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.3636363586363637}},\n",
       "  {'rouge-1': {'r': 0.5151515151515151,\n",
       "    'p': 0.4146341463414634,\n",
       "    'f': 0.4594594545178963},\n",
       "   'rouge-2': {'r': 0.2702702702702703, 'p': 0.2, 'f': 0.22988505258290406},\n",
       "   'rouge-l': {'r': 0.48484848484848486,\n",
       "    'p': 0.3902439024390244,\n",
       "    'f': 0.43243242749086924}},\n",
       "  {'rouge-1': {'r': 0.36363636363636365,\n",
       "    'p': 0.3157894736842105,\n",
       "    'f': 0.33802816403888125},\n",
       "   'rouge-2': {'r': 0.13513513513513514,\n",
       "    'p': 0.11627906976744186,\n",
       "    'f': 0.1249999950281252},\n",
       "   'rouge-l': {'r': 0.3333333333333333,\n",
       "    'p': 0.2894736842105263,\n",
       "    'f': 0.3098591499543742}},\n",
       "  {'rouge-1': {'r': 0.12121212121212122,\n",
       "    'p': 0.26666666666666666,\n",
       "    'f': 0.16666666236979177},\n",
       "   'rouge-2': {'r': 0.02702702702702703,\n",
       "    'p': 0.07142857142857142,\n",
       "    'f': 0.03921568229142678},\n",
       "   'rouge-l': {'r': 0.09090909090909091, 'p': 0.2, 'f': 0.12499999570312517}},\n",
       "  {'rouge-1': {'r': 0.45454545454545453,\n",
       "    'p': 0.32608695652173914,\n",
       "    'f': 0.379746830578433},\n",
       "   'rouge-2': {'r': 0.24324324324324326,\n",
       "    'p': 0.16363636363636364,\n",
       "    'f': 0.19565216910444247},\n",
       "   'rouge-l': {'r': 0.45454545454545453,\n",
       "    'p': 0.32608695652173914,\n",
       "    'f': 0.379746830578433}},\n",
       "  {'rouge-1': {'r': 0.45, 'p': 0.2857142857142857, 'f': 0.3495145583561127},\n",
       "   'rouge-2': {'r': 0.13043478260869565,\n",
       "    'p': 0.07142857142857142,\n",
       "    'f': 0.09230768773491146},\n",
       "   'rouge-l': {'r': 0.25, 'p': 0.15873015873015872, 'f': 0.19417475253087013}},\n",
       "  {'rouge-1': {'r': 0.5, 'p': 0.36363636363636365, 'f': 0.42105262670360116},\n",
       "   'rouge-2': {'r': 0.21739130434782608,\n",
       "    'p': 0.136986301369863,\n",
       "    'f': 0.1680672221481535},\n",
       "   'rouge-l': {'r': 0.425, 'p': 0.3090909090909091, 'f': 0.35789473196675897}},\n",
       "  {'rouge-1': {'r': 0.15, 'p': 0.35294117647058826, 'f': 0.21052631160357038},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.1, 'p': 0.23529411764705882, 'f': 0.1403508730070792}},\n",
       "  {'rouge-1': {'r': 0.325, 'p': 0.26, 'f': 0.2888888839506174},\n",
       "   'rouge-2': {'r': 0.08695652173913043,\n",
       "    'p': 0.07272727272727272,\n",
       "    'f': 0.07920791583178151},\n",
       "   'rouge-l': {'r': 0.275, 'p': 0.22, 'f': 0.24444443950617298}},\n",
       "  {'rouge-1': {'r': 0.125, 'p': 0.3333333333333333, 'f': 0.18181817785123974},\n",
       "   'rouge-2': {'r': 0.06521739130434782, 'p': 0.2, 'f': 0.0983606520290246},\n",
       "   'rouge-l': {'r': 0.125, 'p': 0.3333333333333333, 'f': 0.18181817785123974}},\n",
       "  {'rouge-1': {'r': 0.48484848484848486,\n",
       "    'p': 0.48484848484848486,\n",
       "    'f': 0.4848484798484849},\n",
       "   'rouge-2': {'r': 0.2571428571428571,\n",
       "    'p': 0.23076923076923078,\n",
       "    'f': 0.24324323825785255},\n",
       "   'rouge-l': {'r': 0.42424242424242425,\n",
       "    'p': 0.42424242424242425,\n",
       "    'f': 0.42424241924242434}},\n",
       "  {'rouge-1': {'r': 0.3333333333333333,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.40740740265432096},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.22727272727272727,\n",
       "    'f': 0.17543859175130824},\n",
       "   'rouge-l': {'r': 0.2727272727272727,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.3333333285802469}},\n",
       "  {'rouge-1': {'r': 0.3333333333333333,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.40740740265432096},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.23809523809523808,\n",
       "    'f': 0.1785714238839287},\n",
       "   'rouge-l': {'r': 0.2727272727272727,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.3333333285802469}},\n",
       "  {'rouge-1': {'r': 0.24242424242424243,\n",
       "    'p': 0.42105263157894735,\n",
       "    'f': 0.3076923030547338},\n",
       "   'rouge-2': {'r': 0.11428571428571428,\n",
       "    'p': 0.18181818181818182,\n",
       "    'f': 0.14035087245306266},\n",
       "   'rouge-l': {'r': 0.24242424242424243,\n",
       "    'p': 0.42105263157894735,\n",
       "    'f': 0.3076923030547338}},\n",
       "  {'rouge-1': {'r': 0.12121212121212122,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.1818181780681819},\n",
       "   'rouge-2': {'r': 0.05714285714285714,\n",
       "    'p': 0.18181818181818182,\n",
       "    'f': 0.08695651810018919},\n",
       "   'rouge-l': {'r': 0.12121212121212122,\n",
       "    'p': 0.36363636363636365,\n",
       "    'f': 0.1818181780681819}},\n",
       "  {'rouge-1': {'r': 0.2962962962962963,\n",
       "    'p': 0.1702127659574468,\n",
       "    'f': 0.21621621158144638},\n",
       "   'rouge-2': {'r': 0.14705882352941177,\n",
       "    'p': 0.07142857142857142,\n",
       "    'f': 0.09615384175295877},\n",
       "   'rouge-l': {'r': 0.2962962962962963,\n",
       "    'p': 0.1702127659574468,\n",
       "    'f': 0.21621621158144638}},\n",
       "  {'rouge-1': {'r': 0.25925925925925924,\n",
       "    'p': 0.30434782608695654,\n",
       "    'f': 0.27999999503200007},\n",
       "   'rouge-2': {'r': 0.11764705882352941,\n",
       "    'p': 0.15384615384615385,\n",
       "    'f': 0.1333333284222224},\n",
       "   'rouge-l': {'r': 0.25925925925925924,\n",
       "    'p': 0.30434782608695654,\n",
       "    'f': 0.27999999503200007}},\n",
       "  {'rouge-1': {'r': 0.2222222222222222, 'p': 0.24, 'f': 0.2307692257766273},\n",
       "   'rouge-2': {'r': 0.14705882352941177,\n",
       "    'p': 0.18518518518518517,\n",
       "    'f': 0.16393442129535088},\n",
       "   'rouge-l': {'r': 0.2222222222222222, 'p': 0.24, 'f': 0.2307692257766273}},\n",
       "  {'rouge-1': {'r': 0.2222222222222222,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.2926829223319453},\n",
       "   'rouge-2': {'r': 0.11764705882352941,\n",
       "    'p': 0.3076923076923077,\n",
       "    'f': 0.17021276195563612},\n",
       "   'rouge-l': {'r': 0.2222222222222222,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.2926829223319453}},\n",
       "  {'rouge-1': {'r': 0.37037037037037035,\n",
       "    'p': 0.30303030303030304,\n",
       "    'f': 0.33333332838333335},\n",
       "   'rouge-2': {'r': 0.20588235294117646,\n",
       "    'p': 0.16666666666666666,\n",
       "    'f': 0.18421052137119123},\n",
       "   'rouge-l': {'r': 0.37037037037037035,\n",
       "    'p': 0.30303030303030304,\n",
       "    'f': 0.33333332838333335}},\n",
       "  {'rouge-1': {'r': 0.4, 'p': 0.4444444444444444, 'f': 0.42105262659279785},\n",
       "   'rouge-2': {'r': 0.1791044776119403,\n",
       "    'p': 0.20689655172413793,\n",
       "    'f': 0.19199999502592013},\n",
       "   'rouge-l': {'r': 0.32, 'p': 0.35555555555555557, 'f': 0.33684210027700834}},\n",
       "  {'rouge-1': {'r': 0.24, 'p': 0.23076923076923078, 'f': 0.23529411264898129},\n",
       "   'rouge-2': {'r': 0.04477611940298507,\n",
       "    'p': 0.037037037037037035,\n",
       "    'f': 0.04054053558528184},\n",
       "   'rouge-l': {'r': 0.22, 'p': 0.21153846153846154, 'f': 0.21568626951172637}},\n",
       "  {'rouge-1': {'r': 0.32, 'p': 0.4444444444444444, 'f': 0.37209301838831804},\n",
       "   'rouge-2': {'r': 0.14925373134328357,\n",
       "    'p': 0.2127659574468085,\n",
       "    'f': 0.17543859164512174},\n",
       "   'rouge-l': {'r': 0.3, 'p': 0.4166666666666667, 'f': 0.3488372044348297}},\n",
       "  {'rouge-1': {'r': 0.2, 'p': 0.6666666666666666, 'f': 0.3076923041420118},\n",
       "   'rouge-2': {'r': 0.16417910447761194,\n",
       "    'p': 0.5789473684210527,\n",
       "    'f': 0.25581395004597085},\n",
       "   'rouge-l': {'r': 0.2, 'p': 0.6666666666666666, 'f': 0.3076923041420118}},\n",
       "  {'rouge-1': {'r': 0.06, 'p': 0.21428571428571427, 'f': 0.09374999658203137},\n",
       "   'rouge-2': {'r': 0.029850746268656716,\n",
       "    'p': 0.15384615384615385,\n",
       "    'f': 0.049999997278125145},\n",
       "   'rouge-l': {'r': 0.06, 'p': 0.21428571428571427, 'f': 0.09374999658203137}},\n",
       "  {'rouge-1': {'r': 0.42, 'p': 0.5384615384615384, 'f': 0.47191010743592976},\n",
       "   'rouge-2': {'r': 0.2833333333333333,\n",
       "    'p': 0.3148148148148148,\n",
       "    'f': 0.2982456090489382},\n",
       "   'rouge-l': {'r': 0.38, 'p': 0.48717948717948717, 'f': 0.42696628721121077}},\n",
       "  {'rouge-1': {'r': 0.28, 'p': 0.3181818181818182, 'f': 0.2978723354459032},\n",
       "   'rouge-2': {'r': 0.15, 'p': 0.16981132075471697, 'f': 0.15929203041741732},\n",
       "   'rouge-l': {'r': 0.26, 'p': 0.29545454545454547, 'f': 0.27659573970122237}},\n",
       "  {'rouge-1': {'r': 0.34, 'p': 0.4722222222222222, 'f': 0.39534883234180646},\n",
       "   'rouge-2': {'r': 0.16666666666666666,\n",
       "    'p': 0.2222222222222222,\n",
       "    'f': 0.19047618557823143},\n",
       "   'rouge-l': {'r': 0.32, 'p': 0.4444444444444444, 'f': 0.37209301838831804}},\n",
       "  {'rouge-1': {'r': 0.36, 'p': 0.5454545454545454, 'f': 0.43373493496879084},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.2926829268292683, 'f': 0.23762375755318116},\n",
       "   'rouge-l': {'r': 0.36, 'p': 0.5454545454545454, 'f': 0.43373493496879084}},\n",
       "  {'rouge-1': {'r': 0.44, 'p': 0.44, 'f': 0.43999999500000003},\n",
       "   'rouge-2': {'r': 0.18333333333333332,\n",
       "    'p': 0.18032786885245902,\n",
       "    'f': 0.18181817681852347},\n",
       "   'rouge-l': {'r': 0.36, 'p': 0.36, 'f': 0.359999995}},\n",
       "  {'rouge-1': {'r': 0.3584905660377358,\n",
       "    'p': 0.6129032258064516,\n",
       "    'f': 0.4523809477239229},\n",
       "   'rouge-2': {'r': 0.17543859649122806,\n",
       "    'p': 0.2857142857142857,\n",
       "    'f': 0.217391299633743},\n",
       "   'rouge-l': {'r': 0.33962264150943394,\n",
       "    'p': 0.5806451612903226,\n",
       "    'f': 0.4285714239143991}},\n",
       "  {'rouge-1': {'r': 0.41509433962264153,\n",
       "    'p': 0.4074074074074074,\n",
       "    'f': 0.4112149482714648},\n",
       "   'rouge-2': {'r': 0.24561403508771928,\n",
       "    'p': 0.2153846153846154,\n",
       "    'f': 0.22950819174281117},\n",
       "   'rouge-l': {'r': 0.39622641509433965,\n",
       "    'p': 0.3888888888888889,\n",
       "    'f': 0.3925233594864181}},\n",
       "  {'rouge-1': {'r': 0.41509433962264153,\n",
       "    'p': 0.6285714285714286,\n",
       "    'f': 0.4999999952091944},\n",
       "   'rouge-2': {'r': 0.24561403508771928,\n",
       "    'p': 0.3783783783783784,\n",
       "    'f': 0.2978723356518787},\n",
       "   'rouge-l': {'r': 0.39622641509433965, 'p': 0.6, 'f': 0.47727272248192154}},\n",
       "  {'rouge-1': {'r': 0.37735849056603776,\n",
       "    'p': 0.4166666666666667,\n",
       "    'f': 0.39603959897264984},\n",
       "   'rouge-2': {'r': 0.21052631578947367,\n",
       "    'p': 0.21818181818181817,\n",
       "    'f': 0.21428570928730878},\n",
       "   'rouge-l': {'r': 0.37735849056603776,\n",
       "    'p': 0.4166666666666667,\n",
       "    'f': 0.39603959897264984}},\n",
       "  {'rouge-1': {'r': 0.1509433962264151,\n",
       "    'p': 0.42105263157894735,\n",
       "    'f': 0.2222222183371914},\n",
       "   'rouge-2': {'r': 0.05263157894736842,\n",
       "    'p': 0.16666666666666666,\n",
       "    'f': 0.07999999635200017},\n",
       "   'rouge-l': {'r': 0.1509433962264151,\n",
       "    'p': 0.42105263157894735,\n",
       "    'f': 0.2222222183371914}},\n",
       "  {'rouge-1': {'r': 0.42105263157894735,\n",
       "    'p': 0.25806451612903225,\n",
       "    'f': 0.319999995288},\n",
       "   'rouge-2': {'r': 0.3, 'p': 0.18181818181818182, 'f': 0.22641508964044152},\n",
       "   'rouge-l': {'r': 0.42105263157894735,\n",
       "    'p': 0.25806451612903225,\n",
       "    'f': 0.319999995288}},\n",
       "  {'rouge-1': {'r': 0.5263157894736842,\n",
       "    'p': 0.38461538461538464,\n",
       "    'f': 0.4444444395654321},\n",
       "   'rouge-2': {'r': 0.35, 'p': 0.2413793103448276, 'f': 0.28571428088296547},\n",
       "   'rouge-l': {'r': 0.47368421052631576,\n",
       "    'p': 0.34615384615384615,\n",
       "    'f': 0.39999999512098766}},\n",
       "  {'rouge-1': {'r': 0.3684210526315789,\n",
       "    'p': 0.18421052631578946,\n",
       "    'f': 0.24561403064327492},\n",
       "   'rouge-2': {'r': 0.15, 'p': 0.06666666666666667, 'f': 0.09230768804733748},\n",
       "   'rouge-l': {'r': 0.3157894736842105,\n",
       "    'p': 0.15789473684210525,\n",
       "    'f': 0.21052631134502933}},\n",
       "  {'rouge-1': {'r': 0.3157894736842105, 'p': 0.5, 'f': 0.3870967694484912},\n",
       "   'rouge-2': {'r': 0.15, 'p': 0.2727272727272727, 'f': 0.19354838251821027},\n",
       "   'rouge-l': {'r': 0.2631578947368421,\n",
       "    'p': 0.4166666666666667,\n",
       "    'f': 0.32258064041623313}},\n",
       "  {'rouge-1': {'r': 0.5263157894736842,\n",
       "    'p': 0.2127659574468085,\n",
       "    'f': 0.3030302989302112},\n",
       "   'rouge-2': {'r': 0.35, 'p': 0.1044776119402985, 'f': 0.16091953668912679},\n",
       "   'rouge-l': {'r': 0.5263157894736842,\n",
       "    'p': 0.2127659574468085,\n",
       "    'f': 0.3030302989302112}},\n",
       "  {'rouge-1': {'r': 0.10638297872340426,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.16393442269282457},\n",
       "   'rouge-2': {'r': 0.015625,\n",
       "    'p': 0.07692307692307693,\n",
       "    'f': 0.025974023167482173},\n",
       "   'rouge-l': {'r': 0.10638297872340426,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.16393442269282457}},\n",
       "  {'rouge-1': {'r': 0.5106382978723404,\n",
       "    'p': 0.7741935483870968,\n",
       "    'f': 0.6153846105950033},\n",
       "   'rouge-2': {'r': 0.3125, 'p': 0.5714285714285714, 'f': 0.40404039946944187},\n",
       "   'rouge-l': {'r': 0.5106382978723404,\n",
       "    'p': 0.7741935483870968,\n",
       "    'f': 0.6153846105950033}},\n",
       "  {'rouge-1': {'r': 0.1702127659574468, 'p': 0.8, 'f': 0.280701751492767},\n",
       "   'rouge-2': {'r': 0.0625, 'p': 0.4444444444444444, 'f': 0.10958903893413402},\n",
       "   'rouge-l': {'r': 0.1702127659574468, 'p': 0.8, 'f': 0.280701751492767}},\n",
       "  {'rouge-1': {'r': 0.1276595744680851,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.19672130793872616},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.10638297872340426,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.16393442269282457}},\n",
       "  {'rouge-1': {'r': 0.0851063829787234, 'p': 0.4, 'f': 0.1403508742997846},\n",
       "   'rouge-2': {'r': 0.03125,\n",
       "    'p': 0.2222222222222222,\n",
       "    'f': 0.054794518386188866},\n",
       "   'rouge-l': {'r': 0.0851063829787234, 'p': 0.4, 'f': 0.1403508742997846}},\n",
       "  {'rouge-1': {'r': 0.42105263157894735,\n",
       "    'p': 0.5333333333333333,\n",
       "    'f': 0.4705882303633218},\n",
       "   'rouge-2': {'r': 0.25, 'p': 0.29411764705882354, 'f': 0.270270265303141},\n",
       "   'rouge-l': {'r': 0.42105263157894735,\n",
       "    'p': 0.5333333333333333,\n",
       "    'f': 0.4705882303633218}},\n",
       "  {'rouge-1': {'r': 0.3684210526315789,\n",
       "    'p': 0.5833333333333334,\n",
       "    'f': 0.45161289848074926},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.3076923076923077, 'f': 0.24242423764921955},\n",
       "   'rouge-l': {'r': 0.3684210526315789,\n",
       "    'p': 0.5833333333333334,\n",
       "    'f': 0.45161289848074926}},\n",
       "  {'rouge-1': {'r': 0.2894736842105263, 'p': 0.5, 'f': 0.36666666202222226},\n",
       "   'rouge-2': {'r': 0.175, 'p': 0.2916666666666667, 'f': 0.21874999531250008},\n",
       "   'rouge-l': {'r': 0.2631578947368421,\n",
       "    'p': 0.45454545454545453,\n",
       "    'f': 0.33333332868888893}},\n",
       "  {'rouge-1': {'r': 0.15789473684210525,\n",
       "    'p': 0.42857142857142855,\n",
       "    'f': 0.23076922683431958},\n",
       "   'rouge-2': {'r': 0.075, 'p': 0.23076923076923078, 'f': 0.11320754346742624},\n",
       "   'rouge-l': {'r': 0.13157894736842105,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.19230768837278112}},\n",
       "  {'rouge-1': {'r': 0.3157894736842105,\n",
       "    'p': 0.5714285714285714,\n",
       "    'f': 0.40677965643205977},\n",
       "   'rouge-2': {'r': 0.2, 'p': 0.34782608695652173, 'f': 0.2539682493323256},\n",
       "   'rouge-l': {'r': 0.2894736842105263,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.37288135134731404}},\n",
       "  {'rouge-1': {'r': 0.896551724137931,\n",
       "    'p': 0.7027027027027027,\n",
       "    'f': 0.7878787829522499},\n",
       "   'rouge-2': {'r': 0.8055555555555556,\n",
       "    'p': 0.6444444444444445,\n",
       "    'f': 0.7160493777777778},\n",
       "   'rouge-l': {'r': 0.896551724137931,\n",
       "    'p': 0.7027027027027027,\n",
       "    'f': 0.7878787829522499}},\n",
       "  {'rouge-1': {'r': 0.6896551724137931,\n",
       "    'p': 0.6060606060606061,\n",
       "    'f': 0.6451612853433925},\n",
       "   'rouge-2': {'r': 0.4166666666666667,\n",
       "    'p': 0.39473684210526316,\n",
       "    'f': 0.4054054004090578},\n",
       "   'rouge-l': {'r': 0.6206896551724138,\n",
       "    'p': 0.5454545454545454,\n",
       "    'f': 0.5806451563111343}},\n",
       "  {'rouge-1': {'r': 0.4827586206896552,\n",
       "    'p': 0.42424242424242425,\n",
       "    'f': 0.45161289824661816},\n",
       "   'rouge-2': {'r': 0.1388888888888889,\n",
       "    'p': 0.13157894736842105,\n",
       "    'f': 0.1351351301387876},\n",
       "   'rouge-l': {'r': 0.4482758620689655,\n",
       "    'p': 0.3939393939393939,\n",
       "    'f': 0.4193548337304891}},\n",
       "  {'rouge-1': {'r': 0.5172413793103449,\n",
       "    'p': 0.7894736842105263,\n",
       "    'f': 0.6249999952170139},\n",
       "   'rouge-2': {'r': 0.5833333333333334, 'p': 0.75, 'f': 0.656249995078125},\n",
       "   'rouge-l': {'r': 0.5172413793103449,\n",
       "    'p': 0.7894736842105263,\n",
       "    'f': 0.6249999952170139}},\n",
       "  {'rouge-1': {'r': 0.13793103448275862,\n",
       "    'p': 0.07017543859649122,\n",
       "    'f': 0.09302325134396992},\n",
       "   'rouge-2': {'r': 0.027777777777777776,\n",
       "    'p': 0.013513513513513514,\n",
       "    'f': 0.018181813778513464},\n",
       "   'rouge-l': {'r': 0.13793103448275862,\n",
       "    'p': 0.07017543859649122,\n",
       "    'f': 0.09302325134396992}},\n",
       "  {'rouge-1': {'r': 0.37142857142857144,\n",
       "    'p': 0.5416666666666666,\n",
       "    'f': 0.4406779612754956},\n",
       "   'rouge-2': {'r': 0.21686746987951808,\n",
       "    'p': 0.3103448275862069,\n",
       "    'f': 0.25531914409335554},\n",
       "   'rouge-l': {'r': 0.37142857142857144,\n",
       "    'p': 0.5416666666666666,\n",
       "    'f': 0.4406779612754956}},\n",
       "  {'rouge-1': {'r': 0.44285714285714284,\n",
       "    'p': 0.484375,\n",
       "    'f': 0.4626865621742036},\n",
       "   'rouge-2': {'r': 0.3253012048192771, 'p': 0.3, 'f': 0.3121387233318855},\n",
       "   'rouge-l': {'r': 0.42857142857142855,\n",
       "    'p': 0.46875,\n",
       "    'f': 0.4477611890398752}},\n",
       "  {'rouge-1': {'r': 0.37142857142857144,\n",
       "    'p': 0.6842105263157895,\n",
       "    'f': 0.4814814769204391},\n",
       "   'rouge-2': {'r': 0.24096385542168675,\n",
       "    'p': 0.43478260869565216,\n",
       "    'f': 0.3100775147911784},\n",
       "   'rouge-l': {'r': 0.32857142857142857,\n",
       "    'p': 0.6052631578947368,\n",
       "    'f': 0.4259259213648834}},\n",
       "  {'rouge-1': {'r': 0.3142857142857143,\n",
       "    'p': 0.43137254901960786,\n",
       "    'f': 0.36363635875964767},\n",
       "   'rouge-2': {'r': 0.1686746987951807,\n",
       "    'p': 0.22580645161290322,\n",
       "    'f': 0.19310344338073732},\n",
       "   'rouge-l': {'r': 0.3, 'p': 0.4117647058823529, 'f': 0.3471074331398129}},\n",
       "  {'rouge-1': {'r': 0.1, 'p': 0.4375, 'f': 0.16279069464575452},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.1, 'p': 0.4375, 'f': 0.16279069464575452}},\n",
       "  {'rouge-1': {'r': 0.5882352941176471,\n",
       "    'p': 0.5660377358490566,\n",
       "    'f': 0.5769230719249261},\n",
       "   'rouge-2': {'r': 0.36666666666666664,\n",
       "    'p': 0.2972972972972973,\n",
       "    'f': 0.32835820400980176},\n",
       "   'rouge-l': {'r': 0.5882352941176471,\n",
       "    'p': 0.5660377358490566,\n",
       "    'f': 0.5769230719249261}},\n",
       "  {'rouge-1': {'r': 0.45098039215686275,\n",
       "    'p': 0.38333333333333336,\n",
       "    'f': 0.4144144094472852},\n",
       "   'rouge-2': {'r': 0.25, 'p': 0.18518518518518517, 'f': 0.21276595255771855},\n",
       "   'rouge-l': {'r': 0.3333333333333333,\n",
       "    'p': 0.2833333333333333,\n",
       "    'f': 0.306306301339177}},\n",
       "  {'rouge-1': {'r': 0.3333333333333333, 'p': 0.53125, 'f': 0.4096385494788794},\n",
       "   'rouge-2': {'r': 0.15, 'p': 0.2647058823529412, 'f': 0.1914893570846538},\n",
       "   'rouge-l': {'r': 0.27450980392156865,\n",
       "    'p': 0.4375,\n",
       "    'f': 0.3373493928523734}},\n",
       "  {'rouge-1': {'r': 0.39215686274509803, 'p': 0.625, 'f': 0.4819277061053855},\n",
       "   'rouge-2': {'r': 0.25, 'p': 0.35714285714285715, 'f': 0.2941176422145329},\n",
       "   'rouge-l': {'r': 0.39215686274509803, 'p': 0.625, 'f': 0.4819277061053855}},\n",
       "  {'rouge-1': {'r': 0.35294117647058826, 'p': 0.5625, 'f': 0.4337349350210481},\n",
       "   'rouge-2': {'r': 0.21666666666666667,\n",
       "    'p': 0.30952380952380953,\n",
       "    'f': 0.25490195594002313},\n",
       "   'rouge-l': {'r': 0.35294117647058826,\n",
       "    'p': 0.5625,\n",
       "    'f': 0.4337349350210481}},\n",
       "  {'rouge-1': {'r': 0.13114754098360656,\n",
       "    'p': 0.47058823529411764,\n",
       "    'f': 0.2051282017192637},\n",
       "   'rouge-2': {'r': 0.05555555555555555, 'p': 0.2, 'f': 0.08695651833648407},\n",
       "   'rouge-l': {'r': 0.11475409836065574,\n",
       "    'p': 0.4117647058823529,\n",
       "    'f': 0.17948717607823805}},\n",
       "  {'rouge-1': {'r': 0.13114754098360656, 'p': 0.5, 'f': 0.2077922044999157},\n",
       "   'rouge-2': {'r': 0.05555555555555555, 'p': 0.25, 'f': 0.09090908793388439},\n",
       "   'rouge-l': {'r': 0.13114754098360656, 'p': 0.5, 'f': 0.2077922044999157}},\n",
       "  {'rouge-1': {'r': 0.09836065573770492, 'p': 0.375, 'f': 0.1558441525518638},\n",
       "   'rouge-2': {'r': 0.027777777777777776,\n",
       "    'p': 0.1111111111111111,\n",
       "    'f': 0.044444441244444674},\n",
       "   'rouge-l': {'r': 0.08196721311475409,\n",
       "    'p': 0.3125,\n",
       "    'f': 0.12987012657783784}},\n",
       "  {'rouge-1': {'r': 0.16393442622950818,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.22471909681100874},\n",
       "   'rouge-2': {'r': 0.09722222222222222,\n",
       "    'p': 0.21875,\n",
       "    'f': 0.13461538035502973},\n",
       "   'rouge-l': {'r': 0.16393442622950818,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.22471909681100874}},\n",
       "  {'rouge-1': {'r': 0.09836065573770492, 'p': 0.4, 'f': 0.15789473367382278},\n",
       "   'rouge-2': {'r': 0.013888888888888888,\n",
       "    'p': 0.058823529411764705,\n",
       "    'f': 0.022471907021841105},\n",
       "   'rouge-l': {'r': 0.08196721311475409,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.13157894420013858}},\n",
       "  {'rouge-1': {'r': 0.8, 'p': 0.5970149253731343, 'f': 0.683760678866243},\n",
       "   'rouge-2': {'r': 0.7611940298507462,\n",
       "    'p': 0.5425531914893617,\n",
       "    'f': 0.6335403678114271},\n",
       "   'rouge-l': {'r': 0.8, 'p': 0.5970149253731343, 'f': 0.683760678866243}},\n",
       "  {'rouge-1': {'r': 0.48, 'p': 0.4444444444444444, 'f': 0.461538456545858},\n",
       "   'rouge-2': {'r': 0.34328358208955223,\n",
       "    'p': 0.2987012987012987,\n",
       "    'f': 0.31944443946855716},\n",
       "   'rouge-l': {'r': 0.48, 'p': 0.4444444444444444, 'f': 0.461538456545858}},\n",
       "  {'rouge-1': {'r': 0.28, 'p': 0.30434782608695654, 'f': 0.2916666616753473},\n",
       "   'rouge-2': {'r': 0.19402985074626866,\n",
       "    'p': 0.23214285714285715,\n",
       "    'f': 0.21138210886112777},\n",
       "   'rouge-l': {'r': 0.28, 'p': 0.30434782608695654, 'f': 0.2916666616753473}},\n",
       "  {'rouge-1': {'r': 0.12, 'p': 0.14634146341463414, 'f': 0.13186812691703917},\n",
       "   'rouge-2': {'r': 0.029850746268656716,\n",
       "    'p': 0.043478260869565216,\n",
       "    'f': 0.035398225261180076},\n",
       "   'rouge-l': {'r': 0.12, 'p': 0.14634146341463414, 'f': 0.13186812691703917}},\n",
       "  {'rouge-1': {'r': 0.14, 'p': 0.1320754716981132, 'f': 0.13592232510132926},\n",
       "   'rouge-2': {'r': 0.04477611940298507,\n",
       "    'p': 0.043478260869565216,\n",
       "    'f': 0.04411764205990541},\n",
       "   'rouge-l': {'r': 0.14, 'p': 0.1320754716981132, 'f': 0.13592232510132926}},\n",
       "  {'rouge-1': {'r': 0.5102040816326531,\n",
       "    'p': 0.28735632183908044,\n",
       "    'f': 0.3676470542138841},\n",
       "   'rouge-2': {'r': 0.2033898305084746,\n",
       "    'p': 0.09917355371900827,\n",
       "    'f': 0.13333332892654337},\n",
       "   'rouge-l': {'r': 0.46938775510204084,\n",
       "    'p': 0.26436781609195403,\n",
       "    'f': 0.33823528950800175}},\n",
       "  {'rouge-1': {'r': 0.16326530612244897,\n",
       "    'p': 0.6666666666666666,\n",
       "    'f': 0.2622950788067724},\n",
       "   'rouge-2': {'r': 0.06779661016949153,\n",
       "    'p': 0.3333333333333333,\n",
       "    'f': 0.11267605352906178},\n",
       "   'rouge-l': {'r': 0.10204081632653061,\n",
       "    'p': 0.4166666666666667,\n",
       "    'f': 0.16393442306906753}},\n",
       "  {'rouge-1': {'r': 0.32653061224489793,\n",
       "    'p': 0.47058823529411764,\n",
       "    'f': 0.3855421638380026},\n",
       "   'rouge-2': {'r': 0.1016949152542373,\n",
       "    'p': 0.15789473684210525,\n",
       "    'f': 0.12371133544053584},\n",
       "   'rouge-l': {'r': 0.2653061224489796,\n",
       "    'p': 0.38235294117647056,\n",
       "    'f': 0.3132530072114966}},\n",
       "  {'rouge-1': {'r': 0.3469387755102041,\n",
       "    'p': 0.4146341463414634,\n",
       "    'f': 0.377777772817284},\n",
       "   'rouge-2': {'r': 0.15254237288135594,\n",
       "    'p': 0.19148936170212766,\n",
       "    'f': 0.16981131581879688},\n",
       "   'rouge-l': {'r': 0.30612244897959184,\n",
       "    'p': 0.36585365853658536,\n",
       "    'f': 0.3333333283728396}},\n",
       "  {'rouge-1': {'r': 0.12244897959183673,\n",
       "    'p': 0.46153846153846156,\n",
       "    'f': 0.19354838378251824},\n",
       "   'rouge-2': {'r': 0.05084745762711865, 'p': 0.25, 'f': 0.08450703944455476},\n",
       "   'rouge-l': {'r': 0.12244897959183673,\n",
       "    'p': 0.46153846153846156,\n",
       "    'f': 0.19354838378251824}},\n",
       "  {'rouge-1': {'r': 0.26666666666666666,\n",
       "    'p': 0.0975609756097561,\n",
       "    'f': 0.14285713893494908},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.2, 'p': 0.07317073170731707, 'f': 0.1071428532206634}},\n",
       "  {'rouge-1': {'r': 0.7333333333333333,\n",
       "    'p': 0.7333333333333333,\n",
       "    'f': 0.7333333283333333},\n",
       "   'rouge-2': {'r': 0.5714285714285714,\n",
       "    'p': 0.5714285714285714,\n",
       "    'f': 0.5714285664285715},\n",
       "   'rouge-l': {'r': 0.7333333333333333,\n",
       "    'p': 0.7333333333333333,\n",
       "    'f': 0.7333333283333333}},\n",
       "  {'rouge-1': {'r': 0.3333333333333333,\n",
       "    'p': 0.21739130434782608,\n",
       "    'f': 0.2631578899584488},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.07692307692307693,\n",
       "    'f': 0.09999999545000023},\n",
       "   'rouge-l': {'r': 0.26666666666666666,\n",
       "    'p': 0.17391304347826086,\n",
       "    'f': 0.21052631101108046}},\n",
       "  {'rouge-1': {'r': 0.3333333333333333,\n",
       "    'p': 0.2631578947368421,\n",
       "    'f': 0.2941176421280277},\n",
       "   'rouge-2': {'r': 0.07142857142857142, 'p': 0.05, 'f': 0.05882352456747445},\n",
       "   'rouge-l': {'r': 0.3333333333333333,\n",
       "    'p': 0.2631578947368421,\n",
       "    'f': 0.2941176421280277}},\n",
       "  {'rouge-1': {'r': 0.4, 'p': 0.14634146341463414, 'f': 0.21428571036352043},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.044444444444444446,\n",
       "    'f': 0.0677966065498422},\n",
       "   'rouge-l': {'r': 0.3333333333333333,\n",
       "    'p': 0.12195121951219512,\n",
       "    'f': 0.17857142464923478}},\n",
       "  {'rouge-1': {'r': 0.4, 'p': 0.5172413793103449, 'f': 0.4511278146305614},\n",
       "   'rouge-2': {'r': 0.16666666666666666, 'p': 0.24, 'f': 0.19672130663800066},\n",
       "   'rouge-l': {'r': 0.38666666666666666, 'p': 0.5, 'f': 0.43609022064559894}},\n",
       "  {'rouge-1': {'r': 0.4533333333333333,\n",
       "    'p': 0.5964912280701754,\n",
       "    'f': 0.5151515102444904},\n",
       "   'rouge-2': {'r': 0.2777777777777778,\n",
       "    'p': 0.35714285714285715,\n",
       "    'f': 0.3124999950781251},\n",
       "   'rouge-l': {'r': 0.44, 'p': 0.5789473684210527, 'f': 0.49999999509297527}},\n",
       "  {'rouge-1': {'r': 0.21333333333333335,\n",
       "    'p': 0.42105263157894735,\n",
       "    'f': 0.28318583624402854},\n",
       "   'rouge-2': {'r': 0.06481481481481481,\n",
       "    'p': 0.12280701754385964,\n",
       "    'f': 0.08484848032617104},\n",
       "   'rouge-l': {'r': 0.2, 'p': 0.39473684210526316, 'f': 0.2654867211997808}},\n",
       "  {'rouge-1': {'r': 0.16, 'p': 0.48, 'f': 0.23999999625000001},\n",
       "   'rouge-2': {'r': 0.037037037037037035,\n",
       "    'p': 0.14814814814814814,\n",
       "    'f': 0.059259256059259434},\n",
       "   'rouge-l': {'r': 0.14666666666666667, 'p': 0.44, 'f': 0.21999999625000002}},\n",
       "  {'rouge-1': {'r': 0.21333333333333335,\n",
       "    'p': 0.25396825396825395,\n",
       "    'f': 0.23188405300882178},\n",
       "   'rouge-2': {'r': 0.046296296296296294,\n",
       "    'p': 0.0684931506849315,\n",
       "    'f': 0.05524861397149091},\n",
       "   'rouge-l': {'r': 0.17333333333333334,\n",
       "    'p': 0.20634920634920634,\n",
       "    'f': 0.1884057921392566}},\n",
       "  {'rouge-1': {'r': 0.5192307692307693, 'p': 0.5, 'f': 0.5094339572659311},\n",
       "   'rouge-2': {'r': 0.31746031746031744,\n",
       "    'p': 0.30303030303030304,\n",
       "    'f': 0.3100775143825492},\n",
       "   'rouge-l': {'r': 0.4807692307692308,\n",
       "    'p': 0.46296296296296297,\n",
       "    'f': 0.47169810820932717}},\n",
       "  {'rouge-1': {'r': 0.5961538461538461,\n",
       "    'p': 0.5636363636363636,\n",
       "    'f': 0.5794392473403791},\n",
       "   'rouge-2': {'r': 0.3333333333333333,\n",
       "    'p': 0.3181818181818182,\n",
       "    'f': 0.3255813903515414},\n",
       "   'rouge-l': {'r': 0.5576923076923077,\n",
       "    'p': 0.5272727272727272,\n",
       "    'f': 0.5420560697702858}},\n",
       "  {'rouge-1': {'r': 0.38461538461538464,\n",
       "    'p': 0.37037037037037035,\n",
       "    'f': 0.37735848556781776},\n",
       "   'rouge-2': {'r': 0.15873015873015872,\n",
       "    'p': 0.14925373134328357,\n",
       "    'f': 0.15384614885088774},\n",
       "   'rouge-l': {'r': 0.36538461538461536,\n",
       "    'p': 0.35185185185185186,\n",
       "    'f': 0.3584905610395159}},\n",
       "  {'rouge-1': {'r': 0.34615384615384615,\n",
       "    'p': 0.43902439024390244,\n",
       "    'f': 0.3870967692634986},\n",
       "   'rouge-2': {'r': 0.09523809523809523,\n",
       "    'p': 0.11764705882352941,\n",
       "    'f': 0.10526315295013873},\n",
       "   'rouge-l': {'r': 0.28846153846153844,\n",
       "    'p': 0.36585365853658536,\n",
       "    'f': 0.32258064023124067}},\n",
       "  {'rouge-1': {'r': 0.3269230769230769, 'p': 0.34, 'f': 0.3333333283352557},\n",
       "   'rouge-2': {'r': 0.14285714285714285,\n",
       "    'p': 0.13846153846153847,\n",
       "    'f': 0.1406249950012209},\n",
       "   'rouge-l': {'r': 0.2692307692307692, 'p': 0.28, 'f': 0.27450979892349103}},\n",
       "  {'rouge-1': {'r': 0.5416666666666666,\n",
       "    'p': 0.5416666666666666,\n",
       "    'f': 0.5416666616666667},\n",
       "   'rouge-2': {'r': 0.20833333333333334,\n",
       "    'p': 0.20833333333333334,\n",
       "    'f': 0.20833332833333348},\n",
       "   'rouge-l': {'r': 0.4583333333333333,\n",
       "    'p': 0.4583333333333333,\n",
       "    'f': 0.45833332833333335}},\n",
       "  {'rouge-1': {'r': 0.5, 'p': 0.41379310344827586, 'f': 0.45283018372374517},\n",
       "   'rouge-2': {'r': 0.16666666666666666, 'p': 0.125, 'f': 0.14285713795918387},\n",
       "   'rouge-l': {'r': 0.5, 'p': 0.41379310344827586, 'f': 0.45283018372374517}},\n",
       "  {'rouge-1': {'r': 0.5833333333333334,\n",
       "    'p': 0.4117647058823529,\n",
       "    'f': 0.4827586158382878},\n",
       "   'rouge-2': {'r': 0.25, 'p': 0.15789473684210525, 'f': 0.19354838235171706},\n",
       "   'rouge-l': {'r': 0.5, 'p': 0.35294117647058826, 'f': 0.41379309859690844}},\n",
       "  {'rouge-1': {'r': 0.4166666666666667, 'p': 0.4, 'f': 0.408163260308205},\n",
       "   'rouge-2': {'r': 0.125, 'p': 0.11538461538461539, 'f': 0.11999999500800021},\n",
       "   'rouge-l': {'r': 0.3333333333333333, 'p': 0.32, 'f': 0.32653060724698046}},\n",
       "  {'rouge-1': {'r': 0.5, 'p': 0.1791044776119403, 'f': 0.26373625985267485},\n",
       "   'rouge-2': {'r': 0.20833333333333334,\n",
       "    'p': 0.058823529411764705,\n",
       "    'f': 0.0917431158320008},\n",
       "   'rouge-l': {'r': 0.3333333333333333,\n",
       "    'p': 0.11940298507462686,\n",
       "    'f': 0.17582417194058697}},\n",
       "  {'rouge-1': {'r': 0.5952380952380952,\n",
       "    'p': 0.5681818181818182,\n",
       "    'f': 0.5813953438399135},\n",
       "   'rouge-2': {'r': 0.3333333333333333,\n",
       "    'p': 0.3090909090909091,\n",
       "    'f': 0.3207547119882521},\n",
       "   'rouge-l': {'r': 0.5952380952380952,\n",
       "    'p': 0.5681818181818182,\n",
       "    'f': 0.5813953438399135}},\n",
       "  {'rouge-1': {'r': 0.23809523809523808,\n",
       "    'p': 0.43478260869565216,\n",
       "    'f': 0.30769230311952667},\n",
       "   'rouge-2': {'r': 0.09803921568627451,\n",
       "    'p': 0.18518518518518517,\n",
       "    'f': 0.12820512367850115},\n",
       "   'rouge-l': {'r': 0.23809523809523808,\n",
       "    'p': 0.43478260869565216,\n",
       "    'f': 0.30769230311952667}},\n",
       "  {'rouge-1': {'r': 0.23809523809523808,\n",
       "    'p': 0.24390243902439024,\n",
       "    'f': 0.24096385042241264},\n",
       "   'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       "   'rouge-l': {'r': 0.19047619047619047,\n",
       "    'p': 0.1951219512195122,\n",
       "    'f': 0.19277107933807533}},\n",
       "  {'rouge-1': {'r': 0.5476190476190477,\n",
       "    'p': 0.4791666666666667,\n",
       "    'f': 0.5111111061333333},\n",
       "   'rouge-2': {'r': 0.23529411764705882, 'p': 0.2, 'f': 0.21621621124908705},\n",
       "   'rouge-l': {'r': 0.5, 'p': 0.4375, 'f': 0.46666666168888893}},\n",
       "  {'rouge-1': {'r': 0.09523809523809523,\n",
       "    'p': 0.2857142857142857,\n",
       "    'f': 0.14285713910714296},\n",
       "   'rouge-2': {'r': 0.0392156862745098,\n",
       "    'p': 0.15384615384615385,\n",
       "    'f': 0.062499996762695485},\n",
       "   'rouge-l': {'r': 0.09523809523809523,\n",
       "    'p': 0.2857142857142857,\n",
       "    'f': 0.14285713910714296}},\n",
       "  {'rouge-1': {'r': 0.6470588235294118,\n",
       "    'p': 0.43137254901960786,\n",
       "    'f': 0.5176470540235294},\n",
       "   'rouge-2': {'r': 0.47368421052631576,\n",
       "    'p': 0.2903225806451613,\n",
       "    'f': 0.35999999528800003},\n",
       "   'rouge-l': {'r': 0.6176470588235294,\n",
       "    'p': 0.4117647058823529,\n",
       "    'f': 0.49411764225882365}},\n",
       "  {'rouge-1': {'r': 0.17647058823529413,\n",
       "    'p': 0.35294117647058826,\n",
       "    'f': 0.23529411320261448},\n",
       "   'rouge-2': {'r': 0.10526315789473684,\n",
       "    'p': 0.21052631578947367,\n",
       "    'f': 0.14035087274853814},\n",
       "   'rouge-l': {'r': 0.17647058823529413,\n",
       "    'p': 0.35294117647058826,\n",
       "    'f': 0.23529411320261448}},\n",
       "  {'rouge-1': {'r': 0.5, 'p': 0.3953488372093023, 'f': 0.4415584366267499},\n",
       "   'rouge-2': {'r': 0.2631578947368421,\n",
       "    'p': 0.20408163265306123,\n",
       "    'f': 0.22988505255119576},\n",
       "   'rouge-l': {'r': 0.47058823529411764,\n",
       "    'p': 0.37209302325581395,\n",
       "    'f': 0.41558441065272395}},\n",
       "  {'rouge-1': {'r': 0.6470588235294118,\n",
       "    'p': 0.3793103448275862,\n",
       "    'f': 0.47826086490548214},\n",
       "   'rouge-2': {'r': 0.47368421052631576, 'p': 0.25, 'f': 0.3272727227504133},\n",
       "   'rouge-l': {'r': 0.6176470588235294,\n",
       "    'p': 0.3620689655172414,\n",
       "    'f': 0.4565217344706995}},\n",
       "  {'rouge-1': {'r': 0.38235294117647056, 'p': 0.25, 'f': 0.3023255766143862},\n",
       "   'rouge-2': {'r': 0.18421052631578946,\n",
       "    'p': 0.1111111111111111,\n",
       "    'f': 0.1386138566924813},\n",
       "   'rouge-l': {'r': 0.35294117647058826,\n",
       "    'p': 0.23076923076923078,\n",
       "    'f': 0.2790697626608979}},\n",
       "  {'rouge-1': {'r': 0.6428571428571429,\n",
       "    'p': 0.6666666666666666,\n",
       "    'f': 0.6545454495471076},\n",
       "   'rouge-2': {'r': 0.559322033898305,\n",
       "    'p': 0.5238095238095238,\n",
       "    'f': 0.540983601562752},\n",
       "   'rouge-l': {'r': 0.6071428571428571,\n",
       "    'p': 0.6296296296296297,\n",
       "    'f': 0.6181818131834711}},\n",
       "  {'rouge-1': {'r': 0.6428571428571429,\n",
       "    'p': 0.5454545454545454,\n",
       "    'f': 0.5901639294598228},\n",
       "   'rouge-2': {'r': 0.5423728813559322, 'p': 0.4, 'f': 0.4604316497903836},\n",
       "   'rouge-l': {'r': 0.6071428571428571,\n",
       "    'p': 0.5151515151515151,\n",
       "    'f': 0.557377044213921}},\n",
       "  {'rouge-1': {'r': 0.6607142857142857,\n",
       "    'p': 0.6491228070175439,\n",
       "    'f': 0.6548672516375598},\n",
       "   'rouge-2': {'r': 0.5932203389830508,\n",
       "    'p': 0.5384615384615384,\n",
       "    'f': 0.5645161240439647},\n",
       "   'rouge-l': {'r': 0.6428571428571429,\n",
       "    'p': 0.631578947368421,\n",
       "    'f': 0.637168136593312}},\n",
       "  {'rouge-1': {'r': 0.2857142857142857,\n",
       "    'p': 0.32653061224489793,\n",
       "    'f': 0.304761899784127},\n",
       "   'rouge-2': {'r': 0.13559322033898305,\n",
       "    'p': 0.12903225806451613,\n",
       "    'f': 0.13223139996175146},\n",
       "   'rouge-l': {'r': 0.2857142857142857,\n",
       "    'p': 0.32653061224489793,\n",
       "    'f': 0.304761899784127}},\n",
       "  {'rouge-1': {'r': 0.125, 'p': 0.3181818181818182, 'f': 0.17948717543721246},\n",
       "   'rouge-2': {'r': 0.01694915254237288,\n",
       "    'p': 0.038461538461538464,\n",
       "    'f': 0.023529407518339866},\n",
       "   'rouge-l': {'r': 0.10714285714285714,\n",
       "    'p': 0.2727272727272727,\n",
       "    'f': 0.1538461497961868}}])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rouge_scores), rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07540c10-9c07-4107-ab6e-1b2b27595c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores_dict = {}\n",
    "for i in range(len(rouge_scores)):\n",
    "    rouge_scores_dict[i]= rouge_scores[i]\n",
    "\n",
    "type(rouge_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a1bd968-1f6f-435b-a9e8-414167aee4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.061224489795918366,\n",
       "  'p': 0.21428571428571427,\n",
       "  'f': 0.09523809178130524},\n",
       " 'rouge-2': {'r': 0.017543859649122806,\n",
       "  'p': 0.07142857142857142,\n",
       "  'f': 0.028169010918468917},\n",
       " 'rouge-l': {'r': 0.061224489795918366,\n",
       "  'p': 0.21428571428571427,\n",
       "  'f': 0.09523809178130524}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84355a9f-d96c-471a-8d9d-12b4618a2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rouge_scores_df = pd.DataFrame.from_dict(rouge_scores_dict, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc9c29e9-f879-4dfd-935c-117304124839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'r': 0.061224489795918366, 'p': 0.21428571428...</td>\n",
       "      <td>{'r': 0.017543859649122806, 'p': 0.07142857142...</td>\n",
       "      <td>{'r': 0.061224489795918366, 'p': 0.21428571428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'r': 0.08163265306122448, 'p': 0.266666666666...</td>\n",
       "      <td>{'r': 0.03508771929824561, 'p': 0.133333333333...</td>\n",
       "      <td>{'r': 0.061224489795918366, 'p': 0.2, 'f': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'r': 0.32653061224489793, 'p': 0.571428571428...</td>\n",
       "      <td>{'r': 0.14035087719298245, 'p': 0.242424242424...</td>\n",
       "      <td>{'r': 0.30612244897959184, 'p': 0.535714285714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'r': 0.16326530612244897, 'p': 0.32, 'f': 0.2...</td>\n",
       "      <td>{'r': 0.03508771929824561, 'p': 0.071428571428...</td>\n",
       "      <td>{'r': 0.14285714285714285, 'p': 0.28, 'f': 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'r': 0.2653061224489796, 'p': 0.0970149253731...</td>\n",
       "      <td>{'r': 0.07017543859649122, 'p': 0.022346368715...</td>\n",
       "      <td>{'r': 0.22448979591836735, 'p': 0.082089552238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>{'r': 0.6428571428571429, 'p': 0.6666666666666...</td>\n",
       "      <td>{'r': 0.559322033898305, 'p': 0.52380952380952...</td>\n",
       "      <td>{'r': 0.6071428571428571, 'p': 0.6296296296296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>{'r': 0.6428571428571429, 'p': 0.5454545454545...</td>\n",
       "      <td>{'r': 0.5423728813559322, 'p': 0.4, 'f': 0.460...</td>\n",
       "      <td>{'r': 0.6071428571428571, 'p': 0.5151515151515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>{'r': 0.6607142857142857, 'p': 0.6491228070175...</td>\n",
       "      <td>{'r': 0.5932203389830508, 'p': 0.5384615384615...</td>\n",
       "      <td>{'r': 0.6428571428571429, 'p': 0.6315789473684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>{'r': 0.2857142857142857, 'p': 0.3265306122448...</td>\n",
       "      <td>{'r': 0.13559322033898305, 'p': 0.129032258064...</td>\n",
       "      <td>{'r': 0.2857142857142857, 'p': 0.3265306122448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>{'r': 0.125, 'p': 0.3181818181818182, 'f': 0.1...</td>\n",
       "      <td>{'r': 0.01694915254237288, 'p': 0.038461538461...</td>\n",
       "      <td>{'r': 0.10714285714285714, 'p': 0.272727272727...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               rouge-1  \\\n",
       "0    {'r': 0.061224489795918366, 'p': 0.21428571428...   \n",
       "1    {'r': 0.08163265306122448, 'p': 0.266666666666...   \n",
       "2    {'r': 0.32653061224489793, 'p': 0.571428571428...   \n",
       "3    {'r': 0.16326530612244897, 'p': 0.32, 'f': 0.2...   \n",
       "4    {'r': 0.2653061224489796, 'p': 0.0970149253731...   \n",
       "..                                                 ...   \n",
       "295  {'r': 0.6428571428571429, 'p': 0.6666666666666...   \n",
       "296  {'r': 0.6428571428571429, 'p': 0.5454545454545...   \n",
       "297  {'r': 0.6607142857142857, 'p': 0.6491228070175...   \n",
       "298  {'r': 0.2857142857142857, 'p': 0.3265306122448...   \n",
       "299  {'r': 0.125, 'p': 0.3181818181818182, 'f': 0.1...   \n",
       "\n",
       "                                               rouge-2  \\\n",
       "0    {'r': 0.017543859649122806, 'p': 0.07142857142...   \n",
       "1    {'r': 0.03508771929824561, 'p': 0.133333333333...   \n",
       "2    {'r': 0.14035087719298245, 'p': 0.242424242424...   \n",
       "3    {'r': 0.03508771929824561, 'p': 0.071428571428...   \n",
       "4    {'r': 0.07017543859649122, 'p': 0.022346368715...   \n",
       "..                                                 ...   \n",
       "295  {'r': 0.559322033898305, 'p': 0.52380952380952...   \n",
       "296  {'r': 0.5423728813559322, 'p': 0.4, 'f': 0.460...   \n",
       "297  {'r': 0.5932203389830508, 'p': 0.5384615384615...   \n",
       "298  {'r': 0.13559322033898305, 'p': 0.129032258064...   \n",
       "299  {'r': 0.01694915254237288, 'p': 0.038461538461...   \n",
       "\n",
       "                                               rouge-l  \n",
       "0    {'r': 0.061224489795918366, 'p': 0.21428571428...  \n",
       "1    {'r': 0.061224489795918366, 'p': 0.2, 'f': 0.0...  \n",
       "2    {'r': 0.30612244897959184, 'p': 0.535714285714...  \n",
       "3    {'r': 0.14285714285714285, 'p': 0.28, 'f': 0.1...  \n",
       "4    {'r': 0.22448979591836735, 'p': 0.082089552238...  \n",
       "..                                                 ...  \n",
       "295  {'r': 0.6071428571428571, 'p': 0.6296296296296...  \n",
       "296  {'r': 0.6071428571428571, 'p': 0.5151515151515...  \n",
       "297  {'r': 0.6428571428571429, 'p': 0.6315789473684...  \n",
       "298  {'r': 0.2857142857142857, 'p': 0.3265306122448...  \n",
       "299  {'r': 0.10714285714285714, 'p': 0.272727272727...  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80c56a73-d3d4-43ea-a9d4-e827f201c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge2 = rouge_scores_df['rouge-2'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "339499fe-96f8-4010-bd5f-0bda0da6ce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>p</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.198613</td>\n",
       "      <td>0.258626</td>\n",
       "      <td>0.206965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.164964</td>\n",
       "      <td>0.174559</td>\n",
       "      <td>0.153550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.074632</td>\n",
       "      <td>0.138093</td>\n",
       "      <td>0.097809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.159075</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.178671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.260995</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>0.286181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                r           p           f\n",
       "count  300.000000  300.000000  300.000000\n",
       "mean     0.198613    0.258626    0.206965\n",
       "std      0.164964    0.174559    0.153550\n",
       "min      0.000000    0.000000    0.000000\n",
       "25%      0.074632    0.138093    0.097809\n",
       "50%      0.159075    0.230769    0.178671\n",
       "75%      0.260995    0.335366    0.286181\n",
       "max      0.805556    1.000000    0.739130"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91a999e2-c600-4462-9e34-19d15eaeee1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19861258009846788, 0.25862646516998544, 0.20696501983423318)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_r = rouge2['r'].mean()\n",
    "average_p = rouge2['p'].mean()\n",
    "average_f = rouge2['f'].mean()\n",
    "average_r, average_p, average_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00c15c-b902-4221-931f-6d3e8ae00055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
